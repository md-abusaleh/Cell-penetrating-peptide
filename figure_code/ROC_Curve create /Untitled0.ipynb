{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":680,"status":"ok","timestamp":1737743674246,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"kkYfT7nCmAD0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"yq25YaPHltkU"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:35:35] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 582, number of negative: 582\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1006\n","[LightGBM] [Info] Number of data points in the train set: 1164, number of used features: 116\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -\u003e initscore=0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 374ms/step - accuracy: 0.7381 - loss: 0.4956\n","Epoch 2/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 397ms/step - accuracy: 0.9699 - loss: 0.1082\n","Epoch 3/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 407ms/step - accuracy: 0.9850 - loss: 0.0428\n","Epoch 4/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 347ms/step - accuracy: 0.9855 - loss: 0.0399\n","Epoch 5/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 342ms/step - accuracy: 0.9923 - loss: 0.0285\n","Epoch 6/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 376ms/step - accuracy: 0.9920 - loss: 0.0212\n","Epoch 7/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 381ms/step - accuracy: 0.9940 - loss: 0.0225\n","Epoch 8/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 376ms/step - accuracy: 0.9903 - loss: 0.0225\n","Epoch 9/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 347ms/step - accuracy: 0.9914 - loss: 0.0243\n","Epoch 10/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 374ms/step - accuracy: 0.9968 - loss: 0.0135\n","Epoch 11/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 347ms/step - accuracy: 0.9942 - loss: 0.0141\n","Epoch 12/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 372ms/step - accuracy: 0.9908 - loss: 0.0261\n","Epoch 13/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 380ms/step - accuracy: 0.9942 - loss: 0.0191\n","Epoch 14/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 371ms/step - accuracy: 0.9946 - loss: 0.0127\n","Epoch 15/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 325ms/step - accuracy: 0.9942 - loss: 0.0156\n","Epoch 16/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 370ms/step - accuracy: 0.9956 - loss: 0.0148\n","Epoch 17/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 351ms/step - accuracy: 0.9982 - loss: 0.0093\n","Epoch 18/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 373ms/step - accuracy: 0.9966 - loss: 0.0087\n","Epoch 19/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 368ms/step - accuracy: 0.9962 - loss: 0.0137\n","Epoch 20/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 378ms/step - accuracy: 0.9956 - loss: 0.0170\n","Epoch 21/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 338ms/step - accuracy: 0.9950 - loss: 0.0116\n","Epoch 22/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 368ms/step - accuracy: 0.9938 - loss: 0.0119\n","Epoch 23/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 372ms/step - accuracy: 0.9957 - loss: 0.0106\n","Epoch 24/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 375ms/step - accuracy: 0.9907 - loss: 0.0156\n","Epoch 25/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 371ms/step - accuracy: 0.9955 - loss: 0.0093\n","Epoch 26/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 345ms/step - accuracy: 0.9986 - loss: 0.0062\n","Epoch 27/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 377ms/step - accuracy: 0.9935 - loss: 0.0126\n","Epoch 28/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 372ms/step - accuracy: 0.9963 - loss: 0.0099\n","Epoch 29/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 375ms/step - accuracy: 0.9930 - loss: 0.0113\n","Epoch 30/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 324ms/step - accuracy: 0.9916 - loss: 0.0188\n","Epoch 31/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 369ms/step - accuracy: 0.9926 - loss: 0.0141\n","Epoch 32/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 340ms/step - accuracy: 0.9900 - loss: 0.0172\n","Epoch 33/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 357ms/step - accuracy: 0.9925 - loss: 0.0173\n","Epoch 34/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 365ms/step - accuracy: 0.9952 - loss: 0.0127\n","Epoch 35/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 354ms/step - accuracy: 0.9919 - loss: 0.0144\n","Epoch 36/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 369ms/step - accuracy: 0.9972 - loss: 0.0148\n","Epoch 37/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 366ms/step - accuracy: 0.9926 - loss: 0.0140\n","Epoch 38/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 354ms/step - accuracy: 0.9942 - loss: 0.0152\n","Epoch 39/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 380ms/step - accuracy: 0.9931 - loss: 0.0120\n","Epoch 40/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 339ms/step - accuracy: 0.9978 - loss: 0.0074\n","Epoch 41/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 374ms/step - accuracy: 0.9954 - loss: 0.0092\n","Epoch 42/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 334ms/step - accuracy: 0.9935 - loss: 0.0116\n","Epoch 43/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 364ms/step - accuracy: 0.9891 - loss: 0.0187\n","Epoch 44/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 373ms/step - accuracy: 0.9955 - loss: 0.0118\n","Epoch 45/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 368ms/step - accuracy: 0.9917 - loss: 0.0179\n","Epoch 46/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 339ms/step - accuracy: 0.9920 - loss: 0.0186\n","Epoch 47/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 381ms/step - accuracy: 0.9969 - loss: 0.0087\n","Epoch 48/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 354ms/step - accuracy: 0.9943 - loss: 0.0089\n","Epoch 49/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 375ms/step - accuracy: 0.9931 - loss: 0.0112\n","Epoch 50/50\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 374ms/step - accuracy: 0.9952 - loss: 0.0092\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step\n","Epoch 1/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 6s/step - accuracy: 0.4884 - loss: 0.6959 - val_accuracy: 0.5067 - val_loss: 0.6932\n","Epoch 2/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 6s/step - accuracy: 0.4856 - loss: 0.7014 - val_accuracy: 0.5000 - val_loss: 0.6931\n","Epoch 3/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 6s/step - accuracy: 0.4678 - loss: 0.6965 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 4/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 6s/step - accuracy: 0.5043 - loss: 0.6961 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 5/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 6s/step - accuracy: 0.4837 - loss: 0.6971 - val_accuracy: 0.5000 - val_loss: 0.6931\n","Epoch 6/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 6s/step - accuracy: 0.5032 - loss: 0.6945 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 7/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 6s/step - accuracy: 0.4853 - loss: 0.6982 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 8/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 6s/step - accuracy: 0.5199 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 9/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 6s/step - accuracy: 0.5150 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6936\n","Epoch 10/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 6s/step - accuracy: 0.5112 - loss: 0.6959 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 11/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 6s/step - accuracy: 0.5098 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 12/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 6s/step - accuracy: 0.4739 - loss: 0.6950 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 13/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 6s/step - accuracy: 0.4821 - loss: 0.6942 - val_accuracy: 0.5067 - val_loss: 0.6931\n","Epoch 14/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 6s/step - accuracy: 0.5247 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 15/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 6s/step - accuracy: 0.5008 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n","Epoch 16/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 6s/step - accuracy: 0.4899 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 17/100\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 6s/step - accuracy: 0.4872 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n","Epoch 18/100\n","\u001b[1m17/37\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 6s/step - accuracy: 0.4660 - loss: 0.6943"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neural_network import MLPClassifier\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, Flatten\n","import matplotlib.pyplot as plt\n","\n","# Load individual datasets\n","main_p = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_2/4_CTDD/ctdd_main_positive_features (3).csv\")\n","main_n = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_2/4_CTDD/ctdd_main_negative_features.csv\")\n","validation_p = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_2/4_CTDD/ctdd_validation_positive_features.csv\")\n","validation_n = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_2/4_CTDD/ctdd_validation_negative_features.csv\")\n","\n","# Combine datasets\n","main_p['Target'] = 1\n","main_n['Target'] = 0\n","validation_p['Target'] = 1\n","validation_n['Target'] = 0\n","\n","train_data = pd.concat([main_p, main_n], ignore_index=True)\n","validation_data = pd.concat([validation_p, validation_n], ignore_index=True)\n","\n","# Ensure no NaN or Inf values\n","train_data = train_data.dropna()\n","validation_data = validation_data.dropna()\n","assert np.isfinite(train_data.values).all(), \"Training data contains NaN or Inf values!\"\n","assert np.isfinite(validation_data.values).all(), \"Validation data contains NaN or Inf values!\"\n","\n","# Separate features and labels\n","X_train = train_data.drop(columns=['Target']).values\n","y_train = train_data['Target'].values\n","X_val = validation_data.drop(columns=['Target']).values\n","y_val = validation_data['Target'].values\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Random Forest Model\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","rf_probabilities = rf_model.predict_proba(X_val)[:, 1]\n","\n","# XGBoost Model\n","xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n","xgb_model.fit(X_train, y_train)\n","xgb_probabilities = xgb_model.predict_proba(X_val)[:, 1]\n","\n","# LightGBM Model\n","lgbm_model = LGBMClassifier(random_state=42)\n","lgbm_model.fit(X_train, y_train)\n","lgbm_probabilities = lgbm_model.predict_proba(X_val)[:, 1]\n","\n","# Multi-Layer Perceptron Model\n","mlp_model = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', max_iter=200, random_state=42)\n","mlp_model.fit(X_train, y_train)\n","mlp_probabilities = mlp_model.predict_proba(X_val)[:, 1]\n","\n","# CNN Model\n","X_train_cnn = X_train[..., np.newaxis]  # Shape: (samples, timesteps, 1)\n","X_val_cnn = X_val[..., np.newaxis]      # Shape: (samples, timesteps, 1)\n","\n","cnn_model = Sequential([\n","    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n","    MaxPooling1D(pool_size=2),\n","    Dropout(0.3),\n","    Flatten(),\n","    Dense(1, activation='sigmoid')\n","])\n","cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","cnn_model.fit(X_train_cnn, y_train, epochs=50, batch_size=32, verbose=1)\n","cnn_probabilities = cnn_model.predict(X_val_cnn).flatten()\n","\n","# Proposed Model\n","proposed_model = Sequential([\n","    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1), padding='same'),\n","    BatchNormalization(),\n","    MaxPooling1D(pool_size=2),\n","    Dropout(0.3),\n","    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n","    BatchNormalization(),\n","    MaxPooling1D(pool_size=2),\n","    Dropout(0.3),\n","    Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","    LSTM(64, return_sequences=False),\n","    Dense(128, activation='swish'),\n","    Dropout(0.3),\n","    Dense(64, activation='swish'),\n","    Dropout(0.3),\n","    Dense(1, activation='sigmoid')\n","])\n","proposed_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","proposed_model.fit(X_train_cnn, y_train, validation_data=(X_val_cnn, y_val), epochs=100, batch_size=32, verbose=1)\n","proposed_probabilities = proposed_model.predict(X_val_cnn).flatten()\n","\n","# Compute ROC curve and AUC for a model\n","def compute_roc_auc(model_name, y_true, y_scores):\n","    fpr, tpr, _ = roc_curve(y_true, y_scores)\n","    roc_auc = auc(fpr, tpr)\n","    return fpr, tpr, roc_auc\n","\n","# Compute ROC and AUC for each model\n","roc_data_4 = {\n","    \"RF\": compute_roc_auc(\"RF\", y_val, rf_probabilities),\n","    \"XGB\": compute_roc_auc(\"XGB\", y_val, xgb_probabilities),\n","    \"LGBM\": compute_roc_auc(\"LGBM\", y_val, lgbm_probabilities),\n","    \"MLP\": compute_roc_auc(\"MLP\", y_val, mlp_probabilities),\n","    \"CNN\": compute_roc_auc(\"CNN\", y_val, cnn_probabilities),\n","    \"Deep_CLD\": compute_roc_auc(\"Deep_CLD\", y_val, proposed_probabilities),\n","}\n","\n","# Plot ROC curves\n","plt.figure(figsize=(10, 8))\n","for model_name, (fpr, tpr, roc_auc) in roc_data_4.items():\n","    plt.plot(fpr, tpr, label=f\"{model_name} AUC = {roc_auc:.2f}\")\n","\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlabel(\"False Positive Rate\", fontsize=14)\n","plt.ylabel(\"True Positive Rate\", fontsize=14)\n","plt.legend(fontsize=12)\n","plt.grid(alpha=0.3)\n","plt.title(\"ROC Curve Comparison\", fontsize=16)\n","plt.show()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM6Ssn25bFOk03An/fW530y","mount_file_id":"10H-cbmen8btJTBC11S6c4bY566XbQ4LY","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}