{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOD4lZ6rLnN6w+fZEOpxcZf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"96OKzkOllt3X"},"outputs":[],"source":["!pip install optuna"]},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"ijknEZZemT_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install scikeras"],"metadata":{"id":"8zMV1NXqmUCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import optuna\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from scikeras.wrappers import KerasClassifier # Import path for KerasClassifier\n","\n","# Load datasets\n","main_p = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/positive_main_tpc.csv\")\n","main_n = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/negative_main_tpc (1).csv\")\n","validation_p = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/positive_validation_tpc.csv\")\n","validation_n = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/negative_validation_tpc.csv\")\n","\n","\n","# Combine positive and negative samples\n","X_train = pd.concat([main_p, main_n])\n","y_train = np.concatenate([np.ones(len(main_p)), np.zeros(len(main_n))])\n","\n","# Define cross-validation\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Function to create a neural network model\n","def create_nn(num_units, dropout_rate, learning_rate, input_shape):\n","    model = Sequential([\n","        Dense(num_units, activation='relu', input_shape=input_shape),\n","        Dropout(dropout_rate),\n","        Dense(num_units, activation='relu'),\n","        Dropout(dropout_rate),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Model definitions and parameter grids for RandomizedSearchCV\n","models = {\n","    \"SVM\": SVC(),\n","    \"Decision Tree\": DecisionTreeClassifier(),\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"Logistic Regression\": LogisticRegression(),\n","    \"k-NN\": KNeighborsClassifier(),\n","    \"Naive Bayes\": GaussianNB(),\n","    \"Gradient Boosting\": GradientBoostingClassifier(),\n","    \"XGBoost\": XGBClassifier(),\n","    \"LightGBM\": LGBMClassifier(),\n","    \"CatBoost\": CatBoostClassifier(verbose=0),\n","    \"AdaBoost\": AdaBoostClassifier(),\n","    \"Neural Network\": KerasClassifier(\n","        model=create_nn,\n","        num_units=64,\n","        dropout_rate=0.2,\n","        learning_rate=0.001,\n","        input_shape=(X_train.shape[1],),\n","        epochs=5,\n","        batch_size=32,\n","        verbose=0\n","    )\n","}\n","\n","# Parameter grids for each model\n","param_grids = {\n","    \"SVM\": {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']},\n","    \"Decision Tree\": {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n","    \"Random Forest\": {'n_estimators': [100, 200, 500], 'max_depth': [10, 20, None], 'max_features': ['auto', 'sqrt'], 'min_samples_split': [2, 5, 10]},\n","    \"Logistic Regression\": {'C': [0.1, 1, 10, 100], 'solver': ['liblinear', 'saga'], 'penalty': ['l2']},\n","    \"k-NN\": {'n_neighbors': [3, 5, 11, 19], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n","    \"Naive Bayes\": {'var_smoothing': np.logspace(-9, -1, 10)},\n","    \"Gradient Boosting\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n","    \"XGBoost\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n","    \"LightGBM\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [10, 20, -1]},\n","    \"CatBoost\": {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.1, 0.2], 'iterations': [100, 200]},\n","    \"AdaBoost\": {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]},\n","    \"Neural Network\": {\n","        'model__num_units': [32, 64, 128],\n","        'model__dropout_rate': [0.1, 0.2, 0.3],\n","        'model__learning_rate': [0.001, 0.01, 0.1]\n","    }\n","}\n","\n","# Results storage\n","best_params = {}\n","best_scores = []\n","\n","# Loop through models and apply random search\n","for model_name, model in models.items():\n","    print(f\"Performing RandomizedSearchCV for {model_name}...\")\n","    param_grid = param_grids[model_name]\n","\n","    # Perform randomized search\n","    random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n","    random_search.fit(X_train, y_train)\n","\n","    # Store best parameters and score\n","    best_params[model_name] = random_search.best_params_\n","    best_scores.append(random_search.best_score_)\n","\n","# Display results in a DataFrame\n","results_df = pd.DataFrame({\n","    'Model': list(models.keys()),\n","    'Best Score': best_scores,\n","    'Best Parameters': [best_params[model] for model in models]\n","})\n","\n","print(results_df)\n"],"metadata":{"id":"zr0fOvh4mUFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Storage for predictions and target column\n","probability_datasets = pd.DataFrame(y_train, columns=['Target'])\n","\n","# Loop through models, perform random search, and save probabilities\n","for model_name, model in models.items():\n","    print(f\"Performing RandomizedSearchCV for {model_name}...\")\n","    param_grid = param_grids[model_name]\n","\n","    # Perform randomized search\n","    random_search = RandomizedSearchCV(model,\n","                                       param_grid,\n","                                       n_iter=10,\n","                                       cv=cv,\n","                                       scoring='accuracy',\n","                                       n_jobs=-1,\n","                                       random_state=42)\n","\n","    random_search.fit(X_train, y_train)\n","\n","    # Store best parameters and score\n","    best_params[model_name] = random_search.best_params_\n","    best_scores.append(random_search.best_score_)\n","\n","\n","\n","    # Get probability predictions (if supported)\n","    if hasattr(random_search.best_estimator_, \"predict_proba\"):\n","        probabilities = random_search.best_estimator_.predict_proba(X_train)[:, 1]  # Probability for the positive class\n","        probability_datasets[f\"{model_name}_Probabilities\"] = probabilities\n","    else:\n","        # Fallback if probability prediction isn't supported\n","        predictions = random_search.best_estimator_.predict(X_train)\n","        probability_datasets[f\"{model_name}_Predictions\"] = predictions\n","\n","\n","\n","# Display final dataset with probabilities\n","print(probability_datasets.head())\n","\n","# Save the probability dataset to a CSV file\n","probability_datasets.to_csv(\" TPC in Randomsearch.csv\", index=False)\n","print(\"Probability dataset saved to 'TPC in Randomsearch.csv'.\")\n"],"metadata":{"id":"q1bBrsWNma5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OWRMGyv4ma8V"},"execution_count":null,"outputs":[]}]}