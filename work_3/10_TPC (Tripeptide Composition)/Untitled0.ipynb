{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8bVZcQGUYtmxfKU37Xl1Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wO8Dhz4Rlx0a"},"outputs":[],"source":["!pip install scikeras"]},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"RNKaLQQ9mnPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from scikeras.wrappers import KerasClassifier\n","\n","# Load datasets\n","main_p = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/positive_main_tpc.csv\")\n","main_n = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/negative_main_tpc (1).csv\")\n","validation_p = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/positive_validation_tpc.csv\")\n","validation_n = pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/work_3/10_TPC (Tripeptide Composition)/negative_validation_tpc.csv\")\n","\n","\n","# Combine positive and negative samples\n","X_train = pd.concat([main_p, main_n])\n","y_train = np.concatenate([np.ones(len(main_p)), np.zeros(len(main_n))])\n","\n","# Define cross-validation\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Function to create a neural network model\n","def create_nn(num_units, dropout_rate, learning_rate, input_shape):\n","    model = Sequential([\n","        Dense(num_units, activation='relu', input_shape=input_shape),\n","        Dropout(dropout_rate),\n","        Dense(num_units, activation='relu'),\n","        Dropout(dropout_rate),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Model definitions and parameter grids for GridSearchCV\n","models = {\n","    \"SVM\": SVC(),\n","    \"Decision Tree\": DecisionTreeClassifier(),\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"Logistic Regression\": LogisticRegression(),\n","    \"k-NN\": KNeighborsClassifier(),\n","    \"Naive Bayes\": GaussianNB(),\n","    \"Gradient Boosting\": GradientBoostingClassifier(),\n","    \"XGBoost\": XGBClassifier(),\n","    \"LightGBM\": LGBMClassifier(),\n","    \"CatBoost\": CatBoostClassifier(verbose=0),\n","    \"AdaBoost\": AdaBoostClassifier(),\n","    \"Neural Network\": KerasClassifier(\n","        model=create_nn,\n","        num_units=64,\n","        dropout_rate=0.2,\n","        learning_rate=0.001,\n","        input_shape=(X_train.shape[1],),\n","        epochs=5,\n","        batch_size=32,\n","        verbose=0\n","    )\n","}\n","\n","# Parameter grids for each model\n","param_grids = {\n","    \"SVM\": {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']},\n","    \"Decision Tree\": {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n","    \"Random Forest\": {'n_estimators': [100, 200, 500], 'max_depth': [10, 20, None], 'max_features': ['auto', 'sqrt'], 'min_samples_split': [2, 5, 10]},\n","    \"Logistic Regression\": {'C': [0.1, 1, 10, 100], 'solver': ['liblinear', 'saga'], 'penalty': ['l2']},\n","    \"k-NN\": {'n_neighbors': [3, 5, 11, 19], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n","    \"Naive Bayes\": {'var_smoothing': np.logspace(-9, -1, 10)},\n","    \"Gradient Boosting\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n","    \"XGBoost\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]},\n","    \"LightGBM\": {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [10, 20, -1]},\n","    \"CatBoost\": {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.1, 0.2], 'iterations': [100, 200]},\n","    \"AdaBoost\": {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]},\n","    \"Neural Network\": {\n","        'model__num_units': [32, 64, 128],\n","        'model__dropout_rate': [0.1, 0.2, 0.3],\n","        'model__learning_rate': [0.001, 0.01, 0.1]\n","    }\n","}\n","\n","# Results storage\n","best_params = {}\n","best_scores = []\n","\n","# Loop through models and apply grid search\n","for model_name, model in models.items():\n","    print(f\"Performing GridSearchCV for {model_name}...\")\n","    param_grid = param_grids[model_name]\n","\n","    # Perform grid search\n","    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(X_train, y_train)\n","\n","    # Store best parameters and score\n","    best_params[model_name] = grid_search.best_params_\n","    best_scores.append(grid_search.best_score_)\n","\n","# Display results in a DataFrame\n","results_df = pd.DataFrame({\n","    'Model': list(models.keys()),\n","    'Best Score': best_scores,\n","    'Best Parameters': [best_params[model] for model in models]\n","})\n","\n","print(results_df)\n"],"metadata":{"id":"9Ento0QKmr_i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare the final dataset with probabilities and target\n","all_probabilities = []\n","all_targets = []\n","\n","# Loop through models and apply grid search\n","for model_name, model in models.items():\n","    print(f\"Performing GridSearchCV for {model_name}...\")\n","\n","    # Special handling for SVC: enable probability estimation\n","    if model_name == \"SVM\":\n","        model.probability = True  # Enable probability for SVC\n","\n","    # Get the parameter grid for the current model\n","    param_grid = param_grids[model_name]\n","\n","    # Perform grid search\n","    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(X_train, y_train)\n","\n","    # Store best parameters and score\n","    best_params[model_name] = grid_search.best_params_\n","    best_scores.append(grid_search.best_score_)\n","\n","    # Predict probabilities using the best estimator\n","    best_model = grid_search.best_estimator_\n","    if hasattr(best_model, \"predict_proba\"):\n","        probabilities = best_model.predict_proba(X_train)[:, 1]  # Positive class probabilities\n","    else:\n","        # Fallback for models without predict_proba (e.g., SVM with linear kernel)\n","        probabilities = best_model.decision_function(X_train)\n","        probabilities = (probabilities - probabilities.min()) / (probabilities.max() - probabilities.min())\n","\n","    # Append probabilities and targets for this model\n","    all_probabilities.append(probabilities)\n","    all_targets.append(y_train)\n","\n","    # Combine probabilities, features, and target into a DataFrame\n","    model_data = pd.DataFrame(X_train, columns=main_p.columns)  # Ensure column consistency\n","    model_data[f\"{model_name}_probability\"] = probabilities\n","    model_data['target'] = y_train\n","\n","    # Save to CSV\n","    output_path = f\"/content/{model_name}_probabilities.csv\"\n","    model_data.to_csv(output_path, index=False)\n","    print(f\"Saved probabilities for {model_name} to {output_path}\")\n","\n","# Combine all model probabilities into a single DataFrame (optional)\n","final_dataset = pd.DataFrame({'target': y_train})\n","for idx, model_name in enumerate(models.keys()):\n","    final_dataset[f\"{model_name}_probability\"] = all_probabilities[idx]\n","\n","# Save the combined dataset\n","final_output_path = \"/content/TPC_GridSearchCV.csv\"\n","final_dataset.to_csv(final_output_path, index=False)\n","print(f\"Saved combined dataset to {final_output_path}\")\n"],"metadata":{"id":"c260DwgUmszC"},"execution_count":null,"outputs":[]}]}