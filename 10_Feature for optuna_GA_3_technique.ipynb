{"cells":[{"cell_type":"markdown","metadata":{"id":"AqiY0Yz1i7dR"},"source":["CPFV (Combined Probability and Class Feature Vector)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55131,"status":"ok","timestamp":1744739410190,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"g3AOuFS1vAva","outputId":"dbdaf8eb-5946-4eab-cd5a-8508fbf1999c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4216,"status":"ok","timestamp":1744739451631,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"SPr2XnlIDzZ_","outputId":"904c28d1-4ae1-4c74-d2d9-e8d6715a4a44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/Dataset Marge CPFV.csv\n"]}],"source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"ACC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_AAC.csv\",\n","    \"CTDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTDC.csv\",\n","    \"CTD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTD.csv\",\n","    \"GDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_GDC.csv\",\n","    \"PAAC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_PAAC.csv\",\n","    \"PCP\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_PCP.csv\",\n","    \"TPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_TPC.csv\",\n","    \"CTDT\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTDT.csv\",\n","    \"DPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_DPC.csv\",\n","    \"CTDD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTDD.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/Dataset Marge CPFV.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1744739471949,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"DZTZzk5_i8NL","outputId":"27db2737-8bc9-46c0-c4d1-90de254ddef5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the merged dataset: (300, 240)\n"]}],"source":["# Check the shape of the merged dataset\n","print(\"Shape of the merged dataset:\", combined_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnGPryNRjjkP"},"outputs":[],"source":["df=pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/Optuna_Dataset Marge CPFV.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1744739654481,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"Zz6MlMtIjlUu","outputId":"5223957a-3e04-41ef-c0ed-09324ce774bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 241)"]},"metadata":{},"execution_count":7}],"source":["df.shape"]},{"cell_type":"code","source":["\n","##proposed moded apply for CPFV\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/Optuna_Dataset Marge CPFV.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional: Uncomment if needed to verify column names)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'True_Label' column for binary classification\n","if 'True_Label' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'True_Label' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values  # Features\n","y = data['True_Label'].values                 # Labels\n","\n","# Split data into training and validation sets (70-30 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# Stacked Conv1D layers with BatchNormalization and Dropout\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","# LSTM layer for sequential dependencies\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","\n","# Dense Layers with Dropout\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n","\n","# Compile the Model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n","\n","# Evaluate the model on the validation data\n","val_probs = model.predict(X_val)\n","val_predictions = (val_probs > 0.5).astype(int)\n","\n","# Compute metrics\n","accuracy = accuracy_score(y_val, val_predictions)\n","conf_matrix = confusion_matrix(y_val, val_predictions)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # Recall\n","specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # True Negative Rate\n","mcc = matthews_corrcoef(y_val, val_predictions)\n","kappa = cohen_kappa_score(y_val, val_predictions)\n","auc = roc_auc_score(y_val, val_probs)\n","\n","# Print evaluation metrics\n","print(\"\\nValidation Accuracy:\", accuracy)\n","print(\"Sensitivity (Recall):\", sensitivity)\n","print(\"Specificity:\", specificity)\n","print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n","print(\"Cohen's Kappa:\", kappa)\n","print(\"Area Under Curve (AUC):\", auc)\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7LCd5fvevcvn","executionInfo":{"status":"ok","timestamp":1744742493378,"user_tz":-360,"elapsed":188155,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"132a6e93-ce37-4fd1-8398-dbd53a3b976e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_Class_ACC', 'SVM_Prob_ACC', 'Decision Tree_Class_ACC',\n","       'Decision Tree_Prob_ACC', 'Random Forest_Class_ACC',\n","       'Random Forest_Prob_ACC', 'Logistic Regression_Class_ACC',\n","       'Logistic Regression_Prob_ACC', 'k-NN_Class_ACC', 'k-NN_Prob_ACC',\n","       ...\n","       'XGBoost_Prob_CTDD', 'LightGBM_Class_CTDD', 'LightGBM_Prob_CTDD',\n","       'AdaBoost_Class_CTDD', 'AdaBoost_Prob_CTDD',\n","       'Neural Network (MLPClassifier)_Class_CTDD',\n","       'Neural Network (MLPClassifier)_Prob_CTDD',\n","       'Multilayer Perceptron (Custom MLP)_Class_CTDD',\n","       'Multilayer Perceptron (Custom MLP)_Prob_CTDD', 'True_Label'],\n","      dtype='object', length=241)\n","   SVM_Class_ACC  SVM_Prob_ACC  Decision Tree_Class_ACC  \\\n","0              1      0.899958                        1   \n","1              1      0.947470                        1   \n","2              0      0.156467                        0   \n","3              1      0.623367                        0   \n","4              1      0.551079                        0   \n","\n","   Decision Tree_Prob_ACC  Random Forest_Class_ACC  Random Forest_Prob_ACC  \\\n","0                 0.91200                        1                0.745340   \n","1                 0.99537                        1                0.967689   \n","2                 0.00000                        0                0.193067   \n","3                 0.00000                        1                0.631910   \n","4                 0.00000                        0                0.343221   \n","\n","   Logistic Regression_Class_ACC  Logistic Regression_Prob_ACC  \\\n","0                              1                      0.756727   \n","1                              1                      0.990390   \n","2                              0                      0.337374   \n","3                              1                      0.561091   \n","4                              0                      0.414065   \n","\n","   k-NN_Class_ACC  k-NN_Prob_ACC  ...  XGBoost_Prob_CTDD  LightGBM_Class_CTDD  \\\n","0               1            1.0  ...           0.847744                    1   \n","1               1            1.0  ...           0.974249                    1   \n","2               1            1.0  ...           0.364496                    1   \n","3               1            0.6  ...           0.915559                    1   \n","4               0            0.4  ...           0.412864                    0   \n","\n","   LightGBM_Prob_CTDD  AdaBoost_Class_CTDD  AdaBoost_Prob_CTDD  \\\n","0            0.979110                    0            0.424976   \n","1            0.994123                    1            0.825494   \n","2            0.582278                    0            0.424976   \n","3            0.991126                    1            0.535839   \n","4            0.318813                    0            0.424976   \n","\n","   Neural Network (MLPClassifier)_Class_CTDD  \\\n","0                                          1   \n","1                                          1   \n","2                                          1   \n","3                                          1   \n","4                                          0   \n","\n","   Neural Network (MLPClassifier)_Prob_CTDD  \\\n","0                                  0.999999   \n","1                                  1.000000   \n","2                                  0.996296   \n","3                                  0.728157   \n","4                                  0.000268   \n","\n","   Multilayer Perceptron (Custom MLP)_Class_CTDD  \\\n","0                                              1   \n","1                                              1   \n","2                                              1   \n","3                                              1   \n","4                                              0   \n","\n","   Multilayer Perceptron (Custom MLP)_Prob_CTDD  True_Label  \n","0                                      0.999999           1  \n","1                                      0.999992           1  \n","2                                      0.986393           1  \n","3                                      0.732057           1  \n","4                                      0.000223           1  \n","\n","[5 rows x 241 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_7\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m119\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m82,176\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,129\u001b[0m (875.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,129</span> (875.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,233\u001b[0m (872.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,233</span> (872.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 275ms/step - accuracy: 0.5059 - loss: 12.0306 - val_accuracy: 0.9222 - val_loss: 0.6883\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.6851 - loss: 0.9058 - val_accuracy: 0.5000 - val_loss: 0.6828\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - accuracy: 0.8136 - loss: 0.3347 - val_accuracy: 0.6111 - val_loss: 0.6772\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 323ms/step - accuracy: 0.8674 - loss: 0.3855 - val_accuracy: 0.8556 - val_loss: 0.6728\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.8422 - loss: 0.3918 - val_accuracy: 0.7889 - val_loss: 0.6694\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9111 - loss: 0.3227 - val_accuracy: 0.6444 - val_loss: 0.6669\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.9004 - loss: 0.2675 - val_accuracy: 0.6000 - val_loss: 0.6606\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.9002 - loss: 0.6790 - val_accuracy: 0.5444 - val_loss: 0.6606\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.8221 - loss: 0.6976 - val_accuracy: 0.8889 - val_loss: 0.6498\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 182ms/step - accuracy: 0.9013 - loss: 0.4623 - val_accuracy: 0.9111 - val_loss: 0.6246\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step - accuracy: 0.8904 - loss: 0.7322 - val_accuracy: 0.9000 - val_loss: 0.6144\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step - accuracy: 0.8657 - loss: 1.3515 - val_accuracy: 0.9000 - val_loss: 0.5766\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.8592 - loss: 0.4897 - val_accuracy: 0.9000 - val_loss: 0.5450\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.8888 - loss: 0.6846 - val_accuracy: 0.9111 - val_loss: 0.5323\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.8409 - loss: 0.8002 - val_accuracy: 0.9000 - val_loss: 0.4513\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.8860 - loss: 0.8555 - val_accuracy: 0.9111 - val_loss: 0.3673\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.8336 - loss: 1.0363 - val_accuracy: 0.9111 - val_loss: 0.2991\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.8765 - loss: 0.8112 - val_accuracy: 0.9111 - val_loss: 0.2733\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.8558 - loss: 1.4179 - val_accuracy: 0.9111 - val_loss: 0.2462\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.8436 - loss: 1.0641 - val_accuracy: 0.9111 - val_loss: 0.2621\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.8087 - loss: 1.1318 - val_accuracy: 0.9000 - val_loss: 0.3253\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 282ms/step - accuracy: 0.8631 - loss: 0.5266 - val_accuracy: 0.9111 - val_loss: 0.2870\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.8755 - loss: 0.4656 - val_accuracy: 0.9111 - val_loss: 0.2934\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8341 - loss: 1.5546 - val_accuracy: 0.9000 - val_loss: 0.3827\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.8944 - loss: 1.3790 - val_accuracy: 0.9222 - val_loss: 0.4173\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.8699 - loss: 2.6777 - val_accuracy: 0.9111 - val_loss: 0.4746\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - accuracy: 0.8490 - loss: 1.4921 - val_accuracy: 0.9000 - val_loss: 0.8971\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.8032 - loss: 2.3935 - val_accuracy: 0.8778 - val_loss: 1.1483\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - accuracy: 0.7855 - loss: 4.4396 - val_accuracy: 0.8889 - val_loss: 0.5474\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 299ms/step - accuracy: 0.7435 - loss: 3.0992 - val_accuracy: 0.9000 - val_loss: 0.4935\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.8090 - loss: 11.7454 - val_accuracy: 0.8111 - val_loss: 1.5057\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - accuracy: 0.6596 - loss: 12.0018 - val_accuracy: 0.6889 - val_loss: 1.2663\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.7020 - loss: 10.0987 - val_accuracy: 0.9000 - val_loss: 5.5352\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.7674 - loss: 4.3386 - val_accuracy: 0.9111 - val_loss: 1.8288\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.7688 - loss: 17.5508 - val_accuracy: 0.8556 - val_loss: 1.4151\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8871 - loss: 6.0102 - val_accuracy: 0.8333 - val_loss: 3.8082\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 285ms/step - accuracy: 0.8521 - loss: 11.6559 - val_accuracy: 0.8778 - val_loss: 3.9406\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 314ms/step - accuracy: 0.9069 - loss: 4.1248 - val_accuracy: 0.9000 - val_loss: 1.1901\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.9091 - loss: 3.5527 - val_accuracy: 0.8778 - val_loss: 0.9465\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - accuracy: 0.8344 - loss: 22.1774 - val_accuracy: 0.9222 - val_loss: 0.4584\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.8536 - loss: 4.9836 - val_accuracy: 0.9222 - val_loss: 0.6409\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.8585 - loss: 9.9387 - val_accuracy: 0.9111 - val_loss: 0.5860\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.8590 - loss: 2.2476 - val_accuracy: 0.9222 - val_loss: 0.4457\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.8456 - loss: 5.0387 - val_accuracy: 0.9333 - val_loss: 0.2957\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.8422 - loss: 2.4019 - val_accuracy: 0.8889 - val_loss: 15.5658\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.8741 - loss: 22.9556 - val_accuracy: 0.8667 - val_loss: 0.4703\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - accuracy: 0.8617 - loss: 9.9333 - val_accuracy: 0.9000 - val_loss: 0.3170\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.8692 - loss: 2.2312 - val_accuracy: 0.9000 - val_loss: 0.3350\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.8815 - loss: 0.8389 - val_accuracy: 0.8778 - val_loss: 0.3498\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.8091 - loss: 0.4749 - val_accuracy: 0.8778 - val_loss: 0.3609\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.8320 - loss: 0.4617 - val_accuracy: 0.8889 - val_loss: 0.3538\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.8797 - loss: 0.3492 - val_accuracy: 0.8889 - val_loss: 0.3635\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8699 - loss: 0.6814 - val_accuracy: 0.8667 - val_loss: 0.3618\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8552 - loss: 0.2895 - val_accuracy: 0.8778 - val_loss: 0.3531\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 0.8724 - loss: 0.3517 - val_accuracy: 0.8889 - val_loss: 0.3446\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - accuracy: 0.8540 - loss: 0.5060 - val_accuracy: 0.8889 - val_loss: 0.3400\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.8785 - loss: 0.2863 - val_accuracy: 0.9111 - val_loss: 0.3333\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - accuracy: 0.8834 - loss: 0.5643 - val_accuracy: 0.9111 - val_loss: 0.3273\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.8656 - loss: 0.2798 - val_accuracy: 0.9111 - val_loss: 0.3198\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.8865 - loss: 0.3155 - val_accuracy: 0.9111 - val_loss: 0.3192\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.8667 - loss: 0.3237 - val_accuracy: 0.9000 - val_loss: 0.3157\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8462 - loss: 0.2659 - val_accuracy: 0.9000 - val_loss: 0.3097\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8787 - loss: 0.3535 - val_accuracy: 0.8889 - val_loss: 0.3042\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 291ms/step - accuracy: 0.8344 - loss: 0.3121 - val_accuracy: 0.8889 - val_loss: 0.3035\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step - accuracy: 0.8725 - loss: 0.3216 - val_accuracy: 0.9000 - val_loss: 0.3023\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.8904 - loss: 0.2951 - val_accuracy: 0.9000 - val_loss: 0.3124\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.9060 - loss: 0.2661 - val_accuracy: 0.9000 - val_loss: 0.3100\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8507 - loss: 0.5332 - val_accuracy: 0.8889 - val_loss: 0.3116\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9238 - loss: 0.3182 - val_accuracy: 0.8889 - val_loss: 0.3107\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.8849 - loss: 0.2586 - val_accuracy: 0.8889 - val_loss: 0.3100\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.8902 - loss: 0.3137 - val_accuracy: 0.8889 - val_loss: 0.3087\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 0.8704 - loss: 0.3106 - val_accuracy: 0.8778 - val_loss: 0.3302\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - accuracy: 0.8521 - loss: 0.2855 - val_accuracy: 0.8778 - val_loss: 0.3449\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.8695 - loss: 0.3516 - val_accuracy: 0.8778 - val_loss: 0.3346\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.8564 - loss: 0.3305 - val_accuracy: 0.8889 - val_loss: 0.3291\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8402 - loss: 0.3065 - val_accuracy: 0.8889 - val_loss: 0.3301\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.8905 - loss: 0.2577 - val_accuracy: 0.8889 - val_loss: 0.3193\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8340 - loss: 0.3217 - val_accuracy: 0.8889 - val_loss: 0.3221\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.8896 - loss: 0.3265 - val_accuracy: 0.8889 - val_loss: 0.3137\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.9014 - loss: 0.2502 - val_accuracy: 0.8889 - val_loss: 0.3077\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - accuracy: 0.8863 - loss: 0.3354 - val_accuracy: 0.8889 - val_loss: 0.3176\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 282ms/step - accuracy: 0.8833 - loss: 0.2414 - val_accuracy: 0.8889 - val_loss: 0.3095\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - accuracy: 0.9260 - loss: 0.2777 - val_accuracy: 0.9000 - val_loss: 0.3200\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8939 - loss: 0.3190 - val_accuracy: 0.9000 - val_loss: 0.3125\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - accuracy: 0.8545 - loss: 0.3143 - val_accuracy: 0.9000 - val_loss: 0.2968\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.8976 - loss: 0.2456 - val_accuracy: 0.9000 - val_loss: 0.3127\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.9128 - loss: 0.2562 - val_accuracy: 0.9000 - val_loss: 0.2970\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 333ms/step - accuracy: 0.8396 - loss: 0.2813 - val_accuracy: 0.9000 - val_loss: 0.2928\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.8847 - loss: 0.2689 - val_accuracy: 0.9000 - val_loss: 0.2932\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.8472 - loss: 0.3534 - val_accuracy: 0.9000 - val_loss: 0.2946\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.8692 - loss: 0.3211 - val_accuracy: 0.9000 - val_loss: 0.2915\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 182ms/step - accuracy: 0.9079 - loss: 0.2417 - val_accuracy: 0.9000 - val_loss: 0.2857\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - accuracy: 0.9116 - loss: 0.2398 - val_accuracy: 0.9000 - val_loss: 0.2822\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 327ms/step - accuracy: 0.8855 - loss: 0.3221 - val_accuracy: 0.9000 - val_loss: 0.2784\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.8882 - loss: 0.2736 - val_accuracy: 0.9000 - val_loss: 0.2904\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.9027 - loss: 0.2635 - val_accuracy: 0.9000 - val_loss: 0.2782\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9125 - loss: 0.2564 - val_accuracy: 0.9000 - val_loss: 0.2730\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 180ms/step - accuracy: 0.8719 - loss: 0.3006 - val_accuracy: 0.9000 - val_loss: 0.2686\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.9110 - loss: 0.2692 - val_accuracy: 0.9000 - val_loss: 0.2635\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 182ms/step - accuracy: 0.8919 - loss: 0.2493 - val_accuracy: 0.9000 - val_loss: 0.2610\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step\n","\n","Validation Accuracy: 0.9\n","Sensitivity (Recall): 0.9111111111111111\n","Specificity: 0.8888888888888888\n","Matthews Correlation Coefficient (MCC): 0.8001976040538966\n","Cohen's Kappa: 0.8\n","Area Under Curve (AUC): 0.9565432098765432\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.91      0.89      0.90        45\n","           1       0.89      0.91      0.90        45\n","\n","    accuracy                           0.90        90\n","   macro avg       0.90      0.90      0.90        90\n","weighted avg       0.90      0.90      0.90        90\n","\n"]}]},{"cell_type":"code","source":["#CROSS VALIDATION FOR cpfv\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","\n","# Load dataset\n","dataset_path = \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/Optuna_Dataset Marge CPFV.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values\n","y = data['True_Label'].values\n","\n","# Initialize StratifiedKFold\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Track metrics across folds\n","metrics = {\n","    \"accuracy\": [],\n","    \"sensitivity\": [],\n","    \"specificity\": [],\n","    \"mcc\": [],\n","    \"kappa\": [],\n","    \"auc\": []\n","}\n","\n","fold = 1\n","for train_idx, val_idx in kf.split(X, y):\n","    print(f\"\\n========== Fold {fold} ==========\")\n","\n","    X_train, X_val = X[train_idx], X[val_idx]\n","    y_train, y_val = y[train_idx], y[val_idx]\n","\n","    # Normalize\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","\n","    # Reshape for Conv1D\n","    X_train = X_train[..., np.newaxis]\n","    X_val = X_val[..., np.newaxis]\n","\n","    # Build model\n","    def build_model():\n","        model = Sequential()\n","        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling1D(pool_size=2))\n","        model.add(Dropout(0.3))\n","\n","        model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.3))\n","\n","        model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling1D(pool_size=2))\n","        model.add(Dropout(0.3))\n","\n","        model.add(LSTM(64, activation='relu'))\n","\n","        model.add(Dense(128, activation='swish'))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(64, activation='swish'))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(1, activation='sigmoid'))\n","\n","        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    model = build_model()\n","\n","    # Train model\n","    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_data=(X_val, y_val))\n","\n","    # Predict\n","    val_probs = model.predict(X_val)\n","    val_preds = (val_probs > 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_val, val_preds)\n","    cm = confusion_matrix(y_val, val_preds)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    sens = tp / (tp + fn) if (tp + fn) != 0 else 0\n","    spec = tn / (tn + fp) if (tn + fp) != 0 else 0\n","    mcc = matthews_corrcoef(y_val, val_preds)\n","    kappa = cohen_kappa_score(y_val, val_preds)\n","    auc = roc_auc_score(y_val, val_probs)\n","\n","    # Print fold results\n","    print(f\"Accuracy: {acc:.4f} | Sensitivity: {sens:.4f} | Specificity: {spec:.4f} | MCC: {mcc:.4f} | Kappa: {kappa:.4f} | AUC: {auc:.4f}\")\n","    print(classification_report(y_val, val_preds))\n","\n","    # Store metrics\n","    metrics[\"accuracy\"].append(acc)\n","    metrics[\"sensitivity\"].append(sens)\n","    metrics[\"specificity\"].append(spec)\n","    metrics[\"mcc\"].append(mcc)\n","    metrics[\"kappa\"].append(kappa)\n","    metrics[\"auc\"].append(auc)\n","\n","    fold += 1\n","\n","# Average metrics\n","print(\"\\n========== Average Metrics Across 5 Folds ==========\")\n","for key, values in metrics.items():\n","    print(f\"{key.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygpMYI-t2J8W","executionInfo":{"status":"ok","timestamp":1744745205602,"user_tz":-360,"elapsed":1105246,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"293acf85-4439-4e4b-b37f-916e83f89530"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== Fold 1 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step\n","Accuracy: 0.9000 | Sensitivity: 0.9000 | Specificity: 0.9000 | MCC: 0.8000 | Kappa: 0.8000 | AUC: 0.9300\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.90      0.90        30\n","           1       0.90      0.90      0.90        30\n","\n","    accuracy                           0.90        60\n","   macro avg       0.90      0.90      0.90        60\n","weighted avg       0.90      0.90      0.90        60\n","\n","\n","========== Fold 2 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step\n","Accuracy: 0.9000 | Sensitivity: 1.0000 | Specificity: 0.8000 | MCC: 0.8165 | Kappa: 0.8000 | AUC: 0.9339\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.80      0.89        30\n","           1       0.83      1.00      0.91        30\n","\n","    accuracy                           0.90        60\n","   macro avg       0.92      0.90      0.90        60\n","weighted avg       0.92      0.90      0.90        60\n","\n","\n","========== Fold 3 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step\n","Accuracy: 0.5000 | Sensitivity: 1.0000 | Specificity: 0.0000 | MCC: 0.0000 | Kappa: 0.0000 | AUC: 0.7633\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        30\n","           1       0.50      1.00      0.67        30\n","\n","    accuracy                           0.50        60\n","   macro avg       0.25      0.50      0.33        60\n","weighted avg       0.25      0.50      0.33        60\n","\n","\n","========== Fold 4 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step\n","Accuracy: 0.5000 | Sensitivity: 0.0000 | Specificity: 1.0000 | MCC: 0.0000 | Kappa: 0.0000 | AUC: 0.5000\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67        30\n","           1       0.00      0.00      0.00        30\n","\n","    accuracy                           0.50        60\n","   macro avg       0.25      0.50      0.33        60\n","weighted avg       0.25      0.50      0.33        60\n","\n","\n","========== Fold 5 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step\n","Accuracy: 0.8667 | Sensitivity: 0.8000 | Specificity: 0.9333 | MCC: 0.7399 | Kappa: 0.7333 | AUC: 0.8600\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.93      0.88        30\n","           1       0.92      0.80      0.86        30\n","\n","    accuracy                           0.87        60\n","   macro avg       0.87      0.87      0.87        60\n","weighted avg       0.87      0.87      0.87        60\n","\n","\n","========== Average Metrics Across 5 Folds ==========\n","Accuracy: 0.7333 ± 0.1909\n","Sensitivity: 0.7400 ± 0.3774\n","Specificity: 0.7267 ± 0.3690\n","Mcc: 0.4713 ± 0.3856\n","Kappa: 0.4667 ± 0.3818\n","Auc: 0.7974 ± 0.1611\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3224,"status":"ok","timestamp":1744740381828,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"vxJlB5rJtC7x","outputId":"cfcff297-4d9c-4e69-da8f-613762c8c314"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting deap\n","  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n","Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: deap\n","Successfully installed deap-1.4.2\n"]}],"source":["!pip install deap"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228204,"status":"ok","timestamp":1744740619714,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"BzUnaXxSyMhe","outputId":"00f081e4-09d9-423c-faf1-a31b1b03a603"},"outputs":[{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t50    \n","1  \t39    \n","2  \t41    \n","3  \t30    \n","4  \t44    \n","5  \t39    \n","6  \t46    \n","7  \t41    \n","8  \t35    \n","9  \t45    \n","10 \t38    \n","11 \t42    \n","12 \t35    \n","13 \t37    \n","14 \t35    \n","15 \t47    \n","16 \t45    \n","17 \t43    \n","18 \t36    \n","19 \t44    \n","20 \t37    \n","Top 10 Selected features: [0, 2, 3, 7, 6, 10, 9, 8, 15, 14]\n","Final Accuracy with top 10 selected features: 0.9\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from deap import base, creator, tools, algorithms\n","import random\n","\n","# Load the dataset\n","data_path = '/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/Optuna_Dataset Marge CPFV.csv'\n","data = pd.read_csv(data_path)\n","\n","# Assuming the last column is the target, split features and labels\n","X = data.iloc[:, :-1]  # Features\n","y = data.iloc[:, -1]   # Target\n","\n","# Encode target labels if necessary\n","if y.dtype == object or np.issubdtype(y.dtype, np.number):  # Handle both string and numeric labels\n","    le = LabelEncoder()\n","    y = le.fit_transform(y.astype(str))  # Ensure all targets are treated as strings for classification\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create the individual and fitness functions\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# Classifier to evaluate fitness\n","def evaluate(individual):\n","    selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n","    if len(selected_features) == 0:  # Prevent division by zero\n","        return 0,\n","\n","    X_train_selected = X_train.iloc[:, selected_features]\n","    X_val_selected = X_val.iloc[:, selected_features]\n","\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_train_selected, y_train)\n","    y_pred = model.predict(X_val_selected)\n","\n","    accuracy = accuracy_score(y_val, y_pred)\n","    return accuracy,\n","\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# Parameters for the Genetic Algorithm\n","population_size = 50\n","generations = 20\n","crossover_probability = 0.8\n","mutation_probability = 0.1\n","\n","# Initialize population\n","population = toolbox.population(n=population_size)\n","\n","# Run the Genetic Algorithm\n","result_population, logbook = algorithms.eaSimple(\n","    population,\n","    toolbox,\n","    cxpb=crossover_probability,\n","    mutpb=mutation_probability,\n","    ngen=generations,\n","    verbose=True\n",")\n","\n","# Find the best individual\n","best_individual = tools.selBest(result_population, k=1)[0]\n","selected_features = [i for i, bit in enumerate(best_individual) if bit == 1 and i < len(X.columns)]  # Bounds check\n","\n","# Select top 10 features based on their importance\n","if len(selected_features) > 10:\n","    feature_importances = pd.Series(best_individual).sort_values(ascending=False)\n","    selected_features = list(feature_importances.head(10).index)\n","\n","# Evaluate performance using the top 10 features\n","X_train_selected = X_train.iloc[:, selected_features]\n","X_val_selected = X_val.iloc[:, selected_features]\n","\n","final_model = RandomForestClassifier(random_state=42)\n","final_model.fit(X_train_selected, y_train)\n","final_predictions = final_model.predict(X_val_selected)\n","final_accuracy = accuracy_score(y_val, final_predictions)\n","\n","print(f\"Top 10 Selected features: {selected_features}\")\n","print(f\"Final Accuracy with top 10 selected features: {final_accuracy}\")\n","\n","# Save the top 20 selected features\n","pd.DataFrame({'Selected Features': selected_features}).to_csv('/content/CPFV_top_10_selected_features.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1744740621861,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"birrS7SaWGyk","outputId":"5b0160c0-0800-457d-f9ca-5429fb2de4f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset with top 10 features saved to: /content/CPFV_Top_10_Features.csv\n"]}],"source":["selected_feature_columns = data.columns[selected_features]\n","# Create a filtered dataset with only the selected top 20 features\n","filtered_data = data[selected_feature_columns.tolist() + [data.columns[-1]]]\n","filtered_data_path = '/content/CPFV_Top_10_Features.csv'\n","filtered_data.to_csv(filtered_data_path, index=False)\n","\n","print(f\"Filtered dataset with top 10 features saved to: {filtered_data_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfbu6xYHwXUL"},"outputs":[],"source":["data=pd.read_csv(\"/content/CPFV_Top_10_Features.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739662283861,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"3uADa3ffws27","outputId":"4308a5e5-77cb-43d9-b911-aa9cdc9b497e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 11)"]},"metadata":{},"execution_count":11}],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":41910,"status":"ok","timestamp":1744742670359,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"98sSejDtR5VD","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3204f18b-d088-4a85-a7a3-c300c0123333"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_Class_ACC', 'Decision Tree_Class_ACC', 'Decision Tree_Prob_ACC',\n","       'Logistic Regression_Prob_ACC', 'Logistic Regression_Class_ACC',\n","       'Naive Bayes_Class_ACC', 'k-NN_Prob_ACC', 'k-NN_Class_ACC',\n","       'XGBoost_Prob_ACC', 'XGBoost_Class_ACC', 'True_Label'],\n","      dtype='object')\n","Shape before processing: (300, 11)\n","   SVM_Class_ACC  Decision Tree_Class_ACC  Decision Tree_Prob_ACC  \\\n","0              1                        1                 0.91200   \n","1              1                        1                 0.99537   \n","2              0                        0                 0.00000   \n","3              1                        0                 0.00000   \n","4              1                        0                 0.00000   \n","\n","   Logistic Regression_Prob_ACC  Logistic Regression_Class_ACC  \\\n","0                      0.756727                              1   \n","1                      0.990390                              1   \n","2                      0.337374                              0   \n","3                      0.561091                              1   \n","4                      0.414065                              0   \n","\n","   Naive Bayes_Class_ACC  k-NN_Prob_ACC  k-NN_Class_ACC  XGBoost_Prob_ACC  \\\n","0                      1            1.0               1          0.887425   \n","1                      1            1.0               1          0.998865   \n","2                      0            1.0               1          0.105594   \n","3                      1            0.6               1          0.637449   \n","4                      0            0.4               0          0.421299   \n","\n","   XGBoost_Class_ACC  True_Label  \n","0                  1           1  \n","1                  1           1  \n","2                  0           1  \n","3                  1           1  \n","4                  0           1  \n","\n","Shapes after reshaping:\n","X_train shape: (210, 10, 1)\n","X_val shape: (90, 10, 1)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_8\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m166,529\u001b[0m (650.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">166,529</span> (650.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m165,633\u001b[0m (647.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,633</span> (647.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Training model...\n","Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.6734 - loss: 0.9226 - precision: 0.6605 - recall: 0.6369 - val_accuracy: 0.8667 - val_loss: 0.6623 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8681 - loss: 0.4728 - precision: 0.8647 - recall: 0.8754 - val_accuracy: 0.8667 - val_loss: 0.6576 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8712 - loss: 0.3703 - precision: 0.8507 - recall: 0.9033 - val_accuracy: 0.8667 - val_loss: 0.6573 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8380 - loss: 0.5190 - precision: 0.8527 - recall: 0.8456 - val_accuracy: 0.8778 - val_loss: 0.6507 - val_precision: 0.8864 - val_recall: 0.8667\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8611 - loss: 0.3812 - precision: 0.8413 - recall: 0.9002 - val_accuracy: 0.8889 - val_loss: 0.6417 - val_precision: 0.9070 - val_recall: 0.8667\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8536 - loss: 0.3884 - precision: 0.8321 - recall: 0.8373 - val_accuracy: 0.8667 - val_loss: 0.6325 - val_precision: 0.9024 - val_recall: 0.8222\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8678 - loss: 0.3133 - precision: 0.8139 - recall: 0.9366 - val_accuracy: 0.8667 - val_loss: 0.6239 - val_precision: 0.9231 - val_recall: 0.8000\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8588 - loss: 0.3380 - precision: 0.8305 - recall: 0.9023 - val_accuracy: 0.8111 - val_loss: 0.6179 - val_precision: 0.9118 - val_recall: 0.6889\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8530 - loss: 0.3287 - precision: 0.8348 - recall: 0.8539 - val_accuracy: 0.6778 - val_loss: 0.6143 - val_precision: 0.9444 - val_recall: 0.3778\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8815 - loss: 0.4512 - precision: 0.8618 - recall: 0.9107 - val_accuracy: 0.6222 - val_loss: 0.6118 - val_precision: 0.9231 - val_recall: 0.2667\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8872 - loss: 0.3019 - precision: 0.8745 - recall: 0.9079 - val_accuracy: 0.6222 - val_loss: 0.6047 - val_precision: 0.9231 - val_recall: 0.2667\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8862 - loss: 0.3330 - precision: 0.8593 - recall: 0.9368 - val_accuracy: 0.6889 - val_loss: 0.5992 - val_precision: 0.9474 - val_recall: 0.4000\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9010 - loss: 0.3378 - precision: 0.8870 - recall: 0.9185 - val_accuracy: 0.6778 - val_loss: 0.5999 - val_precision: 0.9444 - val_recall: 0.3778\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8623 - loss: 0.3558 - precision: 0.7955 - recall: 0.9112 - val_accuracy: 0.7556 - val_loss: 0.5944 - val_precision: 0.9259 - val_recall: 0.5556\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8996 - loss: 0.3026 - precision: 0.8717 - recall: 0.9391 - val_accuracy: 0.7778 - val_loss: 0.5906 - val_precision: 0.9310 - val_recall: 0.6000\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8892 - loss: 0.3051 - precision: 0.8480 - recall: 0.9406 - val_accuracy: 0.8111 - val_loss: 0.5879 - val_precision: 0.9118 - val_recall: 0.6889\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8764 - loss: 0.3298 - precision: 0.8449 - recall: 0.9163 - val_accuracy: 0.6778 - val_loss: 0.5865 - val_precision: 0.9000 - val_recall: 0.4000\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8598 - loss: 0.3577 - precision: 0.8604 - recall: 0.8883 - val_accuracy: 0.6000 - val_loss: 0.5912 - val_precision: 0.9091 - val_recall: 0.2222\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8930 - loss: 0.2584 - precision: 0.8780 - recall: 0.9184 - val_accuracy: 0.5889 - val_loss: 0.5872 - val_precision: 0.9000 - val_recall: 0.2000\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9134 - loss: 0.2563 - precision: 0.9071 - recall: 0.9244 - val_accuracy: 0.5889 - val_loss: 0.5848 - val_precision: 0.9000 - val_recall: 0.2000\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8914 - loss: 0.2872 - precision: 0.8930 - recall: 0.8962 - val_accuracy: 0.5889 - val_loss: 0.5828 - val_precision: 1.0000 - val_recall: 0.1778\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9286 - loss: 0.2376 - precision: 0.8985 - recall: 0.9708 - val_accuracy: 0.5889 - val_loss: 0.5786 - val_precision: 1.0000 - val_recall: 0.1778\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9067 - loss: 0.2531 - precision: 0.8699 - recall: 0.9489 - val_accuracy: 0.5333 - val_loss: 0.5797 - val_precision: 1.0000 - val_recall: 0.0667\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8770 - loss: 0.3320 - precision: 0.8448 - recall: 0.9184 - val_accuracy: 0.5222 - val_loss: 0.5858 - val_precision: 1.0000 - val_recall: 0.0444\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8830 - loss: 0.3015 - precision: 0.8723 - recall: 0.9159 - val_accuracy: 0.5111 - val_loss: 0.5949 - val_precision: 1.0000 - val_recall: 0.0222\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8781 - loss: 0.2799 - precision: 0.8467 - recall: 0.9427 - val_accuracy: 0.5333 - val_loss: 0.5877 - val_precision: 1.0000 - val_recall: 0.0667\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9058 - loss: 0.2692 - precision: 0.8925 - recall: 0.9198 - val_accuracy: 0.6000 - val_loss: 0.5728 - val_precision: 0.9091 - val_recall: 0.2222\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9267 - loss: 0.2476 - precision: 0.9433 - recall: 0.9135 - val_accuracy: 0.6889 - val_loss: 0.5635 - val_precision: 0.9048 - val_recall: 0.4222\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8947 - loss: 0.2392 - precision: 0.8829 - recall: 0.9196 - val_accuracy: 0.7556 - val_loss: 0.5567 - val_precision: 0.8966 - val_recall: 0.5778\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8826 - loss: 0.2601 - precision: 0.8592 - recall: 0.8936 - val_accuracy: 0.8333 - val_loss: 0.5543 - val_precision: 0.9167 - val_recall: 0.7333\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9340 - loss: 0.2678 - precision: 0.9206 - recall: 0.9549 - val_accuracy: 0.8667 - val_loss: 0.5494 - val_precision: 0.9231 - val_recall: 0.8000\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9107 - loss: 0.2606 - precision: 0.8746 - recall: 0.9344 - val_accuracy: 0.8778 - val_loss: 0.5383 - val_precision: 0.9250 - val_recall: 0.8222\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9022 - loss: 0.2594 - precision: 0.9027 - recall: 0.9092 - val_accuracy: 0.8889 - val_loss: 0.5210 - val_precision: 0.9070 - val_recall: 0.8667\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8698 - loss: 0.2714 - precision: 0.8327 - recall: 0.9258 - val_accuracy: 0.8778 - val_loss: 0.5166 - val_precision: 0.9048 - val_recall: 0.8444\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8817 - loss: 0.3304 - precision: 0.8977 - recall: 0.8789 - val_accuracy: 0.8889 - val_loss: 0.5095 - val_precision: 0.9070 - val_recall: 0.8667\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9042 - loss: 0.2231 - precision: 0.8545 - recall: 0.9593 - val_accuracy: 0.8889 - val_loss: 0.5028 - val_precision: 0.9070 - val_recall: 0.8667\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9193 - loss: 0.1903 - precision: 0.9058 - recall: 0.9415 - val_accuracy: 0.8444 - val_loss: 0.5086 - val_precision: 0.8974 - val_recall: 0.7778\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9076 - loss: 0.2414 - precision: 0.8794 - recall: 0.9337 - val_accuracy: 0.8333 - val_loss: 0.5165 - val_precision: 0.8750 - val_recall: 0.7778\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9147 - loss: 0.2078 - precision: 0.9007 - recall: 0.9401 - val_accuracy: 0.8222 - val_loss: 0.5160 - val_precision: 0.8537 - val_recall: 0.7778\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9109 - loss: 0.2301 - precision: 0.9126 - recall: 0.9181 - val_accuracy: 0.8333 - val_loss: 0.5052 - val_precision: 0.8571 - val_recall: 0.8000\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9212 - loss: 0.1959 - precision: 0.9346 - recall: 0.8969 - val_accuracy: 0.8667 - val_loss: 0.4894 - val_precision: 0.9024 - val_recall: 0.8222\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8801 - loss: 0.2626 - precision: 0.8728 - recall: 0.8889 - val_accuracy: 0.8778 - val_loss: 0.4860 - val_precision: 0.9048 - val_recall: 0.8444\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8903 - loss: 0.2467 - precision: 0.8923 - recall: 0.8888 - val_accuracy: 0.8778 - val_loss: 0.4851 - val_precision: 0.9048 - val_recall: 0.8444\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9191 - loss: 0.2072 - precision: 0.9139 - recall: 0.9296 - val_accuracy: 0.8889 - val_loss: 0.4672 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9159 - loss: 0.1879 - precision: 0.8986 - recall: 0.9317 - val_accuracy: 0.8889 - val_loss: 0.4631 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8749 - loss: 0.2768 - precision: 0.9176 - recall: 0.8407 - val_accuracy: 0.8889 - val_loss: 0.4625 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9173 - loss: 0.1942 - precision: 0.9431 - recall: 0.8928 - val_accuracy: 0.8889 - val_loss: 0.4588 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9040 - loss: 0.2363 - precision: 0.9040 - recall: 0.9157 - val_accuracy: 0.8889 - val_loss: 0.4545 - val_precision: 0.8889 - val_recall: 0.8889\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8911 - loss: 0.2365 - precision: 0.8955 - recall: 0.8776 - val_accuracy: 0.8889 - val_loss: 0.4415 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9241 - loss: 0.1885 - precision: 0.9148 - recall: 0.9418 - val_accuracy: 0.8889 - val_loss: 0.4391 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9214 - loss: 0.2251 - precision: 0.8967 - recall: 0.9537 - val_accuracy: 0.8889 - val_loss: 0.4401 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8944 - loss: 0.2260 - precision: 0.8918 - recall: 0.9031 - val_accuracy: 0.8667 - val_loss: 0.4353 - val_precision: 0.8235 - val_recall: 0.9333\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9173 - loss: 0.2735 - precision: 0.9157 - recall: 0.9248 - val_accuracy: 0.8889 - val_loss: 0.4087 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8863 - loss: 0.2258 - precision: 0.8688 - recall: 0.9087 - val_accuracy: 0.8889 - val_loss: 0.3783 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9123 - loss: 0.2348 - precision: 0.9131 - recall: 0.9079 - val_accuracy: 0.9000 - val_loss: 0.3875 - val_precision: 0.8750 - val_recall: 0.9333\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8923 - loss: 0.2456 - precision: 0.8792 - recall: 0.9193 - val_accuracy: 0.8889 - val_loss: 0.3959 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8951 - loss: 0.2028 - precision: 0.8617 - recall: 0.9461 - val_accuracy: 0.9000 - val_loss: 0.3793 - val_precision: 0.8750 - val_recall: 0.9333\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9091 - loss: 0.2249 - precision: 0.8875 - recall: 0.9189 - val_accuracy: 0.8778 - val_loss: 0.3588 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8874 - loss: 0.1826 - precision: 0.8994 - recall: 0.8723 - val_accuracy: 0.9000 - val_loss: 0.3281 - val_precision: 0.8750 - val_recall: 0.9333\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9184 - loss: 0.2083 - precision: 0.9004 - recall: 0.9408 - val_accuracy: 0.9000 - val_loss: 0.3437 - val_precision: 0.8750 - val_recall: 0.9333\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9194 - loss: 0.1948 - precision: 0.9460 - recall: 0.8888 - val_accuracy: 0.9111 - val_loss: 0.3730 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9030 - loss: 0.2567 - precision: 0.9270 - recall: 0.8948 - val_accuracy: 0.8889 - val_loss: 0.3479 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9308 - loss: 0.1878 - precision: 0.9048 - recall: 0.9580 - val_accuracy: 0.8889 - val_loss: 0.3313 - val_precision: 0.8889 - val_recall: 0.8889\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9268 - loss: 0.2171 - precision: 0.9473 - recall: 0.9049 - val_accuracy: 0.8778 - val_loss: 0.3233 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9384 - loss: 0.1582 - precision: 0.9243 - recall: 0.9519 - val_accuracy: 0.8778 - val_loss: 0.3172 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9102 - loss: 0.2081 - precision: 0.9011 - recall: 0.9264 - val_accuracy: 0.8889 - val_loss: 0.3068 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9363 - loss: 0.1646 - precision: 0.9176 - recall: 0.9626 - val_accuracy: 0.9111 - val_loss: 0.3013 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9231 - loss: 0.1582 - precision: 0.9404 - recall: 0.9009 - val_accuracy: 0.8778 - val_loss: 0.2909 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9111 - loss: 0.1910 - precision: 0.8834 - recall: 0.9405 - val_accuracy: 0.9000 - val_loss: 0.2914 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8917 - loss: 0.1937 - precision: 0.8717 - recall: 0.9075 - val_accuracy: 0.9222 - val_loss: 0.3120 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9018 - loss: 0.2424 - precision: 0.9489 - recall: 0.8611 - val_accuracy: 0.9000 - val_loss: 0.3014 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9372 - loss: 0.1511 - precision: 0.8972 - recall: 0.9802 - val_accuracy: 0.9000 - val_loss: 0.3299 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9140 - loss: 0.1977 - precision: 0.9621 - recall: 0.8755 - val_accuracy: 0.9111 - val_loss: 0.3358 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9291 - loss: 0.1882 - precision: 0.9352 - recall: 0.9171 - val_accuracy: 0.9000 - val_loss: 0.3510 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9359 - loss: 0.1486 - precision: 0.9270 - recall: 0.9518 - val_accuracy: 0.9000 - val_loss: 0.3439 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9137 - loss: 0.1500 - precision: 0.9027 - recall: 0.9222 - val_accuracy: 0.8889 - val_loss: 0.3342 - val_precision: 0.8889 - val_recall: 0.8889\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9284 - loss: 0.1775 - precision: 0.9272 - recall: 0.9256 - val_accuracy: 0.8889 - val_loss: 0.3275 - val_precision: 0.8889 - val_recall: 0.8889\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9078 - loss: 0.1378 - precision: 0.8924 - recall: 0.9114 - val_accuracy: 0.9000 - val_loss: 0.3439 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9176 - loss: 0.2059 - precision: 0.9582 - recall: 0.8862 - val_accuracy: 0.9111 - val_loss: 0.3379 - val_precision: 0.9111 - val_recall: 0.9111\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9430 - loss: 0.1504 - precision: 0.9207 - recall: 0.9745 - val_accuracy: 0.8889 - val_loss: 0.3707 - val_precision: 0.9070 - val_recall: 0.8667\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9007 - loss: 0.1803 - precision: 0.9167 - recall: 0.8909 - val_accuracy: 0.9111 - val_loss: 0.3658 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9337 - loss: 0.1548 - precision: 0.9100 - recall: 0.9613 - val_accuracy: 0.9000 - val_loss: 0.3615 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9233 - loss: 0.1679 - precision: 0.9109 - recall: 0.9413 - val_accuracy: 0.9000 - val_loss: 0.3720 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9342 - loss: 0.1680 - precision: 0.9226 - recall: 0.9537 - val_accuracy: 0.9000 - val_loss: 0.3982 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9349 - loss: 0.1887 - precision: 0.9236 - recall: 0.9519 - val_accuracy: 0.8889 - val_loss: 0.4190 - val_precision: 0.9487 - val_recall: 0.8222\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9462 - loss: 0.1274 - precision: 0.9509 - recall: 0.9409 - val_accuracy: 0.8889 - val_loss: 0.4091 - val_precision: 0.9487 - val_recall: 0.8222\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9313 - loss: 0.1557 - precision: 0.9442 - recall: 0.9158 - val_accuracy: 0.9000 - val_loss: 0.3860 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9635 - loss: 0.1172 - precision: 0.9495 - recall: 0.9815 - val_accuracy: 0.8889 - val_loss: 0.4204 - val_precision: 0.9487 - val_recall: 0.8222\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9353 - loss: 0.1917 - precision: 0.9344 - recall: 0.9412 - val_accuracy: 0.8778 - val_loss: 0.4079 - val_precision: 0.9474 - val_recall: 0.8000\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9233 - loss: 0.1508 - precision: 0.9408 - recall: 0.9063 - val_accuracy: 0.9000 - val_loss: 0.4009 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9574 - loss: 0.1404 - precision: 0.9468 - recall: 0.9725 - val_accuracy: 0.9222 - val_loss: 0.4022 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9666 - loss: 0.1033 - precision: 0.9736 - recall: 0.9591 - val_accuracy: 0.9111 - val_loss: 0.3768 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9325 - loss: 0.1412 - precision: 0.9079 - recall: 0.9657 - val_accuracy: 0.9111 - val_loss: 0.3642 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9298 - loss: 0.1447 - precision: 0.9194 - recall: 0.9534 - val_accuracy: 0.9000 - val_loss: 0.4259 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9740 - loss: 0.0951 - precision: 0.9780 - recall: 0.9696 - val_accuracy: 0.9000 - val_loss: 0.4642 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9423 - loss: 0.1246 - precision: 0.9142 - recall: 0.9637 - val_accuracy: 0.9000 - val_loss: 0.4484 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9490 - loss: 0.1026 - precision: 0.9789 - recall: 0.9123 - val_accuracy: 0.9000 - val_loss: 0.4212 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9383 - loss: 0.1402 - precision: 0.9255 - recall: 0.9571 - val_accuracy: 0.8889 - val_loss: 0.4119 - val_precision: 0.9268 - val_recall: 0.8444\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9285 - loss: 0.1436 - precision: 0.9092 - recall: 0.9500 - val_accuracy: 0.9000 - val_loss: 0.4423 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9331 - loss: 0.1312 - precision: 0.9509 - recall: 0.9100 - val_accuracy: 0.8889 - val_loss: 0.4420 - val_precision: 0.9268 - val_recall: 0.8444\n","\n","Evaluating model...\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n","\n","Validation Accuracy: 0.8889\n","Sensitivity (Recall): 0.8444\n","Specificity: 0.9333\n","Matthews Correlation Coefficient (MCC): 0.7809\n","Cohen's Kappa: 0.7778\n","Area Under Curve (AUC): 0.9516\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.93      0.89        45\n","           1       0.93      0.84      0.88        45\n","\n","    accuracy                           0.89        90\n","   macro avg       0.89      0.89      0.89        90\n","weighted avg       0.89      0.89      0.89        90\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/CPFV_Top_10_Features.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset\n","print(\"Dataset Columns:\", data.columns)\n","print(\"Shape before processing:\", data.shape)\n","print(data.head())\n","\n","# Check for target column\n","if 'True_Label' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'True_Label' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values\n","y = data['True_Label'].values\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n","\n","print(\"\\nShapes after reshaping:\")\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_val shape:\", X_val.shape)\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# First Conv1D layer\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Second Conv1D layer\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Third Conv1D layer\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Global pooling\n","model.add(GlobalMaxPooling1D())\n","\n","# Dense Layers\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the Model\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',\n","                       tf.keras.metrics.Precision(name='precision'),\n","                       tf.keras.metrics.Recall(name='recall')])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","print(\"\\nTraining model...\")\n","history = model.fit(X_train, y_train,\n","                    validation_data=(X_val, y_val),\n","                    epochs=100,\n","                    batch_size=32,\n","                    verbose=1)\n","\n","# Evaluate the model\n","print(\"\\nEvaluating model...\")\n","val_probs = model.predict(X_val)\n","val_predictions = (val_probs > 0.5).astype(int)\n","\n","# Metrics Calculation\n","accuracy = accuracy_score(y_val, val_predictions)\n","conf_matrix = confusion_matrix(y_val, val_predictions)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n","specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n","mcc = matthews_corrcoef(y_val, val_predictions)\n","kappa = cohen_kappa_score(y_val, val_predictions)\n","auc = roc_auc_score(y_val, val_probs)\n","\n","# Print Metrics\n","print(f\"\\nValidation Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n","print(f\"Cohen's Kappa: {kappa:.4f}\")\n","print(f\"Area Under Curve (AUC): {auc:.4f}\")\n","\n","# Classification Report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_val, val_predictions))\n"]},{"cell_type":"code","source":["#cross validation for cpfv\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Load the dataset\n","dataset_path = \"/content/CPFV_Top_10_Features.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values\n","y = data['True_Label'].values\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Reshape for Conv1D\n","X = X.reshape(X.shape[0], X.shape[1], 1)\n","\n","# Set up Stratified K-Fold\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# For storing metrics\n","accs, sens_list, specs, mccs, kappas, aucs = [], [], [], [], [], []\n","\n","fold = 1\n","for train_idx, val_idx in kf.split(X, y):\n","    print(f\"\\n----- Fold {fold} -----\")\n","\n","    X_train, X_val = X[train_idx], X[val_idx]\n","    y_train, y_val = y[train_idx], y[val_idx]\n","\n","    # Define model\n","    model = Sequential()\n","    model.add(Conv1D(64, 3, activation='relu', input_shape=(X.shape[1], 1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(GlobalMaxPooling1D())\n","\n","    model.add(Dense(128, activation='swish'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(64, activation='swish'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    # Train\n","    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n","\n","    # Predict\n","    val_probs = model.predict(X_val)\n","    val_pred = (val_probs > 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_val, val_pred)\n","    conf = confusion_matrix(y_val, val_pred)\n","    tn, fp, fn, tp = conf.ravel()\n","    sens = tp / (tp + fn) if (tp + fn) else 0\n","    spec = tn / (tn + fp) if (tn + fp) else 0\n","    mcc = matthews_corrcoef(y_val, val_pred)\n","    kappa = cohen_kappa_score(y_val, val_pred)\n","    auc = roc_auc_score(y_val, val_probs)\n","\n","    # Append to lists\n","    accs.append(acc)\n","    sens_list.append(sens)\n","    specs.append(spec)\n","    mccs.append(mcc)\n","    kappas.append(kappa)\n","    aucs.append(auc)\n","\n","    print(f\"Accuracy: {acc:.4f}, Sensitivity: {sens:.4f}, Specificity: {spec:.4f}, MCC: {mcc:.4f}, Kappa: {kappa:.4f}, AUC: {auc:.4f}\")\n","    fold += 1\n","\n","# Print average performance\n","print(\"\\n===== Cross-Validation Results =====\")\n","print(f\"Average Accuracy: {np.mean(accs):.4f}\")\n","print(f\"Average Sensitivity: {np.mean(sens_list):.4f}\")\n","print(f\"Average Specificity: {np.mean(specs):.4f}\")\n","print(f\"Average MCC: {np.mean(mccs):.4f}\")\n","print(f\"Average Kappa: {np.mean(kappas):.4f}\")\n","print(f\"Average AUC: {np.mean(aucs):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnfxFPrV7aWh","executionInfo":{"status":"ok","timestamp":1744745579363,"user_tz":-360,"elapsed":148253,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"2f39ab1c-d806-4cfb-8ba0-4da7a1d610a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","----- Fold 1 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n","Accuracy: 0.8667, Sensitivity: 0.9333, Specificity: 0.8000, MCC: 0.7399, Kappa: 0.7333, AUC: 0.9500\n","\n","----- Fold 2 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n","Accuracy: 0.9167, Sensitivity: 0.9667, Specificity: 0.8667, MCC: 0.8375, Kappa: 0.8333, AUC: 0.9800\n","\n","----- Fold 3 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step\n","Accuracy: 0.9500, Sensitivity: 0.9000, Specificity: 1.0000, MCC: 0.9045, Kappa: 0.9000, AUC: 0.9711\n","\n","----- Fold 4 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n","Accuracy: 0.7833, Sensitivity: 0.7000, Specificity: 0.8667, MCC: 0.5747, Kappa: 0.5667, AUC: 0.9133\n","\n","----- Fold 5 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n","Accuracy: 0.8667, Sensitivity: 0.8667, Specificity: 0.8667, MCC: 0.7333, Kappa: 0.7333, AUC: 0.9489\n","\n","===== Cross-Validation Results =====\n","Average Accuracy: 0.8767\n","Average Sensitivity: 0.8733\n","Average Specificity: 0.8800\n","Average MCC: 0.7580\n","Average Kappa: 0.7533\n","Average AUC: 0.9527\n"]}]},{"cell_type":"markdown","metadata":{"id":"KykXgdLExeCP"},"source":["Class Feature Vector (CFV)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4637,"status":"ok","timestamp":1739662290000,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"-rpIaFvKwxD4","outputId":"89647802-f24d-4a1f-c506-b7cf98c51b74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/Optuna_Dataset Marge CFV.csv\n"]}],"source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"ACC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_AAC.csv\",\n","    \"CTDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTDC (1).csv\",\n","    \"CTD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTD (3).csv\",\n","    \"GDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_GDC.csv\",\n","    \"PAAC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_PAAC.csv\",\n","    \"PCP\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_PCP.csv\",\n","    \"TPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_TPC.csv\",\n","    \"CTDT\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTDT.csv\",\n","    \"DPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_DPC (1).csv\",\n","    \"CTDD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTDD.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/Optuna_Dataset Marge CFV.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1739662290001,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"hFUb_w-IxtQs","outputId":"3747b1d0-c866-4c01-c9d9-db0d78a6c7f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the merged dataset: (300, 120)\n"]}],"source":["# Check the shape of the merged dataset\n","print(\"Shape of the merged dataset:\", combined_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1N9vmtextUn"},"outputs":[],"source":["df=pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/Optuna_Dataset Marge CFV.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739662290702,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"86_AeqSqxtp7","outputId":"fa4a0086-0c09-4c19-a9b9-1db94fd898da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 121)"]},"metadata":{},"execution_count":15}],"source":["df.shape"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/Optuna_Dataset Marge CFV.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional: Uncomment if needed to verify column names)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'True_Label' column for binary classification\n","if 'True_Label' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'True_Label' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values  # Features\n","y = data['True_Label'].values                 # Labels\n","\n","# Split data into training and validation sets (70-30 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# Stacked Conv1D layers with BatchNormalization and Dropout\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","# LSTM layer for sequential dependencies\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","\n","# Dense Layers with Dropout\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n","\n","# Compile the Model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n","\n","# Evaluate the model on the validation data\n","val_probs = model.predict(X_val)\n","val_predictions = (val_probs > 0.5).astype(int)\n","\n","# Compute metrics\n","accuracy = accuracy_score(y_val, val_predictions)\n","conf_matrix = confusion_matrix(y_val, val_predictions)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # Recall\n","specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # True Negative Rate\n","mcc = matthews_corrcoef(y_val, val_predictions)\n","kappa = cohen_kappa_score(y_val, val_predictions)\n","auc = roc_auc_score(y_val, val_probs)\n","\n","# Print evaluation metrics\n","print(\"\\nValidation Accuracy:\", accuracy)\n","print(\"Sensitivity (Recall):\", sensitivity)\n","print(\"Specificity:\", specificity)\n","print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n","print(\"Cohen's Kappa:\", kappa)\n","print(\"Area Under Curve (AUC):\", auc)\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pjPTaPWZqt6Q","executionInfo":{"status":"ok","timestamp":1744742875470,"user_tz":-360,"elapsed":132980,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"983c1941-9749-47c9-bcf2-486bd044fe4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC', 'Decision Tree_ACC', 'Random Forest_ACC',\n","       'Logistic Regression_ACC', 'k-NN_ACC', 'Naive Bayes_ACC',\n","       'Gradient Boosting_ACC', 'XGBoost_ACC', 'LightGBM_ACC', 'AdaBoost_ACC',\n","       ...\n","       'Logistic Regression_CTDD', 'k-NN_CTDD', 'Naive Bayes_CTDD',\n","       'Gradient Boosting_CTDD', 'XGBoost_CTDD', 'LightGBM_CTDD',\n","       'AdaBoost_CTDD', 'Neural Network_CTDD', 'MLP_CTDD', 'True_Label'],\n","      dtype='object', length=121)\n","    SVM_ACC  Decision Tree_ACC  Random Forest_ACC  Logistic Regression_ACC  \\\n","0  0.830810           0.919355           0.777252                 0.824422   \n","1  0.987548           1.000000           0.993010                 0.997619   \n","2  0.211028           0.000000           0.212838                 0.313903   \n","3  0.552428           0.000000           0.561655                 0.560973   \n","4  0.607083           0.500000           0.403041                 0.389037   \n","\n","   k-NN_ACC  Naive Bayes_ACC  Gradient Boosting_ACC  XGBoost_ACC  \\\n","0  1.000000         0.892723               1.000000     0.985941   \n","1  1.000000         1.000000               0.999998     0.999972   \n","2  1.000000         0.114252               0.077102     0.142499   \n","3  0.333333         0.771621               0.688946     0.627514   \n","4  0.000000         0.008400               0.004976     0.506804   \n","\n","   LightGBM_ACC  AdaBoost_ACC  ...  Logistic Regression_CTDD  k-NN_CTDD  \\\n","0      0.974355      0.508407  ...                  0.986358        1.0   \n","1      0.999663      0.629474  ...                  0.999304        1.0   \n","2      0.139887      0.465023  ...                  0.468210        1.0   \n","3      0.576563      0.525876  ...                  0.646864        1.0   \n","4      0.341967      0.497707  ...                  0.356784        0.0   \n","\n","   Naive Bayes_CTDD  Gradient Boosting_CTDD  XGBoost_CTDD  LightGBM_CTDD  \\\n","0                 1                0.999247      0.983702       0.830374   \n","1                 1                0.999690      0.994995       0.998718   \n","2                 1                0.878527      0.263696       0.771480   \n","3                 1                0.892741      0.969475       0.867968   \n","4                 0                0.004224      0.074630       0.320005   \n","\n","   AdaBoost_CTDD  Neural Network_CTDD  MLP_CTDD  True_Label  \n","0       0.501636             1.000000  1.000000           1  \n","1       0.556959             1.000000  1.000000           1  \n","2       0.494464             0.992611  0.790275           1  \n","3       0.551380             0.997340  0.946840           1  \n","4       0.493104             0.000001  0.026131           1  \n","\n","[5 rows x 121 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_9\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m82,176\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,129\u001b[0m (875.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,129</span> (875.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,233\u001b[0m (872.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,233</span> (872.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 303ms/step - accuracy: 0.6185 - loss: 0.7120 - val_accuracy: 0.8889 - val_loss: 0.6803\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.8982 - loss: 0.5215 - val_accuracy: 0.9000 - val_loss: 0.6706\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9077 - loss: 0.2572 - val_accuracy: 0.9000 - val_loss: 0.6696\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9235 - loss: 0.2122 - val_accuracy: 0.9333 - val_loss: 0.6697\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9199 - loss: 0.1889 - val_accuracy: 0.9333 - val_loss: 0.6709\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.8988 - loss: 0.3256 - val_accuracy: 0.7556 - val_loss: 0.6633\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - accuracy: 0.9110 - loss: 0.2738 - val_accuracy: 0.6222 - val_loss: 0.6467\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - accuracy: 0.9213 - loss: 0.1686 - val_accuracy: 0.6444 - val_loss: 0.6359\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.9485 - loss: 0.1645 - val_accuracy: 0.6778 - val_loss: 0.6331\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.9063 - loss: 0.1732 - val_accuracy: 0.6444 - val_loss: 0.6311\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9188 - loss: 0.1865 - val_accuracy: 0.5444 - val_loss: 0.6285\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9496 - loss: 0.1361 - val_accuracy: 0.5444 - val_loss: 0.6205\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9292 - loss: 0.2091 - val_accuracy: 0.5111 - val_loss: 0.6130\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9412 - loss: 0.1838 - val_accuracy: 0.5778 - val_loss: 0.5730\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.9514 - loss: 0.1324 - val_accuracy: 0.6111 - val_loss: 0.5621\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - accuracy: 0.9321 - loss: 0.1506 - val_accuracy: 0.5333 - val_loss: 0.5546\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - accuracy: 0.9350 - loss: 0.1831 - val_accuracy: 0.5000 - val_loss: 0.5675\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.9175 - loss: 0.1642 - val_accuracy: 0.5000 - val_loss: 0.5779\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.9455 - loss: 0.1369 - val_accuracy: 0.5222 - val_loss: 0.5777\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9117 - loss: 0.1553 - val_accuracy: 0.5111 - val_loss: 0.6157\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9338 - loss: 0.1781 - val_accuracy: 0.5000 - val_loss: 0.6376\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.9600 - loss: 0.1239 - val_accuracy: 0.5889 - val_loss: 0.5996\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9497 - loss: 0.1212 - val_accuracy: 0.6222 - val_loss: 0.5625\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.9165 - loss: 0.1665 - val_accuracy: 0.5667 - val_loss: 0.6018\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9467 - loss: 0.1624 - val_accuracy: 0.5333 - val_loss: 0.6980\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - accuracy: 0.9218 - loss: 0.1806 - val_accuracy: 0.5111 - val_loss: 0.8740\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - accuracy: 0.9399 - loss: 0.1459 - val_accuracy: 0.5333 - val_loss: 1.1812\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9419 - loss: 0.1915 - val_accuracy: 0.5000 - val_loss: 1.5553\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9680 - loss: 0.1389 - val_accuracy: 0.5000 - val_loss: 1.1730\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9608 - loss: 0.0972 - val_accuracy: 0.5000 - val_loss: 1.1673\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9637 - loss: 0.1042 - val_accuracy: 0.5000 - val_loss: 1.4199\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9631 - loss: 0.1100 - val_accuracy: 0.5000 - val_loss: 1.5347\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9590 - loss: 0.1156 - val_accuracy: 0.5111 - val_loss: 1.5465\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9361 - loss: 0.1565 - val_accuracy: 0.5889 - val_loss: 1.5026\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9511 - loss: 0.1252 - val_accuracy: 0.5111 - val_loss: 1.6827\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9834 - loss: 0.0696 - val_accuracy: 0.5111 - val_loss: 1.7498\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9532 - loss: 0.1391 - val_accuracy: 0.6000 - val_loss: 1.7181\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.9828 - loss: 0.0695 - val_accuracy: 0.6222 - val_loss: 1.9241\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9753 - loss: 0.0690 - val_accuracy: 0.6111 - val_loss: 2.4585\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.9511 - loss: 0.1531 - val_accuracy: 0.5333 - val_loss: 3.3937\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9803 - loss: 0.0764 - val_accuracy: 0.6667 - val_loss: 2.9211\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9579 - loss: 0.1244 - val_accuracy: 0.6667 - val_loss: 2.6663\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9498 - loss: 0.1104 - val_accuracy: 0.6556 - val_loss: 2.7805\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9447 - loss: 0.1191 - val_accuracy: 0.7444 - val_loss: 2.3005\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9522 - loss: 0.0949 - val_accuracy: 0.7111 - val_loss: 1.8397\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9670 - loss: 0.0781 - val_accuracy: 0.6556 - val_loss: 3.2098\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9712 - loss: 0.0885 - val_accuracy: 0.6222 - val_loss: 5.8374\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9663 - loss: 0.0942 - val_accuracy: 0.6667 - val_loss: 8.0431\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9799 - loss: 0.0848 - val_accuracy: 0.6444 - val_loss: 13.9714\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9869 - loss: 0.0607 - val_accuracy: 0.7111 - val_loss: 13.7491\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.9597 - loss: 0.0743 - val_accuracy: 0.7667 - val_loss: 13.3555\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.9815 - loss: 0.0587 - val_accuracy: 0.7333 - val_loss: 8.3267\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.9631 - loss: 0.0989 - val_accuracy: 0.6778 - val_loss: 7.0040\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9838 - loss: 0.1008 - val_accuracy: 0.6000 - val_loss: 5.2149\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9710 - loss: 0.1156 - val_accuracy: 0.5667 - val_loss: 6.4392\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9820 - loss: 0.0874 - val_accuracy: 0.6444 - val_loss: 3.2313\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9735 - loss: 0.0708 - val_accuracy: 0.7778 - val_loss: 1.6223\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9484 - loss: 0.1117 - val_accuracy: 0.7222 - val_loss: 1.3050\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9581 - loss: 0.0747 - val_accuracy: 0.7111 - val_loss: 1.2626\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9739 - loss: 0.0817 - val_accuracy: 0.6889 - val_loss: 1.2159\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9766 - loss: 0.0628 - val_accuracy: 0.6778 - val_loss: 1.4196\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9749 - loss: 0.0657 - val_accuracy: 0.7111 - val_loss: 1.7023\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9753 - loss: 0.0717 - val_accuracy: 0.8000 - val_loss: 1.3961\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9907 - loss: 0.0273 - val_accuracy: 0.7889 - val_loss: 1.1524\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9988 - loss: 0.0320 - val_accuracy: 0.6000 - val_loss: 2.4286\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.9912 - loss: 0.0368 - val_accuracy: 0.8333 - val_loss: 1.2545\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - accuracy: 0.9859 - loss: 0.0262 - val_accuracy: 0.8778 - val_loss: 0.6970\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9864 - loss: 0.0551 - val_accuracy: 0.8889 - val_loss: 1.1172\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9744 - loss: 0.0509 - val_accuracy: 0.9000 - val_loss: 0.7191\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9829 - loss: 0.0592 - val_accuracy: 0.8667 - val_loss: 0.7920\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9650 - loss: 0.1124 - val_accuracy: 0.8667 - val_loss: 0.6332\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9709 - loss: 0.1060 - val_accuracy: 0.8556 - val_loss: 0.5792\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9800 - loss: 0.0644 - val_accuracy: 0.8889 - val_loss: 0.5485\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9881 - loss: 0.0453 - val_accuracy: 0.9111 - val_loss: 0.6369\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9756 - loss: 0.0485 - val_accuracy: 0.9111 - val_loss: 0.7851\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9824 - loss: 0.0677 - val_accuracy: 0.9111 - val_loss: 0.7962\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9867 - loss: 0.0359 - val_accuracy: 0.9222 - val_loss: 0.9938\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.9933 - loss: 0.0427 - val_accuracy: 0.9000 - val_loss: 1.3264\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.9838 - loss: 0.0488 - val_accuracy: 0.9111 - val_loss: 0.9573\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.9844 - loss: 0.0414 - val_accuracy: 0.9222 - val_loss: 0.7974\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9837 - loss: 0.0296 - val_accuracy: 0.9000 - val_loss: 0.8076\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9931 - loss: 0.0198 - val_accuracy: 0.8889 - val_loss: 1.1612\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9798 - loss: 0.0673 - val_accuracy: 0.9111 - val_loss: 1.3066\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.9938 - loss: 0.0196 - val_accuracy: 0.9111 - val_loss: 0.7462\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9774 - loss: 0.1385 - val_accuracy: 0.9222 - val_loss: 1.6672\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9557 - loss: 0.6595 - val_accuracy: 0.9222 - val_loss: 1.5134\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.8689 - loss: 2.9412 - val_accuracy: 0.9111 - val_loss: 0.7407\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8512 - loss: 2.6948 - val_accuracy: 0.9222 - val_loss: 0.8341\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.8574 - loss: 1.1401 - val_accuracy: 0.9111 - val_loss: 0.5440\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.8389 - loss: 2.0081 - val_accuracy: 0.9000 - val_loss: 2.1268\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.8546 - loss: 2.1905 - val_accuracy: 0.9222 - val_loss: 1.2584\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.8439 - loss: 1.2292 - val_accuracy: 0.9222 - val_loss: 2.1919\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.8599 - loss: 1.3093 - val_accuracy: 0.9222 - val_loss: 1.3527\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.8345 - loss: 1.1086 - val_accuracy: 0.9333 - val_loss: 0.5572\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9116 - loss: 0.2610 - val_accuracy: 0.9333 - val_loss: 0.4147\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.8559 - loss: 1.0147 - val_accuracy: 0.9333 - val_loss: 0.2206\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.8251 - loss: 0.7300 - val_accuracy: 0.8333 - val_loss: 0.3757\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.7552 - loss: 1.2174 - val_accuracy: 0.8778 - val_loss: 0.2647\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.8552 - loss: 0.3766 - val_accuracy: 0.9000 - val_loss: 0.1979\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8315 - loss: 0.3166 - val_accuracy: 0.9111 - val_loss: 0.1859\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step\n","\n","Validation Accuracy: 0.9111111111111111\n","Sensitivity (Recall): 0.8666666666666667\n","Specificity: 0.9555555555555556\n","Matthews Correlation Coefficient (MCC): 0.8254898842683464\n","Cohen's Kappa: 0.8222222222222222\n","Area Under Curve (AUC): 0.9723456790123457\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.96      0.91        45\n","           1       0.95      0.87      0.91        45\n","\n","    accuracy                           0.91        90\n","   macro avg       0.91      0.91      0.91        90\n","weighted avg       0.91      0.91      0.91        90\n","\n"]}]},{"cell_type":"code","source":["#CROSS VALIDATION FOR cfv\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","\n","# Load dataset\n","dataset_path = \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/Optuna_Dataset Marge CFV.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values\n","y = data['True_Label'].values\n","\n","# Initialize StratifiedKFold\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Track metrics across folds\n","metrics = {\n","    \"accuracy\": [],\n","    \"sensitivity\": [],\n","    \"specificity\": [],\n","    \"mcc\": [],\n","    \"kappa\": [],\n","    \"auc\": []\n","}\n","\n","fold = 1\n","for train_idx, val_idx in kf.split(X, y):\n","    print(f\"\\n========== Fold {fold} ==========\")\n","\n","    X_train, X_val = X[train_idx], X[val_idx]\n","    y_train, y_val = y[train_idx], y[val_idx]\n","\n","    # Normalize\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","\n","    # Reshape for Conv1D\n","    X_train = X_train[..., np.newaxis]\n","    X_val = X_val[..., np.newaxis]\n","\n","    # Build model\n","    def build_model():\n","        model = Sequential()\n","        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling1D(pool_size=2))\n","        model.add(Dropout(0.3))\n","\n","        model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.3))\n","\n","        model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling1D(pool_size=2))\n","        model.add(Dropout(0.3))\n","\n","        model.add(LSTM(64, activation='relu'))\n","\n","        model.add(Dense(128, activation='swish'))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(64, activation='swish'))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(1, activation='sigmoid'))\n","\n","        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    model = build_model()\n","\n","    # Train model\n","    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_data=(X_val, y_val))\n","\n","    # Predict\n","    val_probs = model.predict(X_val)\n","    val_preds = (val_probs > 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_val, val_preds)\n","    cm = confusion_matrix(y_val, val_preds)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    sens = tp / (tp + fn) if (tp + fn) != 0 else 0\n","    spec = tn / (tn + fp) if (tn + fp) != 0 else 0\n","    mcc = matthews_corrcoef(y_val, val_preds)\n","    kappa = cohen_kappa_score(y_val, val_preds)\n","    auc = roc_auc_score(y_val, val_probs)\n","\n","    # Print fold results\n","    print(f\"Accuracy: {acc:.4f} | Sensitivity: {sens:.4f} | Specificity: {spec:.4f} | MCC: {mcc:.4f} | Kappa: {kappa:.4f} | AUC: {auc:.4f}\")\n","    print(classification_report(y_val, val_preds))\n","\n","    # Store metrics\n","    metrics[\"accuracy\"].append(acc)\n","    metrics[\"sensitivity\"].append(sens)\n","    metrics[\"specificity\"].append(spec)\n","    metrics[\"mcc\"].append(mcc)\n","    metrics[\"kappa\"].append(kappa)\n","    metrics[\"auc\"].append(auc)\n","\n","    fold += 1\n","\n","# Average metrics\n","print(\"\\n========== Average Metrics Across 5 Folds ==========\")\n","for key, values in metrics.items():\n","    print(f\"{key.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNIQTbbF8X33","executionInfo":{"status":"ok","timestamp":1744746351720,"user_tz":-360,"elapsed":690165,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"e97c4684-afa8-47a8-adb1-4c3d3d597241"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== Fold 1 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step\n","Accuracy: 0.9000 | Sensitivity: 0.9333 | Specificity: 0.8667 | MCC: 0.8018 | Kappa: 0.8000 | AUC: 0.9589\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.87      0.90        30\n","           1       0.88      0.93      0.90        30\n","\n","    accuracy                           0.90        60\n","   macro avg       0.90      0.90      0.90        60\n","weighted avg       0.90      0.90      0.90        60\n","\n","\n","========== Fold 2 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step\n","Accuracy: 0.9500 | Sensitivity: 0.9667 | Specificity: 0.9333 | MCC: 0.9005 | Kappa: 0.9000 | AUC: 0.9889\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.93      0.95        30\n","           1       0.94      0.97      0.95        30\n","\n","    accuracy                           0.95        60\n","   macro avg       0.95      0.95      0.95        60\n","weighted avg       0.95      0.95      0.95        60\n","\n","\n","========== Fold 3 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step\n","Accuracy: 0.9000 | Sensitivity: 0.8667 | Specificity: 0.9333 | MCC: 0.8018 | Kappa: 0.8000 | AUC: 0.9667\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.93      0.90        30\n","           1       0.93      0.87      0.90        30\n","\n","    accuracy                           0.90        60\n","   macro avg       0.90      0.90      0.90        60\n","weighted avg       0.90      0.90      0.90        60\n","\n","\n","========== Fold 4 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step\n","Accuracy: 0.9000 | Sensitivity: 0.9000 | Specificity: 0.9000 | MCC: 0.8000 | Kappa: 0.8000 | AUC: 0.9606\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.90      0.90        30\n","           1       0.90      0.90      0.90        30\n","\n","    accuracy                           0.90        60\n","   macro avg       0.90      0.90      0.90        60\n","weighted avg       0.90      0.90      0.90        60\n","\n","\n","========== Fold 5 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step\n","Accuracy: 0.8833 | Sensitivity: 0.8667 | Specificity: 0.9000 | MCC: 0.7671 | Kappa: 0.7667 | AUC: 0.9167\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.90      0.89        30\n","           1       0.90      0.87      0.88        30\n","\n","    accuracy                           0.88        60\n","   macro avg       0.88      0.88      0.88        60\n","weighted avg       0.88      0.88      0.88        60\n","\n","\n","========== Average Metrics Across 5 Folds ==========\n","Accuracy: 0.9067 ± 0.0226\n","Sensitivity: 0.9067 ± 0.0389\n","Specificity: 0.9067 ± 0.0249\n","Mcc: 0.8142 ± 0.0451\n","Kappa: 0.8133 ± 0.0452\n","Auc: 0.9583 ± 0.0234\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2644,"status":"ok","timestamp":1744742910712,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"BYmlV1dUxts9","outputId":"fc36b0ac-723a-4f6a-9447-c36ea5a6e8b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n"]}],"source":["!pip install deap"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239198,"status":"ok","timestamp":1744743149913,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"UJxv5SM8uvbN","outputId":"ce3a585e-2d02-49dd-e979-d67c5e0370e9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n","/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n"]},{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t50    \n","1  \t41    \n","2  \t36    \n","3  \t44    \n","4  \t40    \n","5  \t40    \n","6  \t39    \n","7  \t39    \n","8  \t48    \n","9  \t39    \n","10 \t42    \n","11 \t44    \n","12 \t38    \n","13 \t43    \n","14 \t37    \n","15 \t45    \n","16 \t34    \n","17 \t38    \n","18 \t36    \n","19 \t37    \n","20 \t40    \n","Top 10 Selected features: [0, 1, 2, 3, 4, 5, 10, 8, 20, 21]\n","Final Accuracy with top 10 selected features: 0.9166666666666666\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from deap import base, creator, tools, algorithms\n","import random\n","\n","# Load the dataset\n","data_path = '/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/Optuna_Dataset Marge CFV.csv'\n","data = pd.read_csv(data_path)\n","\n","# Assuming the last column is the target, split features and labels\n","X = data.iloc[:, :-1]  # Features\n","y = data.iloc[:, -1]   # Target\n","\n","# Encode target labels if necessary\n","if y.dtype == object or np.issubdtype(y.dtype, np.number):  # Handle both string and numeric labels\n","    le = LabelEncoder()\n","    y = le.fit_transform(y.astype(str))  # Ensure all targets are treated as strings for classification\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create the individual and fitness functions\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# Classifier to evaluate fitness\n","def evaluate(individual):\n","    selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n","    if len(selected_features) == 0:  # Prevent division by zero\n","        return 0,\n","\n","    X_train_selected = X_train.iloc[:, selected_features]\n","    X_val_selected = X_val.iloc[:, selected_features]\n","\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_train_selected, y_train)\n","    y_pred = model.predict(X_val_selected)\n","\n","    accuracy = accuracy_score(y_val, y_pred)\n","    return accuracy,\n","\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# Parameters for the Genetic Algorithm\n","population_size = 50\n","generations = 20\n","crossover_probability = 0.8\n","mutation_probability = 0.1\n","\n","# Initialize population\n","population = toolbox.population(n=population_size)\n","\n","# Run the Genetic Algorithm\n","result_population, logbook = algorithms.eaSimple(\n","    population,\n","    toolbox,\n","    cxpb=crossover_probability,\n","    mutpb=mutation_probability,\n","    ngen=generations,\n","    verbose=True\n",")\n","\n","# Find the best individual\n","best_individual = tools.selBest(result_population, k=1)[0]\n","selected_features = [i for i, bit in enumerate(best_individual) if bit == 1 and i < len(X.columns)]  # Bounds check\n","\n","# Select top 20 features based on their importance\n","if len(selected_features) > 10:\n","    feature_importances = pd.Series(best_individual).sort_values(ascending=False)\n","    selected_features = list(feature_importances.head(10).index)\n","\n","# Evaluate performance using the top 10 features\n","X_train_selected = X_train.iloc[:, selected_features]\n","X_val_selected = X_val.iloc[:, selected_features]\n","\n","final_model = RandomForestClassifier(random_state=42)\n","final_model.fit(X_train_selected, y_train)\n","final_predictions = final_model.predict(X_val_selected)\n","final_accuracy = accuracy_score(y_val, final_predictions)\n","\n","print(f\"Top 10 Selected features: {selected_features}\")\n","print(f\"Final Accuracy with top 10 selected features: {final_accuracy}\")\n","\n","# Save the top 20 selected features\n","pd.DataFrame({'Selected Features': selected_features}).to_csv('/content/CFV_top_10_selected_features.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1744743150031,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"dSe8hO4Eu0Zp","outputId":"958d1a20-aed4-4172-f1f0-2268065884e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset with top 10 features saved to: /content/CFV_Top_10_Features.csv\n"]}],"source":["selected_feature_columns = data.columns[selected_features]\n","# Create a filtered dataset with only the selected top 10 features\n","filtered_data = data[selected_feature_columns.tolist() + [data.columns[-1]]]\n","filtered_data_path = '/content/CFV_Top_10_Features.csv'\n","filtered_data.to_csv(filtered_data_path, index=False)\n","\n","print(f\"Filtered dataset with top 10 features saved to: {filtered_data_path}\")"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/CFV_Top_10_Features.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset\n","print(\"Dataset Columns:\", data.columns)\n","print(\"Shape before processing:\", data.shape)\n","print(data.head())\n","\n","# Check for target column\n","if 'True_Label' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'True_Label' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values\n","y = data['True_Label'].values\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n","\n","print(\"\\nShapes after reshaping:\")\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_val shape:\", X_val.shape)\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# First Conv1D layer\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Second Conv1D layer\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Third Conv1D layer\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Global pooling\n","model.add(GlobalMaxPooling1D())\n","\n","# Dense Layers\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the Model\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',\n","                       tf.keras.metrics.Precision(name='precision'),\n","                       tf.keras.metrics.Recall(name='recall')])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","print(\"\\nTraining model...\")\n","history = model.fit(X_train, y_train,\n","                    validation_data=(X_val, y_val),\n","                    epochs=100,\n","                    batch_size=32,\n","                    verbose=1)\n","\n","# Evaluate the model\n","print(\"\\nEvaluating model...\")\n","val_probs = model.predict(X_val)\n","val_predictions = (val_probs > 0.5).astype(int)\n","\n","# Metrics Calculation\n","accuracy = accuracy_score(y_val, val_predictions)\n","conf_matrix = confusion_matrix(y_val, val_predictions)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n","specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n","mcc = matthews_corrcoef(y_val, val_predictions)\n","kappa = cohen_kappa_score(y_val, val_predictions)\n","auc = roc_auc_score(y_val, val_probs)\n","\n","# Print Metrics\n","print(f\"\\nValidation Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n","print(f\"Cohen's Kappa: {kappa:.4f}\")\n","print(f\"Area Under Curve (AUC): {auc:.4f}\")\n","\n","# Classification Report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_val, val_predictions))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HGEfuWz-xgWK","executionInfo":{"status":"ok","timestamp":1744743247524,"user_tz":-360,"elapsed":44941,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"1195758d-91db-4694-a7f5-9945f3945e39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC', 'Decision Tree_ACC', 'Random Forest_ACC',\n","       'Logistic Regression_ACC', 'k-NN_ACC', 'Naive Bayes_ACC',\n","       'Neural Network_ACC', 'LightGBM_ACC', 'LightGBM_CTDC', 'AdaBoost_CTDC',\n","       'True_Label'],\n","      dtype='object')\n","Shape before processing: (300, 11)\n","    SVM_ACC  Decision Tree_ACC  Random Forest_ACC  Logistic Regression_ACC  \\\n","0  0.830810           0.919355           0.777252                 0.824422   \n","1  0.987548           1.000000           0.993010                 0.997619   \n","2  0.211028           0.000000           0.212838                 0.313903   \n","3  0.552428           0.000000           0.561655                 0.560973   \n","4  0.607083           0.500000           0.403041                 0.389037   \n","\n","   k-NN_ACC  Naive Bayes_ACC  Neural Network_ACC  LightGBM_ACC  LightGBM_CTDC  \\\n","0  1.000000         0.892723            0.994922      0.974355       0.999731   \n","1  1.000000         1.000000            1.000000      0.999663       0.999999   \n","2  1.000000         0.114252            0.003939      0.139887       0.072020   \n","3  0.333333         0.771621            0.996351      0.576563       0.991956   \n","4  0.000000         0.008400            0.015381      0.341967       0.149340   \n","\n","   AdaBoost_CTDC  True_Label  \n","0       0.517460           1  \n","1       0.570589           1  \n","2       0.473383           1  \n","3       0.521874           1  \n","4       0.492221           1  \n","\n","Shapes after reshaping:\n","X_train shape: (210, 10, 1)\n","X_val shape: (90, 10, 1)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_10\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m166,529\u001b[0m (650.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">166,529</span> (650.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m165,633\u001b[0m (647.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,633</span> (647.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Training model...\n","Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 222ms/step - accuracy: 0.7387 - loss: 0.7710 - precision: 0.7299 - recall: 0.7668 - val_accuracy: 0.8667 - val_loss: 0.6318 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.8855 - loss: 0.3660 - precision: 0.8550 - recall: 0.9384 - val_accuracy: 0.8667 - val_loss: 0.6074 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9058 - loss: 0.3939 - precision: 0.9259 - recall: 0.8908 - val_accuracy: 0.8667 - val_loss: 0.6005 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9018 - loss: 0.3218 - precision: 0.8926 - recall: 0.8900 - val_accuracy: 0.8667 - val_loss: 0.5950 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8849 - loss: 0.3372 - precision: 0.8683 - recall: 0.9207 - val_accuracy: 0.8667 - val_loss: 0.5872 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9005 - loss: 0.3306 - precision: 0.8597 - recall: 0.9343 - val_accuracy: 0.8667 - val_loss: 0.5805 - val_precision: 0.8667 - val_recall: 0.8667\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9146 - loss: 0.2846 - precision: 0.9315 - recall: 0.8947 - val_accuracy: 0.8778 - val_loss: 0.5710 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9334 - loss: 0.2600 - precision: 0.9316 - recall: 0.9445 - val_accuracy: 0.8667 - val_loss: 0.5689 - val_precision: 0.8511 - val_recall: 0.8889\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9170 - loss: 0.2516 - precision: 0.8920 - recall: 0.9413 - val_accuracy: 0.8778 - val_loss: 0.5670 - val_precision: 0.8542 - val_recall: 0.9111\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9180 - loss: 0.2285 - precision: 0.9050 - recall: 0.9236 - val_accuracy: 0.8778 - val_loss: 0.5580 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9325 - loss: 0.2067 - precision: 0.9414 - recall: 0.9209 - val_accuracy: 0.8778 - val_loss: 0.5544 - val_precision: 0.8542 - val_recall: 0.9111\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9449 - loss: 0.1569 - precision: 0.9567 - recall: 0.9262 - val_accuracy: 0.9000 - val_loss: 0.5529 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9129 - loss: 0.2093 - precision: 0.9145 - recall: 0.9152 - val_accuracy: 0.9111 - val_loss: 0.5589 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9029 - loss: 0.2219 - precision: 0.8798 - recall: 0.9308 - val_accuracy: 0.9111 - val_loss: 0.5606 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8988 - loss: 0.3309 - precision: 0.8722 - recall: 0.9297 - val_accuracy: 0.9111 - val_loss: 0.5603 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9300 - loss: 0.1975 - precision: 0.9084 - recall: 0.9561 - val_accuracy: 0.9111 - val_loss: 0.5571 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9322 - loss: 0.2048 - precision: 0.9374 - recall: 0.9374 - val_accuracy: 0.9111 - val_loss: 0.5472 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9373 - loss: 0.2039 - precision: 0.9210 - recall: 0.9553 - val_accuracy: 0.9111 - val_loss: 0.5334 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9150 - loss: 0.2270 - precision: 0.9167 - recall: 0.9218 - val_accuracy: 0.9111 - val_loss: 0.5306 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9430 - loss: 0.2106 - precision: 0.9368 - recall: 0.9575 - val_accuracy: 0.9111 - val_loss: 0.5259 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9297 - loss: 0.1597 - precision: 0.9405 - recall: 0.9229 - val_accuracy: 0.9111 - val_loss: 0.5205 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9583 - loss: 0.1531 - precision: 0.9681 - recall: 0.9513 - val_accuracy: 0.9111 - val_loss: 0.5152 - val_precision: 0.8776 - val_recall: 0.9556\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9322 - loss: 0.1922 - precision: 0.9300 - recall: 0.9432 - val_accuracy: 0.8889 - val_loss: 0.5275 - val_precision: 0.8431 - val_recall: 0.9556\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9364 - loss: 0.1715 - precision: 0.9197 - recall: 0.9501 - val_accuracy: 0.8778 - val_loss: 0.5225 - val_precision: 0.8400 - val_recall: 0.9333\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9424 - loss: 0.1929 - precision: 0.9483 - recall: 0.9374 - val_accuracy: 0.9000 - val_loss: 0.5121 - val_precision: 0.8750 - val_recall: 0.9333\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9506 - loss: 0.1323 - precision: 0.9441 - recall: 0.9567 - val_accuracy: 0.8889 - val_loss: 0.4936 - val_precision: 0.8723 - val_recall: 0.9111\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9261 - loss: 0.1787 - precision: 0.9273 - recall: 0.9291 - val_accuracy: 0.9000 - val_loss: 0.4888 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9568 - loss: 0.1297 - precision: 0.9515 - recall: 0.9603 - val_accuracy: 0.9000 - val_loss: 0.4660 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9371 - loss: 0.1462 - precision: 0.9132 - recall: 0.9703 - val_accuracy: 0.9000 - val_loss: 0.4599 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9551 - loss: 0.1355 - precision: 0.9385 - recall: 0.9697 - val_accuracy: 0.9000 - val_loss: 0.4494 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9392 - loss: 0.1603 - precision: 0.9334 - recall: 0.9528 - val_accuracy: 0.9000 - val_loss: 0.4439 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9307 - loss: 0.1818 - precision: 0.9309 - recall: 0.9383 - val_accuracy: 0.9000 - val_loss: 0.4471 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9228 - loss: 0.1855 - precision: 0.8993 - recall: 0.9310 - val_accuracy: 0.9000 - val_loss: 0.4526 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9509 - loss: 0.1166 - precision: 0.9421 - recall: 0.9633 - val_accuracy: 0.9000 - val_loss: 0.4344 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9607 - loss: 0.1360 - precision: 0.9554 - recall: 0.9708 - val_accuracy: 0.9000 - val_loss: 0.4376 - val_precision: 0.8913 - val_recall: 0.9111\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9359 - loss: 0.2330 - precision: 0.9593 - recall: 0.9229 - val_accuracy: 0.8778 - val_loss: 0.4392 - val_precision: 0.8542 - val_recall: 0.9111\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9474 - loss: 0.1910 - precision: 0.9314 - recall: 0.9547 - val_accuracy: 0.8778 - val_loss: 0.4259 - val_precision: 0.8542 - val_recall: 0.9111\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9473 - loss: 0.1405 - precision: 0.9131 - recall: 0.9902 - val_accuracy: 0.9111 - val_loss: 0.3921 - val_precision: 0.9111 - val_recall: 0.9111\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9625 - loss: 0.0965 - precision: 0.9671 - recall: 0.9564 - val_accuracy: 0.9000 - val_loss: 0.3833 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9644 - loss: 0.1211 - precision: 0.9446 - recall: 0.9856 - val_accuracy: 0.9000 - val_loss: 0.4056 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9349 - loss: 0.2072 - precision: 0.9197 - recall: 0.9559 - val_accuracy: 0.9222 - val_loss: 0.3748 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9413 - loss: 0.2012 - precision: 0.9325 - recall: 0.9517 - val_accuracy: 0.9222 - val_loss: 0.3517 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9518 - loss: 0.1149 - precision: 0.9367 - recall: 0.9700 - val_accuracy: 0.9222 - val_loss: 0.3437 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9571 - loss: 0.1208 - precision: 0.9614 - recall: 0.9555 - val_accuracy: 0.9222 - val_loss: 0.3552 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9445 - loss: 0.1824 - precision: 0.9425 - recall: 0.9523 - val_accuracy: 0.9222 - val_loss: 0.3436 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9686 - loss: 0.1350 - precision: 0.9572 - recall: 0.9829 - val_accuracy: 0.9111 - val_loss: 0.3202 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9605 - loss: 0.1001 - precision: 0.9693 - recall: 0.9531 - val_accuracy: 0.9111 - val_loss: 0.3073 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9481 - loss: 0.1592 - precision: 0.9440 - recall: 0.9604 - val_accuracy: 0.9111 - val_loss: 0.2884 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9392 - loss: 0.1573 - precision: 0.9415 - recall: 0.9345 - val_accuracy: 0.8889 - val_loss: 0.2814 - val_precision: 0.9268 - val_recall: 0.8444\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9234 - loss: 0.1332 - precision: 0.9101 - recall: 0.9444 - val_accuracy: 0.9111 - val_loss: 0.2782 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9780 - loss: 0.0913 - precision: 0.9706 - recall: 0.9868 - val_accuracy: 0.9000 - val_loss: 0.2896 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9761 - loss: 0.1134 - precision: 0.9869 - recall: 0.9650 - val_accuracy: 0.9000 - val_loss: 0.2916 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9575 - loss: 0.1575 - precision: 0.9292 - recall: 0.9929 - val_accuracy: 0.9000 - val_loss: 0.2859 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9677 - loss: 0.0956 - precision: 0.9458 - recall: 0.9890 - val_accuracy: 0.9000 - val_loss: 0.3095 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9573 - loss: 0.1275 - precision: 0.9401 - recall: 0.9790 - val_accuracy: 0.9000 - val_loss: 0.3218 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9612 - loss: 0.1252 - precision: 0.9481 - recall: 0.9737 - val_accuracy: 0.9111 - val_loss: 0.3114 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9185 - loss: 0.1752 - precision: 0.8890 - recall: 0.9396 - val_accuracy: 0.9111 - val_loss: 0.3108 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9693 - loss: 0.1092 - precision: 0.9712 - recall: 0.9678 - val_accuracy: 0.9111 - val_loss: 0.2920 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9644 - loss: 0.0899 - precision: 0.9651 - recall: 0.9661 - val_accuracy: 0.9111 - val_loss: 0.2923 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9711 - loss: 0.1187 - precision: 0.9670 - recall: 0.9766 - val_accuracy: 0.9222 - val_loss: 0.2896 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9803 - loss: 0.0713 - precision: 0.9755 - recall: 0.9868 - val_accuracy: 0.9111 - val_loss: 0.3236 - val_precision: 0.9744 - val_recall: 0.8444\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9686 - loss: 0.1059 - precision: 0.9522 - recall: 0.9878 - val_accuracy: 0.9333 - val_loss: 0.2834 - val_precision: 0.9756 - val_recall: 0.8889\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9752 - loss: 0.0715 - precision: 0.9606 - recall: 0.9927 - val_accuracy: 0.9111 - val_loss: 0.3039 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9715 - loss: 0.0923 - precision: 0.9652 - recall: 0.9781 - val_accuracy: 0.9111 - val_loss: 0.3474 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9532 - loss: 0.1058 - precision: 0.9687 - recall: 0.9392 - val_accuracy: 0.9222 - val_loss: 0.2882 - val_precision: 0.9318 - val_recall: 0.9111\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9644 - loss: 0.0770 - precision: 0.9412 - recall: 0.9904 - val_accuracy: 0.9111 - val_loss: 0.3027 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9493 - loss: 0.1323 - precision: 0.9378 - recall: 0.9519 - val_accuracy: 0.9000 - val_loss: 0.3280 - val_precision: 0.9500 - val_recall: 0.8444\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9652 - loss: 0.0920 - precision: 0.9466 - recall: 0.9865 - val_accuracy: 0.9000 - val_loss: 0.3278 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9648 - loss: 0.1333 - precision: 0.9585 - recall: 0.9741 - val_accuracy: 0.9000 - val_loss: 0.3464 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9686 - loss: 0.0688 - precision: 0.9647 - recall: 0.9709 - val_accuracy: 0.9000 - val_loss: 0.3439 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9753 - loss: 0.0585 - precision: 0.9563 - recall: 0.9963 - val_accuracy: 0.9000 - val_loss: 0.3243 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9801 - loss: 0.0838 - precision: 0.9728 - recall: 0.9874 - val_accuracy: 0.9000 - val_loss: 0.3573 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9739 - loss: 0.1016 - precision: 0.9671 - recall: 0.9789 - val_accuracy: 0.9111 - val_loss: 0.3719 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9395 - loss: 0.1317 - precision: 0.9250 - recall: 0.9529 - val_accuracy: 0.9000 - val_loss: 0.3623 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9645 - loss: 0.1477 - precision: 0.9533 - recall: 0.9794 - val_accuracy: 0.9222 - val_loss: 0.3630 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9548 - loss: 0.1775 - precision: 0.9616 - recall: 0.9468 - val_accuracy: 0.9222 - val_loss: 0.3382 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9728 - loss: 0.0802 - precision: 0.9793 - recall: 0.9669 - val_accuracy: 0.9333 - val_loss: 0.3148 - val_precision: 0.9535 - val_recall: 0.9111\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9827 - loss: 0.0520 - precision: 0.9693 - recall: 0.9976 - val_accuracy: 0.9111 - val_loss: 0.3453 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9558 - loss: 0.1079 - precision: 0.9476 - recall: 0.9626 - val_accuracy: 0.9111 - val_loss: 0.3724 - val_precision: 0.9512 - val_recall: 0.8667\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9798 - loss: 0.1118 - precision: 0.9805 - recall: 0.9773 - val_accuracy: 0.9000 - val_loss: 0.3918 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9795 - loss: 0.0667 - precision: 0.9604 - recall: 0.9976 - val_accuracy: 0.9000 - val_loss: 0.4327 - val_precision: 0.9286 - val_recall: 0.8667\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9541 - loss: 0.1128 - precision: 0.9328 - recall: 0.9801 - val_accuracy: 0.9111 - val_loss: 0.4183 - val_precision: 0.9744 - val_recall: 0.8444\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9630 - loss: 0.1112 - precision: 0.9348 - recall: 0.9924 - val_accuracy: 0.8778 - val_loss: 0.4981 - val_precision: 0.9722 - val_recall: 0.7778\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9572 - loss: 0.0756 - precision: 0.9849 - recall: 0.9337 - val_accuracy: 0.9222 - val_loss: 0.4312 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9662 - loss: 0.1039 - precision: 0.9611 - recall: 0.9711 - val_accuracy: 0.9333 - val_loss: 0.3903 - val_precision: 0.9756 - val_recall: 0.8889\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9567 - loss: 0.0791 - precision: 0.9297 - recall: 0.9911 - val_accuracy: 0.8889 - val_loss: 0.4927 - val_precision: 0.9730 - val_recall: 0.8000\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9608 - loss: 0.0908 - precision: 0.9653 - recall: 0.9585 - val_accuracy: 0.9333 - val_loss: 0.4368 - val_precision: 0.9756 - val_recall: 0.8889\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9832 - loss: 0.0548 - precision: 0.9789 - recall: 0.9875 - val_accuracy: 0.9111 - val_loss: 0.3878 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9700 - loss: 0.1077 - precision: 0.9487 - recall: 0.9963 - val_accuracy: 0.9222 - val_loss: 0.4178 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9788 - loss: 0.1133 - precision: 1.0000 - recall: 0.9609 - val_accuracy: 0.9000 - val_loss: 0.4253 - val_precision: 0.9737 - val_recall: 0.8222\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9730 - loss: 0.0782 - precision: 0.9732 - recall: 0.9753 - val_accuracy: 0.9222 - val_loss: 0.3981 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9716 - loss: 0.0700 - precision: 0.9482 - recall: 0.9949 - val_accuracy: 0.9222 - val_loss: 0.3929 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9815 - loss: 0.0454 - precision: 0.9780 - recall: 0.9873 - val_accuracy: 0.9111 - val_loss: 0.4373 - val_precision: 0.9744 - val_recall: 0.8444\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9842 - loss: 0.0652 - precision: 0.9854 - recall: 0.9828 - val_accuracy: 0.9111 - val_loss: 0.4576 - val_precision: 0.9744 - val_recall: 0.8444\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9785 - loss: 0.0564 - precision: 0.9794 - recall: 0.9779 - val_accuracy: 0.9222 - val_loss: 0.4100 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9865 - loss: 0.0642 - precision: 0.9777 - recall: 0.9964 - val_accuracy: 0.9222 - val_loss: 0.4517 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9602 - loss: 0.1366 - precision: 0.9729 - recall: 0.9419 - val_accuracy: 0.9111 - val_loss: 0.4276 - val_precision: 0.9744 - val_recall: 0.8444\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9854 - loss: 0.0660 - precision: 0.9729 - recall: 1.0000 - val_accuracy: 0.9222 - val_loss: 0.4349 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9826 - loss: 0.0596 - precision: 0.9840 - recall: 0.9817 - val_accuracy: 0.9222 - val_loss: 0.4212 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9779 - loss: 0.0674 - precision: 0.9812 - recall: 0.9762 - val_accuracy: 0.9111 - val_loss: 0.3893 - val_precision: 0.9744 - val_recall: 0.8444\n","\n","Evaluating model...\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n","\n","Validation Accuracy: 0.9111\n","Sensitivity (Recall): 0.8444\n","Specificity: 0.9778\n","Matthews Correlation Coefficient (MCC): 0.8296\n","Cohen's Kappa: 0.8222\n","Area Under Curve (AUC): 0.9704\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.98      0.92        45\n","           1       0.97      0.84      0.90        45\n","\n","    accuracy                           0.91        90\n","   macro avg       0.92      0.91      0.91        90\n","weighted avg       0.92      0.91      0.91        90\n","\n"]}]},{"cell_type":"code","source":["#cross validation for cfv\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Load the dataset\n","dataset_path = \"/content/CFV_Top_10_Features.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['True_Label']).values\n","y = data['True_Label'].values\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Reshape for Conv1D\n","X = X.reshape(X.shape[0], X.shape[1], 1)\n","\n","# Set up Stratified K-Fold\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# For storing metrics\n","accs, sens_list, specs, mccs, kappas, aucs = [], [], [], [], [], []\n","\n","fold = 1\n","for train_idx, val_idx in kf.split(X, y):\n","    print(f\"\\n----- Fold {fold} -----\")\n","\n","    X_train, X_val = X[train_idx], X[val_idx]\n","    y_train, y_val = y[train_idx], y[val_idx]\n","\n","    # Define model\n","    model = Sequential()\n","    model.add(Conv1D(64, 3, activation='relu', input_shape=(X.shape[1], 1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(GlobalMaxPooling1D())\n","\n","    model.add(Dense(128, activation='swish'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(64, activation='swish'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    # Train\n","    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n","\n","    # Predict\n","    val_probs = model.predict(X_val)\n","    val_pred = (val_probs > 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_val, val_pred)\n","    conf = confusion_matrix(y_val, val_pred)\n","    tn, fp, fn, tp = conf.ravel()\n","    sens = tp / (tp + fn) if (tp + fn) else 0\n","    spec = tn / (tn + fp) if (tn + fp) else 0\n","    mcc = matthews_corrcoef(y_val, val_pred)\n","    kappa = cohen_kappa_score(y_val, val_pred)\n","    auc = roc_auc_score(y_val, val_probs)\n","\n","    # Append to lists\n","    accs.append(acc)\n","    sens_list.append(sens)\n","    specs.append(spec)\n","    mccs.append(mcc)\n","    kappas.append(kappa)\n","    aucs.append(auc)\n","\n","    print(f\"Accuracy: {acc:.4f}, Sensitivity: {sens:.4f}, Specificity: {spec:.4f}, MCC: {mcc:.4f}, Kappa: {kappa:.4f}, AUC: {auc:.4f}\")\n","    fold += 1\n","\n","# Print average performance\n","print(\"\\n===== Cross-Validation Results =====\")\n","print(f\"Average Accuracy: {np.mean(accs):.4f}\")\n","print(f\"Average Sensitivity: {np.mean(sens_list):.4f}\")\n","print(f\"Average Specificity: {np.mean(specs):.4f}\")\n","print(f\"Average MCC: {np.mean(mccs):.4f}\")\n","print(f\"Average Kappa: {np.mean(kappas):.4f}\")\n","print(f\"Average AUC: {np.mean(aucs):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cl3HB6b68p8R","executionInfo":{"status":"ok","timestamp":1744746648248,"user_tz":-360,"elapsed":137460,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"2ae197b8-3400-4d3f-8835-0e775313c2c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","----- Fold 1 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n","Accuracy: 0.9167, Sensitivity: 0.9667, Specificity: 0.8667, MCC: 0.8375, Kappa: 0.8333, AUC: 0.9667\n","\n","----- Fold 2 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n","Accuracy: 0.9167, Sensitivity: 0.9667, Specificity: 0.8667, MCC: 0.8375, Kappa: 0.8333, AUC: 0.9933\n","\n","----- Fold 3 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n","Accuracy: 0.9333, Sensitivity: 0.9000, Specificity: 0.9667, MCC: 0.8686, Kappa: 0.8667, AUC: 0.9578\n","\n","----- Fold 4 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n","Accuracy: 0.8833, Sensitivity: 0.8667, Specificity: 0.9000, MCC: 0.7671, Kappa: 0.7667, AUC: 0.9500\n","\n","----- Fold 5 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n","Accuracy: 0.9000, Sensitivity: 0.9000, Specificity: 0.9000, MCC: 0.8000, Kappa: 0.8000, AUC: 0.9433\n","\n","===== Cross-Validation Results =====\n","Average Accuracy: 0.9100\n","Average Sensitivity: 0.9200\n","Average Specificity: 0.9000\n","Average MCC: 0.8222\n","Average Kappa: 0.8200\n","Average AUC: 0.9622\n"]}]},{"cell_type":"markdown","metadata":{"id":"qfB6BsmDJkgm"},"source":["PFV (Probability Feature Vector)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2919,"status":"ok","timestamp":1744741222298,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"qTbyC6WxKbcN","outputId":"0e9be0a5-ac5d-4035-f71f-18f09f1dd9b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/Optuna_Dataset Marge PFV.csv\n"]}],"source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"ACC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_AAC_OPTUNA_probability_predictions.csv\",\n","    \"CTDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTDC_OPTUNA_probability_predictions.csv\",\n","    \"CTD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTD_OPTUNA_probability_predictions.csv\",\n","    \"GDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_GDC_OPTUNA_probability_predictions.csv\",\n","    \"PAAC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_PAAC_OPTUNA_probability_predictions.csv\",\n","    \"PCP\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_PCP_OPTUNA_probability_predictions.csv\",\n","    \"TPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_TPC_OPTUNA_probability_predictions.csv\",\n","    \"CTDT\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTDT_OPTUNA_probability_predictions.csv\",\n","    \"DPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_DPC_OPTUNA_probability_predictions.csv\",\n","    \"CTDD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTDD_OPTUNA_probability_predictions.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/Optuna_Dataset Marge PFV.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1744741225549,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"7d5z3mrMKffb","outputId":"3ec49655-b7db-4715-d6d5-35e2e68ce312"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the merged dataset: (300, 121)\n"]}],"source":["# Check the shape of the merged dataset\n","print(\"Shape of the merged dataset:\", combined_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WZxp0YYKfh6"},"outputs":[],"source":["df=pd.read_csv(\"/content/Optuna_Dataset Marge PFV.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1744741231521,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"bexOUGn-K2Uj","outputId":"23325dc2-fe85-422b-eafe-a3eef655cba8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 121)"]},"metadata":{},"execution_count":24}],"source":["df.shape"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/Optuna_Dataset Marge PFV.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional: Uncomment if needed to verify column names)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'True_Label' column for binary classification\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'True_Label' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values  # Features\n","y = data['Target'].values                 # Labels\n","\n","# Split data into training and validation sets (70-30 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# Stacked Conv1D layers with BatchNormalization and Dropout\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","# LSTM layer for sequential dependencies\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","\n","# Dense Layers with Dropout\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n","\n","# Compile the Model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n","\n","# Evaluate the model on the validation data\n","val_probs = model.predict(X_val)\n","val_predictions = (val_probs > 0.5).astype(int)\n","\n","# Compute metrics\n","accuracy = accuracy_score(y_val, val_predictions)\n","conf_matrix = confusion_matrix(y_val, val_predictions)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # Recall\n","specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # True Negative Rate\n","mcc = matthews_corrcoef(y_val, val_predictions)\n","kappa = cohen_kappa_score(y_val, val_predictions)\n","auc = roc_auc_score(y_val, val_probs)\n","\n","# Print evaluation metrics\n","print(\"\\nValidation Accuracy:\", accuracy)\n","print(\"Sensitivity (Recall):\", sensitivity)\n","print(\"Specificity:\", specificity)\n","print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n","print(\"Cohen's Kappa:\", kappa)\n","print(\"Area Under Curve (AUC):\", auc)\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nFSfnviMrBUX","executionInfo":{"status":"ok","timestamp":1744743475780,"user_tz":-360,"elapsed":132578,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"37cc85ff-ac76-47fc-ad47-431010e9f47d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC', 'Decision Tree_ACC', 'Random Forest_ACC',\n","       'Logistic Regression_ACC', 'k-NN_ACC', 'Naive Bayes_ACC',\n","       'Gradient Boosting_ACC', 'XGBoost_ACC', 'LightGBM_ACC', 'AdaBoost_ACC',\n","       ...\n","       'Logistic Regression_CTDD', 'k-NN_CTDD', 'Naive Bayes_CTDD',\n","       'Gradient Boosting_CTDD', 'XGBoost_CTDD', 'LightGBM_CTDD',\n","       'AdaBoost_CTDD', 'Neural Network_CTDD', 'MLP_CTDD', 'Target'],\n","      dtype='object', length=121)\n","    SVM_ACC  Decision Tree_ACC  Random Forest_ACC  Logistic Regression_ACC  \\\n","0  0.823857           0.977778           0.719734                 0.828746   \n","1  0.985450           1.000000           1.000000                 0.997871   \n","2  0.223416           0.000000           0.200000                 0.312154   \n","3  0.555763           0.000000           0.643902                 0.561625   \n","4  0.605909           0.000000           0.342683                 0.384698   \n","\n","   k-NN_ACC  Naive Bayes_ACC  Gradient Boosting_ACC  XGBoost_ACC  \\\n","0  1.000000         0.892723               0.999979     0.917172   \n","1  1.000000         1.000000               0.999841     0.999149   \n","2  1.000000         0.114252               0.079732     0.053543   \n","3  0.333333         0.771621               0.693876     0.723154   \n","4  0.000000         0.008400               0.391353     0.366223   \n","\n","   LightGBM_ACC  AdaBoost_ACC  ...  Logistic Regression_CTDD  k-NN_CTDD  \\\n","0      0.983490      0.508819  ...                  0.983757        1.0   \n","1      0.999960      0.631024  ...                  0.999173        1.0   \n","2      0.064879      0.457909  ...                  0.466126        1.0   \n","3      0.039914      0.520116  ...                  0.642504        1.0   \n","4      0.507740      0.501183  ...                  0.361238        0.0   \n","\n","   Naive Bayes_CTDD  Gradient Boosting_CTDD  XGBoost_CTDD  LightGBM_CTDD  \\\n","0               1.0                0.925501      0.984638       0.969006   \n","1               1.0                0.980678      0.995568       0.998936   \n","2               1.0                0.409673      0.301454       0.703552   \n","3               1.0                0.906457      0.972626       0.908195   \n","4               0.0                0.098809      0.061560       0.320076   \n","\n","   AdaBoost_CTDD  Neural Network_CTDD  MLP_CTDD  Target  \n","0       0.501519             1.000000  1.000000       1  \n","1       0.554940             1.000000  1.000000       1  \n","2       0.495854             0.998733  0.792769       1  \n","3       0.547745             0.996954  0.989086       1  \n","4       0.492246             0.000002  0.000047       1  \n","\n","[5 rows x 121 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_11\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_15 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_16 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m82,176\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,129\u001b[0m (875.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,129</span> (875.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,233\u001b[0m (872.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,233</span> (872.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 320ms/step - accuracy: 0.7369 - loss: 0.5206 - val_accuracy: 0.8889 - val_loss: 0.6706\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - accuracy: 0.9114 - loss: 0.3283 - val_accuracy: 0.5000 - val_loss: 0.6649\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259ms/step - accuracy: 0.8991 - loss: 0.2953 - val_accuracy: 0.5000 - val_loss: 0.6572\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - accuracy: 0.8891 - loss: 0.2924 - val_accuracy: 0.5000 - val_loss: 0.6503\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.9217 - loss: 0.1996 - val_accuracy: 0.5556 - val_loss: 0.6319\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.9059 - loss: 0.1681 - val_accuracy: 0.7667 - val_loss: 0.6126\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9223 - loss: 0.2113 - val_accuracy: 0.8444 - val_loss: 0.6055\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9286 - loss: 0.2058 - val_accuracy: 0.8556 - val_loss: 0.6020\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9185 - loss: 0.1850 - val_accuracy: 0.8889 - val_loss: 0.5809\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9449 - loss: 0.1859 - val_accuracy: 0.9000 - val_loss: 0.5543\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9066 - loss: 0.1933 - val_accuracy: 0.9000 - val_loss: 0.5422\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.9063 - loss: 0.1765 - val_accuracy: 0.9000 - val_loss: 0.5352\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9084 - loss: 0.1829 - val_accuracy: 0.9000 - val_loss: 0.5312\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9408 - loss: 0.1701 - val_accuracy: 0.9222 - val_loss: 0.5119\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.9310 - loss: 0.1738 - val_accuracy: 0.9111 - val_loss: 0.5117\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.9256 - loss: 0.1681 - val_accuracy: 0.8000 - val_loss: 0.5120\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.9566 - loss: 0.1371 - val_accuracy: 0.9000 - val_loss: 0.4410\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9117 - loss: 0.1558 - val_accuracy: 0.9111 - val_loss: 0.3681\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9280 - loss: 0.1569 - val_accuracy: 0.9000 - val_loss: 0.3559\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9384 - loss: 0.1858 - val_accuracy: 0.8778 - val_loss: 0.3981\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9726 - loss: 0.1228 - val_accuracy: 0.8111 - val_loss: 0.4261\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9395 - loss: 0.1816 - val_accuracy: 0.6000 - val_loss: 0.5664\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9526 - loss: 0.1207 - val_accuracy: 0.8889 - val_loss: 0.4147\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9376 - loss: 0.2067 - val_accuracy: 0.9000 - val_loss: 0.4350\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9658 - loss: 0.1201 - val_accuracy: 0.8889 - val_loss: 0.5312\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9445 - loss: 0.1358 - val_accuracy: 0.8333 - val_loss: 0.6192\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9412 - loss: 0.1270 - val_accuracy: 0.7333 - val_loss: 0.5883\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - accuracy: 0.9583 - loss: 0.1206 - val_accuracy: 0.7778 - val_loss: 0.5942\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9587 - loss: 0.1006 - val_accuracy: 0.7444 - val_loss: 0.6495\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.9664 - loss: 0.0805 - val_accuracy: 0.6333 - val_loss: 1.0300\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9567 - loss: 0.1214 - val_accuracy: 0.5111 - val_loss: 1.4300\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9729 - loss: 0.0601 - val_accuracy: 0.5444 - val_loss: 1.5844\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9735 - loss: 0.0785 - val_accuracy: 0.5111 - val_loss: 2.0083\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9676 - loss: 0.0683 - val_accuracy: 0.5444 - val_loss: 2.3178\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9719 - loss: 0.1219 - val_accuracy: 0.5444 - val_loss: 1.8505\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9555 - loss: 0.1130 - val_accuracy: 0.5778 - val_loss: 1.8681\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9767 - loss: 0.1000 - val_accuracy: 0.6333 - val_loss: 1.4833\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9756 - loss: 0.0994 - val_accuracy: 0.9111 - val_loss: 0.7073\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9667 - loss: 0.0943 - val_accuracy: 0.8556 - val_loss: 1.0318\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9695 - loss: 0.0980 - val_accuracy: 0.7667 - val_loss: 1.7687\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9786 - loss: 0.0614 - val_accuracy: 0.6556 - val_loss: 1.5210\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 0.9541 - loss: 0.0953 - val_accuracy: 0.9111 - val_loss: 0.5769\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 0.9613 - loss: 0.0705 - val_accuracy: 0.9333 - val_loss: 0.4763\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9674 - loss: 0.1357 - val_accuracy: 0.9222 - val_loss: 0.3794\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9444 - loss: 0.1364 - val_accuracy: 0.9111 - val_loss: 0.4080\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9723 - loss: 0.0611 - val_accuracy: 0.9222 - val_loss: 0.4543\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.9815 - loss: 0.0559 - val_accuracy: 0.9222 - val_loss: 0.4092\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9652 - loss: 0.0873 - val_accuracy: 0.9222 - val_loss: 0.3401\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9730 - loss: 0.0558 - val_accuracy: 0.9222 - val_loss: 0.4081\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9715 - loss: 0.0626 - val_accuracy: 0.9000 - val_loss: 0.5200\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9737 - loss: 0.0879 - val_accuracy: 0.8778 - val_loss: 0.4011\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9587 - loss: 0.1481 - val_accuracy: 0.9222 - val_loss: 0.3438\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - accuracy: 0.9700 - loss: 0.0794 - val_accuracy: 0.9111 - val_loss: 0.3587\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - accuracy: 0.9820 - loss: 0.0490 - val_accuracy: 0.9111 - val_loss: 0.3765\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9768 - loss: 0.0495 - val_accuracy: 0.9111 - val_loss: 0.3860\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9827 - loss: 0.0625 - val_accuracy: 0.9111 - val_loss: 0.3740\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9895 - loss: 0.0541 - val_accuracy: 0.9111 - val_loss: 0.3149\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9643 - loss: 0.1177 - val_accuracy: 0.9333 - val_loss: 0.8414\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9787 - loss: 0.0952 - val_accuracy: 0.9333 - val_loss: 2.4485\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9907 - loss: 0.0490 - val_accuracy: 0.8444 - val_loss: 0.7988\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9692 - loss: 0.0772 - val_accuracy: 0.7889 - val_loss: 0.9058\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.9779 - loss: 0.0676 - val_accuracy: 0.9222 - val_loss: 0.5099\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9831 - loss: 0.0545 - val_accuracy: 0.9444 - val_loss: 0.9268\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.9497 - loss: 0.1258 - val_accuracy: 0.9111 - val_loss: 2.0756\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9572 - loss: 0.2198 - val_accuracy: 0.9222 - val_loss: 0.7060\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.9755 - loss: 0.0861 - val_accuracy: 0.9000 - val_loss: 0.8299\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9752 - loss: 0.0789 - val_accuracy: 0.9222 - val_loss: 0.5842\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9548 - loss: 0.1221 - val_accuracy: 0.9222 - val_loss: 0.4964\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9583 - loss: 0.1266 - val_accuracy: 0.9000 - val_loss: 0.6703\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9796 - loss: 0.0551 - val_accuracy: 0.9111 - val_loss: 0.4314\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9533 - loss: 0.1565 - val_accuracy: 0.9333 - val_loss: 0.2371\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9494 - loss: 0.3041 - val_accuracy: 0.8556 - val_loss: 0.2865\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9537 - loss: 0.2054 - val_accuracy: 0.9000 - val_loss: 0.6419\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9625 - loss: 0.1009 - val_accuracy: 0.9333 - val_loss: 0.7182\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9844 - loss: 0.0590 - val_accuracy: 0.9111 - val_loss: 0.5871\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9776 - loss: 0.0790 - val_accuracy: 0.9444 - val_loss: 0.3811\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.9877 - loss: 0.0469 - val_accuracy: 0.9444 - val_loss: 1.2343\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.9824 - loss: 0.0669 - val_accuracy: 0.9222 - val_loss: 0.4346\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.9880 - loss: 0.0600 - val_accuracy: 0.9333 - val_loss: 0.3235\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.9759 - loss: 0.0488 - val_accuracy: 0.8222 - val_loss: 0.3534\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.9843 - loss: 0.0750 - val_accuracy: 0.9222 - val_loss: 0.2636\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.9824 - loss: 0.0471 - val_accuracy: 0.9333 - val_loss: 0.4017\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9744 - loss: 0.0497 - val_accuracy: 0.9333 - val_loss: 0.4921\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9854 - loss: 0.0451 - val_accuracy: 0.9222 - val_loss: 0.5253\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9946 - loss: 0.0319 - val_accuracy: 0.9444 - val_loss: 0.5619\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9816 - loss: 0.0631 - val_accuracy: 0.9222 - val_loss: 0.5517\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.9834 - loss: 0.0474 - val_accuracy: 0.9333 - val_loss: 0.5385\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9892 - loss: 0.0539 - val_accuracy: 0.9111 - val_loss: 0.6096\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9882 - loss: 0.0255 - val_accuracy: 0.9222 - val_loss: 0.6694\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - accuracy: 0.9820 - loss: 0.0514 - val_accuracy: 0.9222 - val_loss: 0.4278\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - accuracy: 0.9955 - loss: 0.0258 - val_accuracy: 0.9333 - val_loss: 0.4665\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9933 - loss: 0.0249 - val_accuracy: 0.9111 - val_loss: 0.4484\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.9955 - loss: 0.0202 - val_accuracy: 0.9000 - val_loss: 0.8808\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9815 - loss: 0.0595 - val_accuracy: 0.8667 - val_loss: 0.5020\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.9802 - loss: 0.0499 - val_accuracy: 0.8889 - val_loss: 0.8247\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9874 - loss: 0.0363 - val_accuracy: 0.9333 - val_loss: 1.6625\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9910 - loss: 0.0500 - val_accuracy: 0.9000 - val_loss: 1.0040\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9854 - loss: 0.0388 - val_accuracy: 0.9333 - val_loss: 0.5928\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9882 - loss: 0.0470 - val_accuracy: 0.9000 - val_loss: 0.5115\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9829 - loss: 0.0318 - val_accuracy: 0.8889 - val_loss: 0.4555\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step\n","\n","Validation Accuracy: 0.8888888888888888\n","Sensitivity (Recall): 0.8222222222222222\n","Specificity: 0.9555555555555556\n","Matthews Correlation Coefficient (MCC): 0.7847849263290312\n","Cohen's Kappa: 0.7777777777777778\n","Area Under Curve (AUC): 0.9698765432098765\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.84      0.96      0.90        45\n","           1       0.95      0.82      0.88        45\n","\n","    accuracy                           0.89        90\n","   macro avg       0.90      0.89      0.89        90\n","weighted avg       0.90      0.89      0.89        90\n","\n"]}]},{"cell_type":"code","source":["#CROSS VALIDATION FOR pfv\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","\n","# Load dataset\n","dataset_path = \"/content/Optuna_Dataset Marge PFV.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values\n","y = data['Target'].values\n","\n","# Initialize StratifiedKFold\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Track metrics across folds\n","metrics = {\n","    \"accuracy\": [],\n","    \"sensitivity\": [],\n","    \"specificity\": [],\n","    \"mcc\": [],\n","    \"kappa\": [],\n","    \"auc\": []\n","}\n","\n","fold = 1\n","for train_idx, val_idx in kf.split(X, y):\n","    print(f\"\\n========== Fold {fold} ==========\")\n","\n","    X_train, X_val = X[train_idx], X[val_idx]\n","    y_train, y_val = y[train_idx], y[val_idx]\n","\n","    # Normalize\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_val = scaler.transform(X_val)\n","\n","    # Reshape for Conv1D\n","    X_train = X_train[..., np.newaxis]\n","    X_val = X_val[..., np.newaxis]\n","\n","    # Build model\n","    def build_model():\n","        model = Sequential()\n","        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling1D(pool_size=2))\n","        model.add(Dropout(0.3))\n","\n","        model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.3))\n","\n","        model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling1D(pool_size=2))\n","        model.add(Dropout(0.3))\n","\n","        model.add(LSTM(64, activation='relu'))\n","\n","        model.add(Dense(128, activation='swish'))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(64, activation='swish'))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(1, activation='sigmoid'))\n","\n","        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    model = build_model()\n","\n","    # Train model\n","    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_data=(X_val, y_val))\n","\n","    # Predict\n","    val_probs = model.predict(X_val)\n","    val_preds = (val_probs > 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_val, val_preds)\n","    cm = confusion_matrix(y_val, val_preds)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    sens = tp / (tp + fn) if (tp + fn) != 0 else 0\n","    spec = tn / (tn + fp) if (tn + fp) != 0 else 0\n","    mcc = matthews_corrcoef(y_val, val_preds)\n","    kappa = cohen_kappa_score(y_val, val_preds)\n","    auc = roc_auc_score(y_val, val_probs)\n","\n","    # Print fold results\n","    print(f\"Accuracy: {acc:.4f} | Sensitivity: {sens:.4f} | Specificity: {spec:.4f} | MCC: {mcc:.4f} | Kappa: {kappa:.4f} | AUC: {auc:.4f}\")\n","    print(classification_report(y_val, val_preds))\n","\n","    # Store metrics\n","    metrics[\"accuracy\"].append(acc)\n","    metrics[\"sensitivity\"].append(sens)\n","    metrics[\"specificity\"].append(spec)\n","    metrics[\"mcc\"].append(mcc)\n","    metrics[\"kappa\"].append(kappa)\n","    metrics[\"auc\"].append(auc)\n","\n","    fold += 1\n","\n","# Average metrics\n","print(\"\\n========== Average Metrics Across 5 Folds ==========\")\n","for key, values in metrics.items():\n","    print(f\"{key.capitalize()}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42_66TPB914A","executionInfo":{"status":"ok","timestamp":1744747331114,"user_tz":-360,"elapsed":615418,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"063ee8d0-b756-46f9-dd53-f3d6ddd3f467"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== Fold 1 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step\n","Accuracy: 0.8833 | Sensitivity: 0.9000 | Specificity: 0.8667 | MCC: 0.7671 | Kappa: 0.7667 | AUC: 0.9556\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.87      0.88        30\n","           1       0.87      0.90      0.89        30\n","\n","    accuracy                           0.88        60\n","   macro avg       0.88      0.88      0.88        60\n","weighted avg       0.88      0.88      0.88        60\n","\n","\n","========== Fold 2 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step\n","Accuracy: 0.8833 | Sensitivity: 0.9000 | Specificity: 0.8667 | MCC: 0.7671 | Kappa: 0.7667 | AUC: 0.9667\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.87      0.88        30\n","           1       0.87      0.90      0.89        30\n","\n","    accuracy                           0.88        60\n","   macro avg       0.88      0.88      0.88        60\n","weighted avg       0.88      0.88      0.88        60\n","\n","\n","========== Fold 3 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n","Accuracy: 0.9167 | Sensitivity: 0.8667 | Specificity: 0.9667 | MCC: 0.8375 | Kappa: 0.8333 | AUC: 0.9678\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.97      0.92        30\n","           1       0.96      0.87      0.91        30\n","\n","    accuracy                           0.92        60\n","   macro avg       0.92      0.92      0.92        60\n","weighted avg       0.92      0.92      0.92        60\n","\n","\n","========== Fold 4 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step\n","Accuracy: 0.9000 | Sensitivity: 0.9000 | Specificity: 0.9000 | MCC: 0.8000 | Kappa: 0.8000 | AUC: 0.9667\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.90      0.90        30\n","           1       0.90      0.90      0.90        30\n","\n","    accuracy                           0.90        60\n","   macro avg       0.90      0.90      0.90        60\n","weighted avg       0.90      0.90      0.90        60\n","\n","\n","========== Fold 5 ==========\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step\n","Accuracy: 0.8833 | Sensitivity: 0.8667 | Specificity: 0.9000 | MCC: 0.7671 | Kappa: 0.7667 | AUC: 0.9511\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.90      0.89        30\n","           1       0.90      0.87      0.88        30\n","\n","    accuracy                           0.88        60\n","   macro avg       0.88      0.88      0.88        60\n","weighted avg       0.88      0.88      0.88        60\n","\n","\n","========== Average Metrics Across 5 Folds ==========\n","Accuracy: 0.8933 ± 0.0133\n","Sensitivity: 0.8867 ± 0.0163\n","Specificity: 0.9000 ± 0.0365\n","Mcc: 0.7878 ± 0.0280\n","Kappa: 0.7867 ± 0.0267\n","Auc: 0.9616 ± 0.0069\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59,"status":"ok","timestamp":1744743494143,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"Fjk-izOeliFs","outputId":"be3098dc-0356-4181-9b45-bc08940d2840"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['SVM_ACC', 'Decision Tree_ACC', 'Random Forest_ACC',\n","       'Logistic Regression_ACC', 'k-NN_ACC', 'Naive Bayes_ACC',\n","       'Gradient Boosting_ACC', 'XGBoost_ACC', 'LightGBM_ACC', 'AdaBoost_ACC',\n","       ...\n","       'Logistic Regression_CTDD', 'k-NN_CTDD', 'Naive Bayes_CTDD',\n","       'Gradient Boosting_CTDD', 'XGBoost_CTDD', 'LightGBM_CTDD',\n","       'AdaBoost_CTDD', 'Neural Network_CTDD', 'MLP_CTDD', 'Target'],\n","      dtype='object', length=121)"]},"metadata":{},"execution_count":38}],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2622,"status":"ok","timestamp":1744743498838,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"7LIhYQPPK2dy","outputId":"53cb5584-9f4d-4409-b2cd-4909fe148618"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n"]}],"source":["!pip install deap"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271035,"status":"ok","timestamp":1744743772798,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"JkxGOohWKfk-","outputId":"8b56cf10-affb-4ff3-f4ba-ade3835afe8a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n","/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n"]},{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t50    \n","1  \t40    \n","2  \t45    \n","3  \t45    \n","4  \t43    \n","5  \t40    \n","6  \t46    \n","7  \t38    \n","8  \t40    \n","9  \t38    \n","10 \t39    \n","11 \t42    \n","12 \t43    \n","13 \t37    \n","14 \t39    \n","15 \t42    \n","16 \t40    \n","17 \t41    \n","18 \t40    \n","19 \t31    \n","20 \t36    \n","Top 10 Selected features: [0, 2, 3, 4, 7, 5, 12, 9, 23, 22]\n","Final Accuracy with top 10 selected features: 0.9\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from deap import base, creator, tools, algorithms\n","import random\n","\n","# Load the dataset\n","data_path = '/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/Optuna_Dataset Marge PFV (1).csv'\n","data = pd.read_csv(data_path)\n","\n","# Assuming the last column is the target, split features and labels\n","X = data.iloc[:, :-1]  # Features\n","y = data.iloc[:, -1]   # Target\n","\n","# Encode target labels if necessary\n","if y.dtype == object or np.issubdtype(y.dtype, np.number):  # Handle both string and numeric labels\n","    le = LabelEncoder()\n","    y = le.fit_transform(y.astype(str))  # Ensure all targets are treated as strings for classification\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create the individual and fitness functions\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# Classifier to evaluate fitness\n","def evaluate(individual):\n","    selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n","    if len(selected_features) == 0:  # Prevent division by zero\n","        return 0,\n","\n","    X_train_selected = X_train.iloc[:, selected_features]\n","    X_val_selected = X_val.iloc[:, selected_features]\n","\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_train_selected, y_train)\n","    y_pred = model.predict(X_val_selected)\n","\n","    accuracy = accuracy_score(y_val, y_pred)\n","    return accuracy,\n","\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# Parameters for the Genetic Algorithm\n","population_size = 50\n","generations = 20\n","crossover_probability = 0.8\n","mutation_probability = 0.1\n","\n","# Initialize population\n","population = toolbox.population(n=population_size)\n","\n","# Run the Genetic Algorithm\n","result_population, logbook = algorithms.eaSimple(\n","    population,\n","    toolbox,\n","    cxpb=crossover_probability,\n","    mutpb=mutation_probability,\n","    ngen=generations,\n","    verbose=True\n",")\n","\n","# Find the best individual\n","best_individual = tools.selBest(result_population, k=1)[0]\n","selected_features = [i for i, bit in enumerate(best_individual) if bit == 1 and i < len(X.columns)]  # Bounds check\n","\n","# Select top 20 features based on their importance\n","if len(selected_features) > 10:\n","    feature_importances = pd.Series(best_individual).sort_values(ascending=False)\n","    selected_features = list(feature_importances.head(10).index)\n","\n","# Evaluate performance using the top 10 features\n","X_train_selected = X_train.iloc[:, selected_features]\n","X_val_selected = X_val.iloc[:, selected_features]\n","\n","final_model = RandomForestClassifier(random_state=42)\n","final_model.fit(X_train_selected, y_train)\n","final_predictions = final_model.predict(X_val_selected)\n","final_accuracy = accuracy_score(y_val, final_predictions)\n","\n","print(f\"Top 10 Selected features: {selected_features}\")\n","print(f\"Final Accuracy with top 10 selected features: {final_accuracy}\")\n","\n","# Save the top 20 selected features\n","pd.DataFrame({'Selected Features': selected_features}).to_csv('/content/PFV_top_10_selected_features.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1744743772841,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"XUPiBwintQEh","outputId":"62d724fe-9c72-4118-cd00-fa5bcf0ab430"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset with top 10 features saved to: /content/PFV_Top_10_Features.csv\n"]}],"source":["selected_feature_columns = data.columns[selected_features]\n","# Create a filtered dataset with only the selected top 10 features\n","filtered_data = data[selected_feature_columns.tolist() + [data.columns[-1]]]\n","filtered_data_path = '/content/PFV_Top_10_Features.csv'\n","filtered_data.to_csv(filtered_data_path, index=False)\n","\n","print(f\"Filtered dataset with top 10 features saved to: {filtered_data_path}\")"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/PFV_Top_10_Features.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset\n","print(\"Dataset Columns:\", data.columns)\n","print(\"Shape before processing:\", data.shape)\n","print(data.head())\n","\n","# Check for target column\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'True_Label' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values\n","y = data['Target'].values\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n","\n","print(\"\\nShapes after reshaping:\")\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_val shape:\", X_val.shape)\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# First Conv1D layer\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Second Conv1D layer\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Third Conv1D layer\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","# Global pooling\n","model.add(GlobalMaxPooling1D())\n","\n","# Dense Layers\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the Model\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',\n","                       tf.keras.metrics.Precision(name='precision'),\n","                       tf.keras.metrics.Recall(name='recall')])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","print(\"\\nTraining model...\")\n","history = model.fit(X_train, y_train,\n","                    validation_data=(X_val, y_val),\n","                    epochs=100,\n","                    batch_size=32,\n","                    verbose=1)\n","\n","# Evaluate the model\n","print(\"\\nEvaluating model...\")\n","val_probs = model.predict(X_val)\n","val_predictions = (val_probs > 0.5).astype(int)\n","\n","# Metrics Calculation\n","accuracy = accuracy_score(y_val, val_predictions)\n","conf_matrix = confusion_matrix(y_val, val_predictions)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n","specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n","mcc = matthews_corrcoef(y_val, val_predictions)\n","kappa = cohen_kappa_score(y_val, val_predictions)\n","auc = roc_auc_score(y_val, val_probs)\n","\n","# Print Metrics\n","print(f\"\\nValidation Accuracy: {accuracy:.4f}\")\n","print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n","print(f\"Cohen's Kappa: {kappa:.4f}\")\n","print(f\"Area Under Curve (AUC): {auc:.4f}\")\n","\n","# Classification Report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_val, val_predictions))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"P3KruBqB0aw2","executionInfo":{"status":"ok","timestamp":1744743844299,"user_tz":-360,"elapsed":50144,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"485db2d5-5d49-4583-b60f-8af4c986f881"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC', 'Random Forest_ACC', 'Logistic Regression_ACC', 'k-NN_ACC',\n","       'XGBoost_ACC', 'Naive Bayes_ACC', 'SVM_CTDC', 'AdaBoost_ACC',\n","       'MLP_CTDC', 'Neural Network_CTDC', 'Target'],\n","      dtype='object')\n","Shape before processing: (300, 11)\n","    SVM_ACC  Random Forest_ACC  Logistic Regression_ACC  k-NN_ACC  \\\n","0  0.823857           0.719734                 0.828746  1.000000   \n","1  0.985450           1.000000                 0.997871  1.000000   \n","2  0.223416           0.200000                 0.312154  1.000000   \n","3  0.555763           0.643902                 0.561625  0.333333   \n","4  0.605909           0.342683                 0.384698  0.000000   \n","\n","   XGBoost_ACC  Naive Bayes_ACC  SVM_CTDC  AdaBoost_ACC  MLP_CTDC  \\\n","0     0.917172         0.892723  0.966059      0.508819  0.999219   \n","1     0.999149         1.000000  0.999989      0.631024  1.000000   \n","2     0.053543         0.114252  0.387876      0.457909  0.802535   \n","3     0.723154         0.771621  0.967857      0.520116  0.999998   \n","4     0.366223         0.008400  0.330877      0.501183  0.912710   \n","\n","   Neural Network_CTDC  Target  \n","0             0.999968       1  \n","1             1.000000       1  \n","2             0.385196       1  \n","3             1.000000       1  \n","4             0.995410       1  \n","\n","Shapes after reshaping:\n","X_train shape: (210, 10, 1)\n","X_val shape: (90, 10, 1)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_12\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_max_pooling1d_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m166,529\u001b[0m (650.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">166,529</span> (650.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m165,633\u001b[0m (647.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,633</span> (647.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Training model...\n","Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 388ms/step - accuracy: 0.7208 - loss: 0.9614 - precision: 0.7135 - recall: 0.7803 - val_accuracy: 0.9222 - val_loss: 0.6427 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8992 - loss: 0.2429 - precision: 0.9449 - recall: 0.8624 - val_accuracy: 0.9000 - val_loss: 0.6223 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9310 - loss: 0.2476 - precision: 0.9384 - recall: 0.9213 - val_accuracy: 0.9000 - val_loss: 0.6156 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9178 - loss: 0.2403 - precision: 0.8722 - recall: 0.9581 - val_accuracy: 0.8889 - val_loss: 0.6165 - val_precision: 0.8889 - val_recall: 0.8889\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9199 - loss: 0.2051 - precision: 0.9311 - recall: 0.9107 - val_accuracy: 0.8778 - val_loss: 0.6203 - val_precision: 0.8696 - val_recall: 0.8889\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8813 - loss: 0.3541 - precision: 0.8591 - recall: 0.9101 - val_accuracy: 0.8667 - val_loss: 0.6242 - val_precision: 0.8367 - val_recall: 0.9111\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9074 - loss: 0.2276 - precision: 0.9166 - recall: 0.9079 - val_accuracy: 0.8889 - val_loss: 0.6233 - val_precision: 0.8431 - val_recall: 0.9556\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9484 - loss: 0.1561 - precision: 0.9562 - recall: 0.9373 - val_accuracy: 0.8667 - val_loss: 0.6215 - val_precision: 0.8113 - val_recall: 0.9556\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9265 - loss: 0.2374 - precision: 0.9451 - recall: 0.9117 - val_accuracy: 0.8444 - val_loss: 0.6237 - val_precision: 0.7719 - val_recall: 0.9778\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9136 - loss: 0.1916 - precision: 0.9112 - recall: 0.9208 - val_accuracy: 0.8667 - val_loss: 0.6207 - val_precision: 0.8000 - val_recall: 0.9778\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9194 - loss: 0.2126 - precision: 0.9146 - recall: 0.9188 - val_accuracy: 0.8778 - val_loss: 0.6169 - val_precision: 0.8269 - val_recall: 0.9556\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9336 - loss: 0.1988 - precision: 0.9278 - recall: 0.9473 - val_accuracy: 0.8778 - val_loss: 0.6161 - val_precision: 0.8269 - val_recall: 0.9556\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9257 - loss: 0.1941 - precision: 0.9363 - recall: 0.9160 - val_accuracy: 0.9000 - val_loss: 0.6139 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9464 - loss: 0.1793 - precision: 0.9537 - recall: 0.9462 - val_accuracy: 0.9000 - val_loss: 0.6034 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9243 - loss: 0.1584 - precision: 0.9077 - recall: 0.9432 - val_accuracy: 0.9000 - val_loss: 0.5994 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9337 - loss: 0.1537 - precision: 0.9463 - recall: 0.9248 - val_accuracy: 0.9000 - val_loss: 0.5990 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9237 - loss: 0.1866 - precision: 0.9362 - recall: 0.9049 - val_accuracy: 0.9000 - val_loss: 0.6009 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9082 - loss: 0.1664 - precision: 0.9209 - recall: 0.8996 - val_accuracy: 0.9000 - val_loss: 0.5905 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9612 - loss: 0.1406 - precision: 0.9417 - recall: 0.9861 - val_accuracy: 0.9000 - val_loss: 0.5813 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9449 - loss: 0.1852 - precision: 0.9619 - recall: 0.9298 - val_accuracy: 0.9000 - val_loss: 0.5925 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9591 - loss: 0.1604 - precision: 0.9831 - recall: 0.9359 - val_accuracy: 0.8778 - val_loss: 0.5878 - val_precision: 0.8269 - val_recall: 0.9556\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9360 - loss: 0.1763 - precision: 0.9310 - recall: 0.9471 - val_accuracy: 0.8778 - val_loss: 0.5860 - val_precision: 0.8269 - val_recall: 0.9556\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9559 - loss: 0.1665 - precision: 0.9492 - recall: 0.9695 - val_accuracy: 0.9000 - val_loss: 0.5861 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9516 - loss: 0.1186 - precision: 0.9546 - recall: 0.9486 - val_accuracy: 0.9000 - val_loss: 0.5697 - val_precision: 0.8600 - val_recall: 0.9556\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9220 - loss: 0.1771 - precision: 0.9218 - recall: 0.9237 - val_accuracy: 0.8889 - val_loss: 0.5556 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9590 - loss: 0.1305 - precision: 0.9665 - recall: 0.9545 - val_accuracy: 0.8778 - val_loss: 0.5501 - val_precision: 0.8542 - val_recall: 0.9111\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9570 - loss: 0.1642 - precision: 0.9524 - recall: 0.9640 - val_accuracy: 0.8889 - val_loss: 0.5467 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9315 - loss: 0.1974 - precision: 0.9223 - recall: 0.9408 - val_accuracy: 0.8889 - val_loss: 0.5505 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9447 - loss: 0.1678 - precision: 0.9317 - recall: 0.9618 - val_accuracy: 0.8889 - val_loss: 0.5434 - val_precision: 0.8571 - val_recall: 0.9333\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9234 - loss: 0.1379 - precision: 0.9203 - recall: 0.9170 - val_accuracy: 0.8889 - val_loss: 0.5388 - val_precision: 0.8431 - val_recall: 0.9556\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9601 - loss: 0.1082 - precision: 0.9591 - recall: 0.9621 - val_accuracy: 0.8778 - val_loss: 0.5375 - val_precision: 0.8269 - val_recall: 0.9556\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9390 - loss: 0.1631 - precision: 0.9252 - recall: 0.9542 - val_accuracy: 0.8889 - val_loss: 0.5311 - val_precision: 0.8431 - val_recall: 0.9556\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9508 - loss: 0.1557 - precision: 0.9358 - recall: 0.9636 - val_accuracy: 0.8778 - val_loss: 0.5332 - val_precision: 0.8269 - val_recall: 0.9556\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9170 - loss: 0.1879 - precision: 0.9120 - recall: 0.9265 - val_accuracy: 0.8889 - val_loss: 0.5249 - val_precision: 0.8302 - val_recall: 0.9778\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9733 - loss: 0.0992 - precision: 0.9642 - recall: 0.9845 - val_accuracy: 0.9111 - val_loss: 0.4919 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9276 - loss: 0.1435 - precision: 0.9374 - recall: 0.9140 - val_accuracy: 0.9000 - val_loss: 0.4843 - val_precision: 0.8462 - val_recall: 0.9778\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9330 - loss: 0.1520 - precision: 0.9118 - recall: 0.9494 - val_accuracy: 0.9111 - val_loss: 0.4661 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9284 - loss: 0.1433 - precision: 0.9251 - recall: 0.9435 - val_accuracy: 0.9111 - val_loss: 0.4583 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9308 - loss: 0.1673 - precision: 0.9225 - recall: 0.9458 - val_accuracy: 0.9111 - val_loss: 0.4797 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9466 - loss: 0.1462 - precision: 0.9589 - recall: 0.9411 - val_accuracy: 0.9222 - val_loss: 0.4728 - val_precision: 0.8800 - val_recall: 0.9778\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9431 - loss: 0.1729 - precision: 0.9360 - recall: 0.9493 - val_accuracy: 0.9222 - val_loss: 0.4637 - val_precision: 0.8800 - val_recall: 0.9778\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9545 - loss: 0.1872 - precision: 0.9559 - recall: 0.9543 - val_accuracy: 0.9000 - val_loss: 0.4472 - val_precision: 0.8462 - val_recall: 0.9778\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9444 - loss: 0.1157 - precision: 0.9133 - recall: 0.9798 - val_accuracy: 0.9111 - val_loss: 0.4272 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9198 - loss: 0.1998 - precision: 0.8573 - recall: 0.9702 - val_accuracy: 0.9111 - val_loss: 0.4030 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9695 - loss: 0.0856 - precision: 0.9656 - recall: 0.9731 - val_accuracy: 0.9000 - val_loss: 0.3616 - val_precision: 0.8462 - val_recall: 0.9778\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9714 - loss: 0.1084 - precision: 0.9644 - recall: 0.9822 - val_accuracy: 0.9111 - val_loss: 0.3590 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9420 - loss: 0.1901 - precision: 0.9384 - recall: 0.9494 - val_accuracy: 0.9222 - val_loss: 0.4097 - val_precision: 0.8800 - val_recall: 0.9778\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9313 - loss: 0.1933 - precision: 0.9550 - recall: 0.9201 - val_accuracy: 0.9222 - val_loss: 0.4029 - val_precision: 0.8800 - val_recall: 0.9778\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9620 - loss: 0.0935 - precision: 0.9575 - recall: 0.9694 - val_accuracy: 0.9222 - val_loss: 0.3660 - val_precision: 0.8800 - val_recall: 0.9778\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9591 - loss: 0.1351 - precision: 0.9458 - recall: 0.9727 - val_accuracy: 0.9111 - val_loss: 0.3149 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9596 - loss: 0.1182 - precision: 0.9318 - recall: 0.9927 - val_accuracy: 0.9222 - val_loss: 0.2815 - val_precision: 0.8800 - val_recall: 0.9778\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9702 - loss: 0.0758 - precision: 0.9564 - recall: 0.9849 - val_accuracy: 0.9444 - val_loss: 0.2590 - val_precision: 0.9167 - val_recall: 0.9778\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9463 - loss: 0.1294 - precision: 0.9395 - recall: 0.9578 - val_accuracy: 0.9111 - val_loss: 0.2742 - val_precision: 0.8627 - val_recall: 0.9778\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9563 - loss: 0.1103 - precision: 0.9341 - recall: 0.9772 - val_accuracy: 0.9556 - val_loss: 0.2732 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9477 - loss: 0.1090 - precision: 0.9417 - recall: 0.9568 - val_accuracy: 0.9556 - val_loss: 0.2736 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9678 - loss: 0.0901 - precision: 0.9511 - recall: 0.9867 - val_accuracy: 0.9556 - val_loss: 0.2464 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9644 - loss: 0.0842 - precision: 0.9643 - recall: 0.9663 - val_accuracy: 0.9444 - val_loss: 0.2333 - val_precision: 0.9167 - val_recall: 0.9778\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9645 - loss: 0.0935 - precision: 0.9453 - recall: 0.9844 - val_accuracy: 0.9556 - val_loss: 0.2502 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9566 - loss: 0.0980 - precision: 0.9511 - recall: 0.9659 - val_accuracy: 0.9556 - val_loss: 0.2629 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9535 - loss: 0.1327 - precision: 0.9465 - recall: 0.9575 - val_accuracy: 0.9556 - val_loss: 0.2313 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9498 - loss: 0.1069 - precision: 0.9218 - recall: 0.9836 - val_accuracy: 0.9444 - val_loss: 0.2073 - val_precision: 0.9167 - val_recall: 0.9778\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9469 - loss: 0.1310 - precision: 0.9405 - recall: 0.9535 - val_accuracy: 0.9556 - val_loss: 0.2011 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9681 - loss: 0.0816 - precision: 0.9508 - recall: 0.9892 - val_accuracy: 0.9556 - val_loss: 0.2052 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9484 - loss: 0.1145 - precision: 0.9439 - recall: 0.9558 - val_accuracy: 0.9556 - val_loss: 0.2089 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9485 - loss: 0.1205 - precision: 0.9169 - recall: 0.9822 - val_accuracy: 0.9556 - val_loss: 0.2093 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9489 - loss: 0.1561 - precision: 0.9009 - recall: 0.9830 - val_accuracy: 0.9444 - val_loss: 0.2275 - val_precision: 0.9348 - val_recall: 0.9556\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9501 - loss: 0.1280 - precision: 0.9638 - recall: 0.9379 - val_accuracy: 0.9556 - val_loss: 0.2126 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9535 - loss: 0.0906 - precision: 0.9291 - recall: 0.9787 - val_accuracy: 0.9556 - val_loss: 0.2152 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9718 - loss: 0.0855 - precision: 0.9534 - recall: 0.9949 - val_accuracy: 0.9556 - val_loss: 0.2068 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9599 - loss: 0.0810 - precision: 0.9388 - recall: 0.9827 - val_accuracy: 0.9444 - val_loss: 0.2254 - val_precision: 0.9348 - val_recall: 0.9556\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9721 - loss: 0.0602 - precision: 0.9937 - recall: 0.9493 - val_accuracy: 0.9444 - val_loss: 0.2225 - val_precision: 0.9348 - val_recall: 0.9556\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9681 - loss: 0.1060 - precision: 0.9811 - recall: 0.9542 - val_accuracy: 0.9444 - val_loss: 0.2172 - val_precision: 0.9167 - val_recall: 0.9778\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9623 - loss: 0.0798 - precision: 0.9463 - recall: 0.9814 - val_accuracy: 0.9444 - val_loss: 0.2055 - val_precision: 0.9348 - val_recall: 0.9556\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9880 - loss: 0.0589 - precision: 0.9848 - recall: 0.9910 - val_accuracy: 0.9111 - val_loss: 0.2231 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9511 - loss: 0.1146 - precision: 0.9913 - recall: 0.9057 - val_accuracy: 0.9000 - val_loss: 0.2502 - val_precision: 0.9091 - val_recall: 0.8889\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9636 - loss: 0.1098 - precision: 0.9638 - recall: 0.9662 - val_accuracy: 0.9111 - val_loss: 0.2310 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9718 - loss: 0.0849 - precision: 0.9687 - recall: 0.9759 - val_accuracy: 0.9333 - val_loss: 0.2324 - val_precision: 0.9333 - val_recall: 0.9333\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9607 - loss: 0.0907 - precision: 0.9613 - recall: 0.9618 - val_accuracy: 0.9556 - val_loss: 0.2368 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9573 - loss: 0.0910 - precision: 0.9518 - recall: 0.9677 - val_accuracy: 0.9556 - val_loss: 0.2351 - val_precision: 0.9362 - val_recall: 0.9778\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9537 - loss: 0.1051 - precision: 0.9544 - recall: 0.9501 - val_accuracy: 0.9333 - val_loss: 0.2524 - val_precision: 0.9333 - val_recall: 0.9333\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9683 - loss: 0.1142 - precision: 0.9680 - recall: 0.9618 - val_accuracy: 0.9333 - val_loss: 0.2478 - val_precision: 0.9149 - val_recall: 0.9556\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9857 - loss: 0.0640 - precision: 0.9760 - recall: 0.9963 - val_accuracy: 0.9333 - val_loss: 0.2463 - val_precision: 0.9149 - val_recall: 0.9556\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9582 - loss: 0.0794 - precision: 0.9247 - recall: 1.0000 - val_accuracy: 0.9222 - val_loss: 0.2254 - val_precision: 0.9130 - val_recall: 0.9333\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9699 - loss: 0.0899 - precision: 0.9854 - recall: 0.9551 - val_accuracy: 0.9333 - val_loss: 0.2084 - val_precision: 0.9149 - val_recall: 0.9556\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9658 - loss: 0.0674 - precision: 0.9484 - recall: 0.9820 - val_accuracy: 0.9444 - val_loss: 0.2177 - val_precision: 0.9167 - val_recall: 0.9778\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9769 - loss: 0.0893 - precision: 0.9603 - recall: 0.9963 - val_accuracy: 0.9444 - val_loss: 0.2258 - val_precision: 0.9348 - val_recall: 0.9556\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9560 - loss: 0.0862 - precision: 0.9683 - recall: 0.9428 - val_accuracy: 0.9222 - val_loss: 0.2793 - val_precision: 0.9130 - val_recall: 0.9333\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9796 - loss: 0.0844 - precision: 0.9654 - recall: 0.9915 - val_accuracy: 0.9333 - val_loss: 0.2771 - val_precision: 0.9333 - val_recall: 0.9333\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9686 - loss: 0.0616 - precision: 0.9501 - recall: 0.9893 - val_accuracy: 0.9444 - val_loss: 0.2450 - val_precision: 0.9348 - val_recall: 0.9556\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9604 - loss: 0.0822 - precision: 0.9701 - recall: 0.9499 - val_accuracy: 0.9333 - val_loss: 0.2762 - val_precision: 0.9535 - val_recall: 0.9111\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9663 - loss: 0.0776 - precision: 0.9565 - recall: 0.9762 - val_accuracy: 0.9333 - val_loss: 0.2885 - val_precision: 0.9535 - val_recall: 0.9111\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9779 - loss: 0.0581 - precision: 0.9824 - recall: 0.9730 - val_accuracy: 0.9222 - val_loss: 0.2957 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9857 - loss: 0.0398 - precision: 0.9855 - recall: 0.9866 - val_accuracy: 0.9333 - val_loss: 0.3064 - val_precision: 0.9535 - val_recall: 0.9111\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9926 - loss: 0.0269 - precision: 0.9892 - recall: 0.9963 - val_accuracy: 0.9222 - val_loss: 0.3189 - val_precision: 0.9524 - val_recall: 0.8889\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9778 - loss: 0.0579 - precision: 0.9688 - recall: 0.9857 - val_accuracy: 0.9222 - val_loss: 0.2916 - val_precision: 0.9750 - val_recall: 0.8667\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9777 - loss: 0.0865 - precision: 0.9939 - recall: 0.9646 - val_accuracy: 0.9333 - val_loss: 0.2915 - val_precision: 0.9535 - val_recall: 0.9111\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9697 - loss: 0.0763 - precision: 0.9500 - recall: 0.9901 - val_accuracy: 0.9111 - val_loss: 0.2830 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9733 - loss: 0.0796 - precision: 0.9819 - recall: 0.9630 - val_accuracy: 0.9111 - val_loss: 0.3143 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9822 - loss: 0.0596 - precision: 0.9647 - recall: 1.0000 - val_accuracy: 0.9111 - val_loss: 0.3296 - val_precision: 0.9302 - val_recall: 0.8889\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9816 - loss: 0.0567 - precision: 0.9689 - recall: 0.9963 - val_accuracy: 0.9222 - val_loss: 0.3330 - val_precision: 0.9524 - val_recall: 0.8889\n","\n","Evaluating model...\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n","\n","Validation Accuracy: 0.9222\n","Sensitivity (Recall): 0.8889\n","Specificity: 0.9556\n","Matthews Correlation Coefficient (MCC): 0.8463\n","Cohen's Kappa: 0.8444\n","Area Under Curve (AUC): 0.9664\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.96      0.92        45\n","           1       0.95      0.89      0.92        45\n","\n","    accuracy                           0.92        90\n","   macro avg       0.92      0.92      0.92        90\n","weighted avg       0.92      0.92      0.92        90\n","\n"]}]},{"cell_type":"code","source":["#cross validation for pfv\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    matthews_corrcoef, cohen_kappa_score, roc_auc_score\n",")\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Load the dataset\n","dataset_path = \"/content/PFV_Top_10_Features.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values\n","y = data['Target'].values\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Reshape for Conv1D\n","X = X.reshape(X.shape[0], X.shape[1], 1)\n","\n","# Set up Stratified K-Fold\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# For storing metrics\n","accs, sens_list, specs, mccs, kappas, aucs = [], [], [], [], [], []\n","\n","fold = 1\n","for train_idx, val_idx in kf.split(X, y):\n","    print(f\"\\n----- Fold {fold} -----\")\n","\n","    X_train, X_val = X[train_idx], X[val_idx]\n","    y_train, y_val = y[train_idx], y[val_idx]\n","\n","    # Define model\n","    model = Sequential()\n","    model.add(Conv1D(64, 3, activation='relu', input_shape=(X.shape[1], 1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.3))\n","\n","    model.add(GlobalMaxPooling1D())\n","\n","    model.add(Dense(128, activation='swish'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(64, activation='swish'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    # Train\n","    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n","\n","    # Predict\n","    val_probs = model.predict(X_val)\n","    val_pred = (val_probs > 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_val, val_pred)\n","    conf = confusion_matrix(y_val, val_pred)\n","    tn, fp, fn, tp = conf.ravel()\n","    sens = tp / (tp + fn) if (tp + fn) else 0\n","    spec = tn / (tn + fp) if (tn + fp) else 0\n","    mcc = matthews_corrcoef(y_val, val_pred)\n","    kappa = cohen_kappa_score(y_val, val_pred)\n","    auc = roc_auc_score(y_val, val_probs)\n","\n","    # Append to lists\n","    accs.append(acc)\n","    sens_list.append(sens)\n","    specs.append(spec)\n","    mccs.append(mcc)\n","    kappas.append(kappa)\n","    aucs.append(auc)\n","\n","    print(f\"Accuracy: {acc:.4f}, Sensitivity: {sens:.4f}, Specificity: {spec:.4f}, MCC: {mcc:.4f}, Kappa: {kappa:.4f}, AUC: {auc:.4f}\")\n","    fold += 1\n","\n","# Print average performance\n","print(\"\\n===== Cross-Validation Results =====\")\n","print(f\"Average Accuracy: {np.mean(accs):.4f}\")\n","print(f\"Average Sensitivity: {np.mean(sens_list):.4f}\")\n","print(f\"Average Specificity: {np.mean(specs):.4f}\")\n","print(f\"Average MCC: {np.mean(mccs):.4f}\")\n","print(f\"Average Kappa: {np.mean(kappas):.4f}\")\n","print(f\"Average AUC: {np.mean(aucs):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkTziUpI-GqA","outputId":"0f4e0a66-a361-416b-c417-d72b7a96d045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","----- Fold 1 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n","Accuracy: 0.9667, Sensitivity: 0.9667, Specificity: 0.9667, MCC: 0.9333, Kappa: 0.9333, AUC: 0.9944\n","\n","----- Fold 2 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n","Accuracy: 0.9667, Sensitivity: 1.0000, Specificity: 0.9333, MCC: 0.9354, Kappa: 0.9333, AUC: 0.9978\n","\n","----- Fold 3 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n","Accuracy: 0.9667, Sensitivity: 0.9333, Specificity: 1.0000, MCC: 0.9354, Kappa: 0.9333, AUC: 0.9733\n","\n","----- Fold 4 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n","Accuracy: 0.9167, Sensitivity: 0.9333, Specificity: 0.9000, MCC: 0.8338, Kappa: 0.8333, AUC: 0.9522\n","\n","----- Fold 5 -----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ODrnUtK4zpyY"},"source":["Three technique dataset are marge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SsVtoDKUQwD_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1739662707356,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"2OD-hWPNzwAJ","outputId":"e7dc0f6b-a645-4ee7-e6cc-e42cffe1d106"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/three_T_Marge.csv\n"]}],"source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"CFV\": \"/content/CFV_Top_10_Features.csv\",\n","    \"CPFV\": \"/content/CPFV_Top_10_Features.csv\",\n","    \"PFV\": \"/content/PFV_Top_10_Features.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/three_T_Marge.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLoO-cdN9kzp"},"outputs":[],"source":["df=pd.read_csv(\"/content/three_T_Marge.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1739662707357,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"},"user_tz":-360},"id":"PtUnE-v99sz3","outputId":"8c76b4a9-df1a-4aa5-b36f-93ae9be7cb09"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 31)"]},"metadata":{},"execution_count":29}],"source":["df.shape"]},{"cell_type":"code","source":["import pandas as pd\n","import xgboost\n","import shap\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","df = pd.read_csv(\"/content/three_T_Marge.csv\")\n","\n","# Assuming the last column is the target variable\n","X = df.iloc[:, :-1]  # Features\n","y = df.iloc[:, -1]   # Target\n","\n","# Train an XGBoost model (or any tree-based model)\n","model = xgboost.XGBClassifier()\n","model.fit(X, y)\n","\n","# Initialize SHAP explainer\n","explainer = shap.TreeExplainer(model)\n","shap_values = explainer.shap_values(X)\n","\n","# Create the default SHAP summary plot (Bar Plot)\n","plt.figure(figsize=(6, 4))  # Smaller figure size\n","shap.summary_plot(shap_values, X, plot_type=\"bar\")  # Bar plot for feature importance\n","plt.title(\"SHAP Feature Importance (Bar Plot)\", fontsize=14, fontweight='bold')\n","plt.show()\n","\n","# Create the default SHAP beeswarm plot\n","plt.figure(figsize=(3, 3))  # Smaller figure size\n","shap.summary_plot(shap_values, X)  # Beeswarm plot for detailed feature impact\n","plt.title(\"SHAP Feature Impact (Beeswarm Plot)\", fontsize=14, fontweight='bold')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LIug4YKN_2Na","executionInfo":{"status":"ok","timestamp":1739663330762,"user_tz":-360,"elapsed":3003,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"a99cd18d-e319-441d-98eb-b58f67410d4a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x950 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x950 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Y-z2nEIL-9Er"},"source":["Hybrid CNN-LSTM Model for Cell-Penetrating Peptide Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vaN7uof89unN","outputId":"9613cb79-47a9-4b55-b10f-6695b37234d3","executionInfo":{"status":"ok","timestamp":1739031394305,"user_tz":-360,"elapsed":55785,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC_CFV', 'AdaBoost_GDC_CFV', 'AdaBoost_CTDT_CFV', 'SVM_DPC_CFV',\n","       'Random Forest_PAAC_CFV', 'Decision Tree_PAAC_CFV', 'MLP_GDC_CFV',\n","       'Neural Network_GDC_CFV', 'Random Forest_DPC_CFV', 'XGBoost_CTDT_CFV',\n","       'Random Forest_Class_GDC_CPFV',\n","       'Multilayer Perceptron (Custom MLP)_Prob_GDC_CPFV',\n","       'Neural Network (MLPClassifier)_Class_GDC_CPFV',\n","       'AdaBoost_Prob_GDC_CPFV', 'AdaBoost_Class_GDC_CPFV',\n","       'LightGBM_Prob_GDC_CPFV', 'LightGBM_Class_GDC_CPFV',\n","       'XGBoost_Class_GDC_CPFV', 'Gradient Boosting_Prob_GDC_CPFV',\n","       'Gradient Boosting_Class_GDC_CPFV', 'SVM_PCP_PFV', 'AdaBoost_PAAC_PFV',\n","       'MLP_PCP_PFV', 'Neural Network_PCP_PFV', 'LightGBM_PCP_PFV',\n","       'Gradient Boosting_PCP_PFV', 'Naive Bayes_PCP_PFV', 'k-NN_PCP_PFV',\n","       'Logistic Regression_PCP_PFV', 'MLP_PAAC_PFV', 'Target'],\n","      dtype='object')\n","   SVM_ACC_CFV  AdaBoost_GDC_CFV  AdaBoost_CTDT_CFV  SVM_DPC_CFV  \\\n","0     0.830810          0.609364           0.501956     0.952625   \n","1     0.987548          0.609364           0.554677     0.972204   \n","2     0.211028          0.464830           0.494672     0.515618   \n","3     0.552428          0.534680           0.549709     0.978918   \n","4     0.607083          0.495365           0.492617     0.551777   \n","\n","   Random Forest_PAAC_CFV  Decision Tree_PAAC_CFV  MLP_GDC_CFV  \\\n","0                0.641420                0.816456     0.999924   \n","1                0.902640                0.983607     0.999924   \n","2                0.309144                0.034483     0.008714   \n","3                0.674516                0.108696     0.996928   \n","4                0.340675                0.034483     0.302993   \n","\n","   Neural Network_GDC_CFV  Random Forest_DPC_CFV  XGBoost_CTDT_CFV  ...  \\\n","0                0.998631               0.497160          0.984983  ...   \n","1                0.998631               0.831769          0.995125  ...   \n","2                0.220107               0.396653          0.372593  ...   \n","3                0.986588               0.621746          0.977446  ...   \n","4                0.360953               0.461488          0.275739  ...   \n","\n","   AdaBoost_PAAC_PFV  MLP_PCP_PFV  Neural Network_PCP_PFV  LightGBM_PCP_PFV  \\\n","0           0.526144     0.994466                1.000000          0.996590   \n","1           0.662831     0.997881                0.999993          0.998059   \n","2           0.462671     0.208824                0.100467          0.010956   \n","3           0.533153     0.965118                0.981379          0.798022   \n","4           0.481918     0.263974                0.130168          0.214318   \n","\n","   Gradient Boosting_PCP_PFV  Naive Bayes_PCP_PFV  k-NN_PCP_PFV  \\\n","0               1.000000e+00             1.000000           1.0   \n","1               1.000000e+00             1.000000           1.0   \n","2               2.058050e-10             0.037961           0.0   \n","3               9.860029e-01             0.247224           1.0   \n","4               1.049644e-07             0.095711           0.0   \n","\n","   Logistic Regression_PCP_PFV  MLP_PAAC_PFV  Target  \n","0                     0.938520      0.999980       1  \n","1                     0.987474      0.999933       1  \n","2                     0.193770      0.999456       1  \n","3                     0.612827      0.992662       1  \n","4                     0.425606      0.075896       1  \n","\n","[5 rows x 31 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m98,560\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m82,176\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,129\u001b[0m (875.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,129</span> (875.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,233\u001b[0m (872.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,233</span> (872.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.7381 - loss: 0.5804 - val_accuracy: 0.8333 - val_loss: 0.6726\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8770 - loss: 0.3212 - val_accuracy: 0.8111 - val_loss: 0.6693\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8874 - loss: 0.2800 - val_accuracy: 0.7778 - val_loss: 0.6688\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8944 - loss: 0.2796 - val_accuracy: 0.8000 - val_loss: 0.6601\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9014 - loss: 0.2391 - val_accuracy: 0.7778 - val_loss: 0.6537\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9111 - loss: 0.2132 - val_accuracy: 0.7889 - val_loss: 0.6494\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9105 - loss: 0.1793 - val_accuracy: 0.8667 - val_loss: 0.6571\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9037 - loss: 0.2185 - val_accuracy: 0.8778 - val_loss: 0.6576\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9049 - loss: 0.1665 - val_accuracy: 0.8444 - val_loss: 0.6399\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9269 - loss: 0.1646 - val_accuracy: 0.8000 - val_loss: 0.6328\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9037 - loss: 0.1988 - val_accuracy: 0.7889 - val_loss: 0.6373\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9238 - loss: 0.2007 - val_accuracy: 0.7778 - val_loss: 0.6445\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9197 - loss: 0.1591 - val_accuracy: 0.5889 - val_loss: 0.6057\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9334 - loss: 0.1400 - val_accuracy: 0.5778 - val_loss: 0.6008\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8982 - loss: 0.1824 - val_accuracy: 0.6333 - val_loss: 0.6365\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9492 - loss: 0.1409 - val_accuracy: 0.7000 - val_loss: 0.6215\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9400 - loss: 0.1129 - val_accuracy: 0.5111 - val_loss: 0.6077\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9358 - loss: 0.1681 - val_accuracy: 0.7444 - val_loss: 0.6196\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.1216 - val_accuracy: 0.7000 - val_loss: 0.5866\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9443 - loss: 0.1201 - val_accuracy: 0.5000 - val_loss: 0.5833\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9568 - loss: 0.1254 - val_accuracy: 0.5000 - val_loss: 0.5682\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9421 - loss: 0.1061 - val_accuracy: 0.5000 - val_loss: 0.5760\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9660 - loss: 0.0852 - val_accuracy: 0.5000 - val_loss: 0.5979\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9469 - loss: 0.1203 - val_accuracy: 0.5000 - val_loss: 0.6373\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9502 - loss: 0.1201 - val_accuracy: 0.5000 - val_loss: 0.6319\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9492 - loss: 0.1487 - val_accuracy: 0.5000 - val_loss: 0.6475\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9758 - loss: 0.0906 - val_accuracy: 0.5444 - val_loss: 0.6161\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9699 - loss: 0.0653 - val_accuracy: 0.5000 - val_loss: 0.6836\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9430 - loss: 0.1105 - val_accuracy: 0.5000 - val_loss: 0.7670\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9724 - loss: 0.0737 - val_accuracy: 0.6444 - val_loss: 0.9479\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9599 - loss: 0.1094 - val_accuracy: 0.6778 - val_loss: 0.8224\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9445 - loss: 0.1277 - val_accuracy: 0.6778 - val_loss: 0.7946\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9738 - loss: 0.0699 - val_accuracy: 0.7889 - val_loss: 0.7163\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9697 - loss: 0.1021 - val_accuracy: 0.7778 - val_loss: 0.6192\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9893 - loss: 0.0664 - val_accuracy: 0.7333 - val_loss: 0.5531\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9708 - loss: 0.0865 - val_accuracy: 0.7444 - val_loss: 0.5294\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9244 - loss: 0.1508 - val_accuracy: 0.7000 - val_loss: 0.6877\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9871 - loss: 0.0387 - val_accuracy: 0.6889 - val_loss: 0.7967\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9739 - loss: 0.0647 - val_accuracy: 0.7333 - val_loss: 0.7491\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9921 - loss: 0.0437 - val_accuracy: 0.7778 - val_loss: 0.7669\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9830 - loss: 0.0403 - val_accuracy: 0.7889 - val_loss: 0.7644\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9893 - loss: 0.0363 - val_accuracy: 0.7889 - val_loss: 0.7355\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9812 - loss: 0.0414 - val_accuracy: 0.7889 - val_loss: 0.6569\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9749 - loss: 0.0445 - val_accuracy: 0.7556 - val_loss: 0.6745\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9929 - loss: 0.0327 - val_accuracy: 0.7667 - val_loss: 0.7172\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9719 - loss: 0.0571 - val_accuracy: 0.8000 - val_loss: 0.7645\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9951 - loss: 0.0133 - val_accuracy: 0.7889 - val_loss: 0.7218\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9970 - loss: 0.0200 - val_accuracy: 0.8000 - val_loss: 0.6906\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9708 - loss: 0.0585 - val_accuracy: 0.8000 - val_loss: 0.6585\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9892 - loss: 0.0180 - val_accuracy: 0.8000 - val_loss: 0.8404\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9928 - loss: 0.0389 - val_accuracy: 0.8333 - val_loss: 0.7669\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0309 - val_accuracy: 0.8333 - val_loss: 0.5691\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9843 - loss: 0.0320 - val_accuracy: 0.8333 - val_loss: 0.6326\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9913 - loss: 0.0157 - val_accuracy: 0.8000 - val_loss: 0.9694\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9842 - loss: 0.0206 - val_accuracy: 0.8000 - val_loss: 1.0428\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0195 - val_accuracy: 0.8000 - val_loss: 0.9412\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0183 - val_accuracy: 0.8111 - val_loss: 0.8981\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9962 - loss: 0.0080 - val_accuracy: 0.8444 - val_loss: 0.7854\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.8667 - val_loss: 0.8486\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8444 - val_loss: 1.0343\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9882 - loss: 0.0313 - val_accuracy: 0.8444 - val_loss: 1.1248\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9876 - loss: 0.0252 - val_accuracy: 0.8667 - val_loss: 1.1327\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9775 - loss: 0.0532 - val_accuracy: 0.8667 - val_loss: 1.1096\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.8556 - val_loss: 1.0434\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9781 - loss: 0.0853 - val_accuracy: 0.8556 - val_loss: 0.8322\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9952 - loss: 0.0155 - val_accuracy: 0.8667 - val_loss: 0.7860\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0383 - val_accuracy: 0.8778 - val_loss: 0.7357\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9838 - loss: 0.1018 - val_accuracy: 0.8556 - val_loss: 0.5732\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0204 - val_accuracy: 0.8556 - val_loss: 0.5883\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9892 - loss: 0.0280 - val_accuracy: 0.8889 - val_loss: 0.6546\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9895 - loss: 0.0250 - val_accuracy: 0.8778 - val_loss: 0.7722\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8778 - val_loss: 0.9690\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8556 - val_loss: 1.1265\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9938 - loss: 0.0318 - val_accuracy: 0.8556 - val_loss: 1.0511\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9974 - loss: 0.0169 - val_accuracy: 0.8667 - val_loss: 1.0242\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9933 - loss: 0.0109 - val_accuracy: 0.8444 - val_loss: 1.0704\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.8556 - val_loss: 1.0443\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8667 - val_loss: 1.0368\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8667 - val_loss: 1.1204\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8333 - val_loss: 1.3842\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9866 - loss: 0.0162 - val_accuracy: 0.8667 - val_loss: 0.9629\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9889 - loss: 0.0254 - val_accuracy: 0.8556 - val_loss: 1.0176\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0199 - val_accuracy: 0.8667 - val_loss: 1.4797\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0111 - val_accuracy: 0.8778 - val_loss: 1.6377\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9892 - loss: 0.0248 - val_accuracy: 0.8778 - val_loss: 1.5284\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9934 - loss: 0.0112 - val_accuracy: 0.8556 - val_loss: 1.3648\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9892 - loss: 0.0888 - val_accuracy: 0.8667 - val_loss: 1.2652\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9745 - loss: 0.0417 - val_accuracy: 0.8556 - val_loss: 1.3665\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9857 - loss: 0.0254 - val_accuracy: 0.8778 - val_loss: 1.4310\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9732 - loss: 0.0513 - val_accuracy: 0.8667 - val_loss: 1.4453\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9859 - loss: 0.0456 - val_accuracy: 0.8667 - val_loss: 1.4009\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8667 - val_loss: 1.3677\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.8889 - val_loss: 1.4168\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9988 - loss: 0.0114 - val_accuracy: 0.8889 - val_loss: 1.6400\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9988 - loss: 0.0202 - val_accuracy: 0.8556 - val_loss: 2.1201\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8444 - val_loss: 1.0404\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9951 - loss: 0.0195 - val_accuracy: 0.8667 - val_loss: 1.0092\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9940 - loss: 0.0275 - val_accuracy: 0.8667 - val_loss: 1.1851\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8667 - val_loss: 1.3081\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0113 - val_accuracy: 0.8778 - val_loss: 1.3832\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 509ms/step\n","\n","Validation Accuracy: 0.8777777777777778\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.90      0.84      0.87        45\n","           1       0.85      0.91      0.88        45\n","\n","    accuracy                           0.88        90\n","   macro avg       0.88      0.88      0.88        90\n","weighted avg       0.88      0.88      0.88        90\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/three_T_Marge.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional: Uncomment if needed to verify column names)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'Target' column for binary classification\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'Target' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values  # Features (all columns except 'Target')\n","y = data['Target'].values                 # Labels (the 'Target' column)\n","\n","# Split data into training and validation sets (80-20 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]      # Adding channel dimension\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# Stacked Conv1D layers with BatchNormalization and Dropout\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","# LSTM layer for sequential dependencies\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","\n","# Dense Layers for final prediction with Dropout for regularization\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n","\n","# Compile the Model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n","\n","# Evaluate the model on the validation data\n","val_predictions = (model.predict(X_val) > 0.5).astype(int)\n","accuracy = accuracy_score(y_val, val_predictions)\n","\n","print(\"\\nValidation Accuracy:\", accuracy)\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QO97A5_1Xzno","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739031397449,"user_tz":-360,"elapsed":3142,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"fd42d130-dd17-4836-fb89-850aee8223a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n"]}],"source":["pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4GiYYkQLC2bJ","executionInfo":{"status":"ok","timestamp":1739034193807,"user_tz":-360,"elapsed":2796333,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"bb2cbcc8-7e98-4767-8317-d5e6f45a8b62"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:16:37,865] A new study created in memory with name: no-name-1d35c2ff-6783-40c4-83c0-b30c9577600c\n"]},{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC_CFV', 'AdaBoost_GDC_CFV', 'AdaBoost_CTDT_CFV', 'SVM_DPC_CFV',\n","       'Random Forest_PAAC_CFV', 'Decision Tree_PAAC_CFV', 'MLP_GDC_CFV',\n","       'Neural Network_GDC_CFV', 'Random Forest_DPC_CFV', 'XGBoost_CTDT_CFV',\n","       'Random Forest_Class_GDC_CPFV',\n","       'Multilayer Perceptron (Custom MLP)_Prob_GDC_CPFV',\n","       'Neural Network (MLPClassifier)_Class_GDC_CPFV',\n","       'AdaBoost_Prob_GDC_CPFV', 'AdaBoost_Class_GDC_CPFV',\n","       'LightGBM_Prob_GDC_CPFV', 'LightGBM_Class_GDC_CPFV',\n","       'XGBoost_Class_GDC_CPFV', 'Gradient Boosting_Prob_GDC_CPFV',\n","       'Gradient Boosting_Class_GDC_CPFV', 'SVM_PCP_PFV', 'AdaBoost_PAAC_PFV',\n","       'MLP_PCP_PFV', 'Neural Network_PCP_PFV', 'LightGBM_PCP_PFV',\n","       'Gradient Boosting_PCP_PFV', 'Naive Bayes_PCP_PFV', 'k-NN_PCP_PFV',\n","       'Logistic Regression_PCP_PFV', 'MLP_PAAC_PFV', 'Target'],\n","      dtype='object')\n","   SVM_ACC_CFV  AdaBoost_GDC_CFV  AdaBoost_CTDT_CFV  SVM_DPC_CFV  \\\n","0     0.830810          0.609364           0.501956     0.952625   \n","1     0.987548          0.609364           0.554677     0.972204   \n","2     0.211028          0.464830           0.494672     0.515618   \n","3     0.552428          0.534680           0.549709     0.978918   \n","4     0.607083          0.495365           0.492617     0.551777   \n","\n","   Random Forest_PAAC_CFV  Decision Tree_PAAC_CFV  MLP_GDC_CFV  \\\n","0                0.641420                0.816456     0.999924   \n","1                0.902640                0.983607     0.999924   \n","2                0.309144                0.034483     0.008714   \n","3                0.674516                0.108696     0.996928   \n","4                0.340675                0.034483     0.302993   \n","\n","   Neural Network_GDC_CFV  Random Forest_DPC_CFV  XGBoost_CTDT_CFV  ...  \\\n","0                0.998631               0.497160          0.984983  ...   \n","1                0.998631               0.831769          0.995125  ...   \n","2                0.220107               0.396653          0.372593  ...   \n","3                0.986588               0.621746          0.977446  ...   \n","4                0.360953               0.461488          0.275739  ...   \n","\n","   AdaBoost_PAAC_PFV  MLP_PCP_PFV  Neural Network_PCP_PFV  LightGBM_PCP_PFV  \\\n","0           0.526144     0.994466                1.000000          0.996590   \n","1           0.662831     0.997881                0.999993          0.998059   \n","2           0.462671     0.208824                0.100467          0.010956   \n","3           0.533153     0.965118                0.981379          0.798022   \n","4           0.481918     0.263974                0.130168          0.214318   \n","\n","   Gradient Boosting_PCP_PFV  Naive Bayes_PCP_PFV  k-NN_PCP_PFV  \\\n","0               1.000000e+00             1.000000           1.0   \n","1               1.000000e+00             1.000000           1.0   \n","2               2.058050e-10             0.037961           0.0   \n","3               9.860029e-01             0.247224           1.0   \n","4               1.049644e-07             0.095711           0.0   \n","\n","   Logistic Regression_PCP_PFV  MLP_PAAC_PFV  Target  \n","0                     0.938520      0.999980       1  \n","1                     0.987474      0.999933       1  \n","2                     0.193770      0.999456       1  \n","3                     0.612827      0.992662       1  \n","4                     0.425606      0.075896       1  \n","\n","[5 rows x 31 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:17:23,214] Trial 0 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 4, 'num_conv2_filters': 224, 'kernel_size2': 2, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 48, 'dropout_rate': 0.3857564920075546, 'optimizer': 'rmsprop', 'learning_rate': 0.0005195562380018076}. Best is trial 0 with value: 0.8666666666666667.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9299\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3ce00a2020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 782ms/step"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3ce00a2020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 453ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:17:46,952] Trial 1 finished with value: 0.8 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 5, 'num_conv2_filters': 256, 'kernel_size2': 2, 'num_lstm_units': 48, 'dense_units1': 64, 'dense_units2': 32, 'dropout_rate': 0.3401406880249805, 'optimizer': 'rmsprop', 'learning_rate': 0.0013132844313561518}. Best is trial 0 with value: 0.8666666666666667.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8000, AUC: 0.9274\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:18:22,128] Trial 2 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 4, 'num_conv2_filters': 192, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 256, 'dense_units2': 112, 'dropout_rate': 0.23692517952723882, 'optimizer': 'rmsprop', 'learning_rate': 0.00019770914933264582}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9017\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 413ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:18:56,695] Trial 3 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 192, 'kernel_size2': 3, 'num_lstm_units': 64, 'dense_units1': 192, 'dense_units2': 80, 'dropout_rate': 0.2154273622014238, 'optimizer': 'adam', 'learning_rate': 0.0008397709584830247}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:19:13,032] Trial 4 finished with value: 0.7888888888888889 and parameters: {'num_conv1_filters': 256, 'kernel_size1': 5, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 64, 'dense_units1': 256, 'dense_units2': 112, 'dropout_rate': 0.25041856789309674, 'optimizer': 'rmsprop', 'learning_rate': 0.006070801400068574}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7889, AUC: 0.9205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:19:38,106] Trial 5 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 64, 'dense_units1': 256, 'dense_units2': 80, 'dropout_rate': 0.46800239572360497, 'optimizer': 'rmsprop', 'learning_rate': 0.00013762792476511678}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:19:55,609] Trial 6 finished with value: 0.8111111111111111 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 2, 'num_conv2_filters': 128, 'kernel_size2': 3, 'num_lstm_units': 32, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.49621943217004993, 'optimizer': 'rmsprop', 'learning_rate': 0.006765960260587706}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8111, AUC: 0.9180\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:20:22,239] Trial 7 finished with value: 0.7888888888888889 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 128, 'dense_units1': 256, 'dense_units2': 64, 'dropout_rate': 0.20496349339113573, 'optimizer': 'adam', 'learning_rate': 0.008717252312979968}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7889, AUC: 0.9195\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:20:58,653] Trial 8 finished with value: 0.8333333333333334 and parameters: {'num_conv1_filters': 224, 'kernel_size1': 3, 'num_conv2_filters': 256, 'kernel_size2': 4, 'num_lstm_units': 32, 'dense_units1': 96, 'dense_units2': 80, 'dropout_rate': 0.2797305877893256, 'optimizer': 'adam', 'learning_rate': 0.0004082772190017886}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8333, AUC: 0.9081\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:21:25,197] Trial 9 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 224, 'kernel_size1': 5, 'num_conv2_filters': 192, 'kernel_size2': 2, 'num_lstm_units': 96, 'dense_units1': 96, 'dense_units2': 48, 'dropout_rate': 0.20336051724015175, 'optimizer': 'rmsprop', 'learning_rate': 0.000182556147803304}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:21:52,262] Trial 10 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 4, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.3199154616754211, 'optimizer': 'adam', 'learning_rate': 0.0021375838235910944}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9200\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:22:26,843] Trial 11 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 192, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 192, 'dense_units2': 96, 'dropout_rate': 0.26676720845021396, 'optimizer': 'adam', 'learning_rate': 0.0003882715713381636}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:22:47,550] Trial 12 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 3, 'num_conv2_filters': 192, 'kernel_size2': 3, 'num_lstm_units': 80, 'dense_units1': 192, 'dense_units2': 96, 'dropout_rate': 0.4052796737505019, 'optimizer': 'adam', 'learning_rate': 0.002294579046841853}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9240\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:23:15,621] Trial 13 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 4, 'num_conv2_filters': 160, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.238482931329339, 'optimizer': 'adam', 'learning_rate': 0.00010313698042048924}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9052\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:23:40,287] Trial 14 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 224, 'kernel_size2': 3, 'num_lstm_units': 64, 'dense_units1': 160, 'dense_units2': 128, 'dropout_rate': 0.3010934208486797, 'optimizer': 'rmsprop', 'learning_rate': 0.0007837726925312196}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 429ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:24:15,268] Trial 15 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 4, 'num_conv2_filters': 160, 'kernel_size2': 5, 'num_lstm_units': 80, 'dense_units1': 224, 'dense_units2': 64, 'dropout_rate': 0.23408867959174642, 'optimizer': 'adam', 'learning_rate': 0.0002415794107693615}. Best is trial 2 with value: 0.8777777777777778.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:24:38,128] Trial 16 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 224, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 160, 'dense_units2': 112, 'dropout_rate': 0.3783100835368919, 'optimizer': 'rmsprop', 'learning_rate': 0.0010446652394180433}. Best is trial 16 with value: 0.8888888888888888.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9126\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:24:58,600] Trial 17 finished with value: 0.7888888888888889 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 224, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 160, 'dense_units2': 112, 'dropout_rate': 0.3841117023050871, 'optimizer': 'rmsprop', 'learning_rate': 0.0027405593164382554}. Best is trial 16 with value: 0.8888888888888888.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7889, AUC: 0.9284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:25:29,857] Trial 18 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 4, 'num_conv2_filters': 256, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 128, 'dense_units2': 128, 'dropout_rate': 0.43162301454274854, 'optimizer': 'rmsprop', 'learning_rate': 0.0012426474350256298}. Best is trial 16 with value: 0.8888888888888888.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9151\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:25:55,762] Trial 19 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 5, 'num_conv2_filters': 224, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 112, 'dropout_rate': 0.3579137859866101, 'optimizer': 'rmsprop', 'learning_rate': 0.00023264988562732324}. Best is trial 16 with value: 0.8888888888888888.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9022\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:26:20,744] Trial 20 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.4388744375287397, 'optimizer': 'rmsprop', 'learning_rate': 0.0005402550028951545}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:26:37,476] Trial 21 finished with value: 0.8222222222222222 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.46676695280587566, 'optimizer': 'rmsprop', 'learning_rate': 0.0005894769233228712}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8222, AUC: 0.9185\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:27:11,959] Trial 22 finished with value: 0.9 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 224, 'dense_units2': 112, 'dropout_rate': 0.4284345805812696, 'optimizer': 'rmsprop', 'learning_rate': 0.0002720369295788122}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:27:40,364] Trial 23 finished with value: 0.8 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.43504546975914693, 'optimizer': 'rmsprop', 'learning_rate': 0.00034633423715514015}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8000, AUC: 0.9195\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:28:13,651] Trial 24 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 96, 'dense_units1': 160, 'dense_units2': 128, 'dropout_rate': 0.42977811913603037, 'optimizer': 'rmsprop', 'learning_rate': 0.0013419525167168466}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9165\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:28:39,416] Trial 25 finished with value: 0.8222222222222222 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.40041717341634275, 'optimizer': 'rmsprop', 'learning_rate': 0.0006133546509545049}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8222, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:29:00,655] Trial 26 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 80, 'dropout_rate': 0.363587419108542, 'optimizer': 'rmsprop', 'learning_rate': 0.0035022887645121225}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9091\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:29:36,130] Trial 27 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 2, 'num_conv2_filters': 128, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 160, 'dense_units2': 96, 'dropout_rate': 0.4531253991339573, 'optimizer': 'rmsprop', 'learning_rate': 0.0003332009444498807}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:29:58,227] Trial 28 finished with value: 0.8222222222222222 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 160, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 192, 'dense_units2': 128, 'dropout_rate': 0.49847269529811955, 'optimizer': 'rmsprop', 'learning_rate': 0.0016826521986080085}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8222, AUC: 0.9170\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:30:24,323] Trial 29 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 112, 'dropout_rate': 0.38218487305289134, 'optimizer': 'rmsprop', 'learning_rate': 0.0005149410413730945}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9328\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:30:58,246] Trial 30 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 96, 'dense_units2': 96, 'dropout_rate': 0.4084461654072649, 'optimizer': 'rmsprop', 'learning_rate': 0.0006264746993430751}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9101\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:31:23,079] Trial 31 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 112, 'dropout_rate': 0.37978635396858745, 'optimizer': 'rmsprop', 'learning_rate': 0.0009432125475972705}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9185\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:31:47,478] Trial 32 finished with value: 0.9 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 112, 'dropout_rate': 0.3297200720285363, 'optimizer': 'rmsprop', 'learning_rate': 0.00042167512511940035}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 430ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:32:21,569] Trial 33 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 64, 'dense_units2': 112, 'dropout_rate': 0.3347575579413271, 'optimizer': 'rmsprop', 'learning_rate': 0.00045690623526949625}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9170\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 439ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:32:48,437] Trial 34 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 32, 'dropout_rate': 0.3335849413377709, 'optimizer': 'rmsprop', 'learning_rate': 0.00023202983959779181}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9151\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:33:23,515] Trial 35 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 96, 'dense_units2': 128, 'dropout_rate': 0.30584507278660156, 'optimizer': 'rmsprop', 'learning_rate': 0.0003062103679411845}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9180\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:33:48,142] Trial 36 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 2, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 112, 'dropout_rate': 0.41316931362391146, 'optimizer': 'rmsprop', 'learning_rate': 0.00048304437216003013}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9343\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:34:14,774] Trial 37 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 2, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 80, 'dropout_rate': 0.45041684857460196, 'optimizer': 'rmsprop', 'learning_rate': 0.00015573975262816775}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:34:39,155] Trial 38 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 48, 'dense_units1': 256, 'dense_units2': 96, 'dropout_rate': 0.480113889386291, 'optimizer': 'rmsprop', 'learning_rate': 0.0007473816431593972}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:35:06,332] Trial 39 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 128, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 96, 'dense_units2': 112, 'dropout_rate': 0.3477911553276441, 'optimizer': 'rmsprop', 'learning_rate': 0.00026059847093089336}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:35:39,377] Trial 40 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 4, 'num_conv2_filters': 160, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.42219841567660704, 'optimizer': 'rmsprop', 'learning_rate': 0.000506742548560947}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:36:05,559] Trial 41 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 32, 'dropout_rate': 0.3271916332290464, 'optimizer': 'rmsprop', 'learning_rate': 0.00019475569869225874}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:36:29,611] Trial 42 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 32, 'dropout_rate': 0.37126641507253555, 'optimizer': 'rmsprop', 'learning_rate': 0.0002859642519297389}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:37:07,761] Trial 43 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 64, 'dense_units2': 48, 'dropout_rate': 0.39550222017899467, 'optimizer': 'rmsprop', 'learning_rate': 0.0001214599936065478}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9319\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:37:32,132] Trial 44 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 4, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 96, 'dense_units1': 96, 'dense_units2': 80, 'dropout_rate': 0.30832260367473285, 'optimizer': 'rmsprop', 'learning_rate': 0.00040762038817784905}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9062\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:37:56,377] Trial 45 finished with value: 0.9 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 64, 'dropout_rate': 0.2809156204023053, 'optimizer': 'rmsprop', 'learning_rate': 0.00016568338592572583}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9240\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:38:22,517] Trial 46 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 80, 'dense_units1': 256, 'dense_units2': 96, 'dropout_rate': 0.35089890462774276, 'optimizer': 'adam', 'learning_rate': 0.0002289074620857911}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9086\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:38:46,154] Trial 47 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 96, 'dense_units1': 96, 'dense_units2': 64, 'dropout_rate': 0.45114031436022384, 'optimizer': 'rmsprop', 'learning_rate': 0.0007070854436000053}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:39:21,633] Trial 48 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 128, 'dense_units2': 32, 'dropout_rate': 0.34119261886615065, 'optimizer': 'rmsprop', 'learning_rate': 0.00037350913703492524}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9160\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:39:47,209] Trial 49 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.2896496386560212, 'optimizer': 'adam', 'learning_rate': 0.0002147605754639168}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9264\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 464ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:40:14,646] Trial 50 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 4, 'num_conv2_filters': 128, 'kernel_size2': 2, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 96, 'dropout_rate': 0.31813183558397207, 'optimizer': 'rmsprop', 'learning_rate': 0.00028756899676281533}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9274\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:40:36,973] Trial 51 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 32, 'dense_units1': 256, 'dense_units2': 96, 'dropout_rate': 0.4729298860608798, 'optimizer': 'rmsprop', 'learning_rate': 0.0008213067754912466}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9121\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:41:02,367] Trial 52 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 48, 'dense_units1': 256, 'dense_units2': 80, 'dropout_rate': 0.48544972182560264, 'optimizer': 'rmsprop', 'learning_rate': 0.0005294764797224167}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9235\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:41:28,256] Trial 53 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 256, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 80, 'dense_units1': 256, 'dense_units2': 112, 'dropout_rate': 0.39305423536300593, 'optimizer': 'rmsprop', 'learning_rate': 0.0004389031820411707}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9151\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:41:51,391] Trial 54 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 5, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 48, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.4802204275580691, 'optimizer': 'rmsprop', 'learning_rate': 0.001007348585672578}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9136\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:42:16,462] Trial 55 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 64, 'dense_units1': 224, 'dense_units2': 112, 'dropout_rate': 0.444015268066653, 'optimizer': 'rmsprop', 'learning_rate': 0.0007206493407136303}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9175\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:42:45,405] Trial 56 finished with value: 0.8222222222222222 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 3, 'num_lstm_units': 48, 'dense_units1': 256, 'dense_units2': 96, 'dropout_rate': 0.4664978014543547, 'optimizer': 'adam', 'learning_rate': 0.0005660325282766793}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8222, AUC: 0.9210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:43:18,513] Trial 57 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 32, 'dense_units1': 192, 'dense_units2': 80, 'dropout_rate': 0.4146600938289846, 'optimizer': 'rmsprop', 'learning_rate': 0.0012259426437496086}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9175\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:43:42,267] Trial 58 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 4, 'num_conv2_filters': 160, 'kernel_size2': 5, 'num_lstm_units': 80, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.3651692647136453, 'optimizer': 'rmsprop', 'learning_rate': 0.00035454250624855735}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:44:14,844] Trial 59 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 64, 'dense_units1': 160, 'dense_units2': 48, 'dropout_rate': 0.259292256008418, 'optimizer': 'rmsprop', 'learning_rate': 0.0006712199456975137}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:44:44,022] Trial 60 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 112, 'dropout_rate': 0.4377757576503925, 'optimizer': 'rmsprop', 'learning_rate': 0.0001382463843202584}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:45:08,885] Trial 61 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 32, 'dropout_rate': 0.37357609955517296, 'optimizer': 'rmsprop', 'learning_rate': 0.00028958041833235037}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9249\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:45:33,297] Trial 62 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 48, 'dropout_rate': 0.36711743983547174, 'optimizer': 'rmsprop', 'learning_rate': 0.0002584484833740593}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:45:59,199] Trial 63 finished with value: 0.9 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 64, 'dense_units2': 32, 'dropout_rate': 0.32602715774674, 'optimizer': 'rmsprop', 'learning_rate': 0.00018726488888635973}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9146\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:46:27,592] Trial 64 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 96, 'dense_units2': 32, 'dropout_rate': 0.3518144588378527, 'optimizer': 'rmsprop', 'learning_rate': 0.00042466745367040684}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:47:04,514] Trial 65 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 96, 'dense_units2': 32, 'dropout_rate': 0.42355677251868656, 'optimizer': 'rmsprop', 'learning_rate': 0.00032753604338603225}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9185\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:47:29,246] Trial 66 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 64, 'dense_units2': 112, 'dropout_rate': 0.33547469096156746, 'optimizer': 'rmsprop', 'learning_rate': 0.0008178805242227795}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9146\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:47:48,210] Trial 67 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 224, 'dense_units2': 48, 'dropout_rate': 0.4605041172124452, 'optimizer': 'adam', 'learning_rate': 0.000528176072549651}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9170\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 16:48:52,675] Trial 68 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 192, 'dense_units2': 96, 'dropout_rate': 0.48773254327334614, 'optimizer': 'rmsprop', 'learning_rate': 0.0003759454747664822}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:03:13,831] Trial 69 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 4, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 64, 'dropout_rate': 0.39220612589452636, 'optimizer': 'rmsprop', 'learning_rate': 0.004488533369201741}. Best is trial 20 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9170\n","\n","Best Hyperparameters: {'num_conv1_filters': 128, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.4388744375287397, 'optimizer': 'rmsprop', 'learning_rate': 0.0005402550028951545}\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n","from sklearn.model_selection import train_test_split\n","import optuna\n","\n","# Load the dataset\n","dataset_path = \"/content/three_T_Marge.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'Target' column for binary classification\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'Target' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values  # Features\n","y = data['Target'].values                 # Labels\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]\n","\n","def objective(trial):\n","    # Hyperparameter tuning\n","    num_conv1_filters = trial.suggest_int('num_conv1_filters', 32, 256, step=32)\n","    kernel_size1 = trial.suggest_int('kernel_size1', 2, 5)\n","    num_conv2_filters = trial.suggest_int('num_conv2_filters', 64, 256, step=32)\n","    kernel_size2 = trial.suggest_int('kernel_size2', 2, 5)\n","    num_lstm_units = trial.suggest_int('num_lstm_units', 32, 128, step=16)\n","    dense_units1 = trial.suggest_int('dense_units1', 64, 256, step=32)\n","    dense_units2 = trial.suggest_int('dense_units2', 32, 128, step=16)\n","    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n","    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n","    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n","\n","    optimizer = Adam(learning_rate=learning_rate) if optimizer_name == 'adam' else RMSprop(learning_rate=learning_rate)\n","\n","    model = Sequential([\n","        Conv1D(num_conv1_filters, kernel_size1, activation='relu', input_shape=(X_train.shape[1], 1)),\n","        BatchNormalization(),\n","        MaxPooling1D(pool_size=2),\n","        Dropout(dropout_rate),\n","        Conv1D(num_conv2_filters, kernel_size2, activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling1D(pool_size=2),\n","        Dropout(dropout_rate),\n","        LSTM(num_lstm_units, activation='relu'),\n","        Dense(dense_units1, activation='swish'),\n","        Dropout(dropout_rate),\n","        Dense(dense_units2, activation='swish'),\n","        Dropout(dropout_rate),\n","        Dense(1, activation='sigmoid')\n","    ])\n","\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping])\n","\n","    val_probs = model.predict(X_val).flatten()\n","    val_predictions = (val_probs > 0.5).astype(int)\n","\n","    accuracy = accuracy_score(y_val, val_predictions)\n","    auc_score = roc_auc_score(y_val, val_probs)\n","\n","    print(f\"Trial Accuracy: {accuracy:.4f}, AUC: {auc_score:.4f}\")\n","    return accuracy  # Return accuracy, or change to auc_score if preferred\n","\n","# Run optimization\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=70)\n","\n","# Display best hyperparameters\n","print(\"\\nBest Hyperparameters:\", study.best_params)\n","\n","# Evaluate with best model\n","best_model = study.best_trial.user_attrs.get(\"model\", None)\n","if best_model:\n","    val_probs = best_model.predict(X_val).flatten()\n","    val_predictions = (val_probs > 0.5).astype(int)\n","    print(\"\\nFinal Model Accuracy:\", accuracy_score(y_val, val_predictions))\n","    print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAt38TasVBE6","executionInfo":{"status":"ok","timestamp":1739036707599,"user_tz":-360,"elapsed":1952198,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"5a7f3582-bf99-4bed-b863-d0847628dddd"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:12:52,705] A new study created in memory with name: no-name-16d55b56-5395-4169-aba5-191929ca22b1\n"]},{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_ACC_CFV', 'AdaBoost_GDC_CFV', 'AdaBoost_CTDT_CFV', 'SVM_DPC_CFV',\n","       'Random Forest_PAAC_CFV', 'Decision Tree_PAAC_CFV', 'MLP_GDC_CFV',\n","       'Neural Network_GDC_CFV', 'Random Forest_DPC_CFV', 'XGBoost_CTDT_CFV',\n","       'Random Forest_Class_GDC_CPFV',\n","       'Multilayer Perceptron (Custom MLP)_Prob_GDC_CPFV',\n","       'Neural Network (MLPClassifier)_Class_GDC_CPFV',\n","       'AdaBoost_Prob_GDC_CPFV', 'AdaBoost_Class_GDC_CPFV',\n","       'LightGBM_Prob_GDC_CPFV', 'LightGBM_Class_GDC_CPFV',\n","       'XGBoost_Class_GDC_CPFV', 'Gradient Boosting_Prob_GDC_CPFV',\n","       'Gradient Boosting_Class_GDC_CPFV', 'SVM_PCP_PFV', 'AdaBoost_PAAC_PFV',\n","       'MLP_PCP_PFV', 'Neural Network_PCP_PFV', 'LightGBM_PCP_PFV',\n","       'Gradient Boosting_PCP_PFV', 'Naive Bayes_PCP_PFV', 'k-NN_PCP_PFV',\n","       'Logistic Regression_PCP_PFV', 'MLP_PAAC_PFV', 'Target'],\n","      dtype='object')\n","   SVM_ACC_CFV  AdaBoost_GDC_CFV  AdaBoost_CTDT_CFV  SVM_DPC_CFV  \\\n","0     0.830810          0.609364           0.501956     0.952625   \n","1     0.987548          0.609364           0.554677     0.972204   \n","2     0.211028          0.464830           0.494672     0.515618   \n","3     0.552428          0.534680           0.549709     0.978918   \n","4     0.607083          0.495365           0.492617     0.551777   \n","\n","   Random Forest_PAAC_CFV  Decision Tree_PAAC_CFV  MLP_GDC_CFV  \\\n","0                0.641420                0.816456     0.999924   \n","1                0.902640                0.983607     0.999924   \n","2                0.309144                0.034483     0.008714   \n","3                0.674516                0.108696     0.996928   \n","4                0.340675                0.034483     0.302993   \n","\n","   Neural Network_GDC_CFV  Random Forest_DPC_CFV  XGBoost_CTDT_CFV  ...  \\\n","0                0.998631               0.497160          0.984983  ...   \n","1                0.998631               0.831769          0.995125  ...   \n","2                0.220107               0.396653          0.372593  ...   \n","3                0.986588               0.621746          0.977446  ...   \n","4                0.360953               0.461488          0.275739  ...   \n","\n","   AdaBoost_PAAC_PFV  MLP_PCP_PFV  Neural Network_PCP_PFV  LightGBM_PCP_PFV  \\\n","0           0.526144     0.994466                1.000000          0.996590   \n","1           0.662831     0.997881                0.999993          0.998059   \n","2           0.462671     0.208824                0.100467          0.010956   \n","3           0.533153     0.965118                0.981379          0.798022   \n","4           0.481918     0.263974                0.130168          0.214318   \n","\n","   Gradient Boosting_PCP_PFV  Naive Bayes_PCP_PFV  k-NN_PCP_PFV  \\\n","0               1.000000e+00             1.000000           1.0   \n","1               1.000000e+00             1.000000           1.0   \n","2               2.058050e-10             0.037961           0.0   \n","3               9.860029e-01             0.247224           1.0   \n","4               1.049644e-07             0.095711           0.0   \n","\n","   Logistic Regression_PCP_PFV  MLP_PAAC_PFV  Target  \n","0                     0.938520      0.999980       1  \n","1                     0.987474      0.999933       1  \n","2                     0.193770      0.999456       1  \n","3                     0.612827      0.992662       1  \n","4                     0.425606      0.075896       1  \n","\n","[5 rows x 31 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:13:27,061] Trial 0 finished with value: 0.9 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 80, 'dense_units1': 192, 'dense_units2': 128, 'dropout_rate': 0.4839862331249046, 'optimizer': 'rmsprop', 'learning_rate': 0.001106774442634639}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:14:03,430] Trial 1 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 224, 'kernel_size1': 3, 'num_conv2_filters': 192, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 64, 'dense_units2': 96, 'dropout_rate': 0.2596642225355303, 'optimizer': 'rmsprop', 'learning_rate': 0.0002605735135089195}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9175\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7809049b8a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 530ms/step"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7809049b8a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:14:35,138] Trial 2 finished with value: 0.8111111111111111 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 4, 'num_conv2_filters': 224, 'kernel_size2': 3, 'num_lstm_units': 80, 'dense_units1': 96, 'dense_units2': 32, 'dropout_rate': 0.25848224107020806, 'optimizer': 'adam', 'learning_rate': 0.0021634584182793994}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8111, AUC: 0.8993\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:15:11,196] Trial 3 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 2, 'num_lstm_units': 112, 'dense_units1': 256, 'dense_units2': 80, 'dropout_rate': 0.2730947665006397, 'optimizer': 'adam', 'learning_rate': 0.0003321573245169928}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9304\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:15:39,214] Trial 4 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 256, 'kernel_size1': 5, 'num_conv2_filters': 128, 'kernel_size2': 4, 'num_lstm_units': 64, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.49016849942708585, 'optimizer': 'rmsprop', 'learning_rate': 0.000123982789004588}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:16:06,512] Trial 5 finished with value: 0.7777777777777778 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 32, 'dense_units1': 256, 'dense_units2': 32, 'dropout_rate': 0.35412968939420564, 'optimizer': 'adam', 'learning_rate': 0.0008971659482459025}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7778, AUC: 0.9116\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:16:41,744] Trial 6 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 4, 'num_conv2_filters': 256, 'kernel_size2': 3, 'num_lstm_units': 64, 'dense_units1': 128, 'dense_units2': 128, 'dropout_rate': 0.49036136476788067, 'optimizer': 'adam', 'learning_rate': 0.0007602537873880895}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9190\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:17:08,998] Trial 7 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 4, 'num_conv2_filters': 96, 'kernel_size2': 2, 'num_lstm_units': 64, 'dense_units1': 224, 'dense_units2': 64, 'dropout_rate': 0.310008476581179, 'optimizer': 'adam', 'learning_rate': 0.009682706094832141}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9304\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:17:43,220] Trial 8 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 5, 'num_conv2_filters': 96, 'kernel_size2': 2, 'num_lstm_units': 128, 'dense_units1': 256, 'dense_units2': 64, 'dropout_rate': 0.2830558687800415, 'optimizer': 'adam', 'learning_rate': 0.0005106651378706238}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9358\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:18:02,425] Trial 9 finished with value: 0.8 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 4, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 80, 'dense_units1': 160, 'dense_units2': 32, 'dropout_rate': 0.21599163809649313, 'optimizer': 'adam', 'learning_rate': 0.0004697282487490249}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8000, AUC: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:18:31,809] Trial 10 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 32, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.4115072619104671, 'optimizer': 'rmsprop', 'learning_rate': 0.0027121556631505826}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9244\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:19:03,322] Trial 11 finished with value: 0.8333333333333334 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 112, 'dense_units1': 192, 'dense_units2': 80, 'dropout_rate': 0.39693855584469634, 'optimizer': 'rmsprop', 'learning_rate': 0.0019674978048630186}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8333, AUC: 0.9195\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:19:32,656] Trial 12 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 192, 'dense_units2': 96, 'dropout_rate': 0.4334677745759173, 'optimizer': 'rmsprop', 'learning_rate': 0.00019816400550614393}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9116\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:20:07,119] Trial 13 finished with value: 0.8111111111111111 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 160, 'kernel_size2': 2, 'num_lstm_units': 96, 'dense_units1': 224, 'dense_units2': 64, 'dropout_rate': 0.3397802502981735, 'optimizer': 'rmsprop', 'learning_rate': 0.00029916678191416163}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8111, AUC: 0.9274\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:20:28,061] Trial 14 finished with value: 0.8111111111111111 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 3, 'num_lstm_units': 112, 'dense_units1': 160, 'dense_units2': 96, 'dropout_rate': 0.2241451062350765, 'optimizer': 'adam', 'learning_rate': 0.0043226919472404545}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8111, AUC: 0.9294\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:21:00,630] Trial 15 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 160, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 224, 'dense_units2': 80, 'dropout_rate': 0.45183994516042, 'optimizer': 'rmsprop', 'learning_rate': 0.001349271069142512}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9165\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:21:37,224] Trial 16 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 2, 'num_lstm_units': 48, 'dense_units1': 128, 'dense_units2': 112, 'dropout_rate': 0.3487034565041388, 'optimizer': 'rmsprop', 'learning_rate': 0.00048885059777424}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:22:16,786] Trial 17 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 48, 'dropout_rate': 0.3820508193515871, 'optimizer': 'adam', 'learning_rate': 0.00010713433792450806}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:22:47,668] Trial 18 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 160, 'kernel_size2': 4, 'num_lstm_units': 80, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.31482269683195285, 'optimizer': 'adam', 'learning_rate': 0.0012735915915261062}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9274\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:23:07,979] Trial 19 finished with value: 0.8222222222222222 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 5, 'num_lstm_units': 96, 'dense_units1': 128, 'dense_units2': 80, 'dropout_rate': 0.4576781637241417, 'optimizer': 'rmsprop', 'learning_rate': 0.0052473916041157085}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8222, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 392ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:23:36,058] Trial 20 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 256, 'kernel_size1': 2, 'num_conv2_filters': 128, 'kernel_size2': 2, 'num_lstm_units': 48, 'dense_units1': 256, 'dense_units2': 48, 'dropout_rate': 0.20119979743340546, 'optimizer': 'rmsprop', 'learning_rate': 0.00018431965683509652}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:23:56,718] Trial 21 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 32, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.41797234416050444, 'optimizer': 'rmsprop', 'learning_rate': 0.0024234443730546803}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9170\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:24:26,877] Trial 22 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 48, 'dense_units1': 160, 'dense_units2': 128, 'dropout_rate': 0.3839223963720265, 'optimizer': 'rmsprop', 'learning_rate': 0.0032426031639375213}. Best is trial 0 with value: 0.9.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9215\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:24:49,977] Trial 23 finished with value: 0.9111111111111111 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 160, 'dense_units2': 112, 'dropout_rate': 0.4572886914281392, 'optimizer': 'rmsprop', 'learning_rate': 0.0014230000820774995}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9111, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:25:25,159] Trial 24 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 3, 'num_lstm_units': 128, 'dense_units1': 160, 'dense_units2': 96, 'dropout_rate': 0.49837370271681614, 'optimizer': 'rmsprop', 'learning_rate': 0.0006912974532310119}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:25:47,204] Trial 25 finished with value: 0.9 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 96, 'dense_units2': 128, 'dropout_rate': 0.4654661339818517, 'optimizer': 'rmsprop', 'learning_rate': 0.0014628671409510183}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:26:10,253] Trial 26 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 4, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 64, 'dense_units2': 128, 'dropout_rate': 0.46360919410434126, 'optimizer': 'rmsprop', 'learning_rate': 0.001470957224911602}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:26:33,326] Trial 27 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 192, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 96, 'dense_units2': 128, 'dropout_rate': 0.47177974191499555, 'optimizer': 'rmsprop', 'learning_rate': 0.0011592386671668117}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9244\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:27:07,689] Trial 28 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 96, 'dense_units2': 112, 'dropout_rate': 0.4328970827614493, 'optimizer': 'rmsprop', 'learning_rate': 0.0017239675173682959}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9264\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:27:31,506] Trial 29 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 4, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 128, 'dense_units1': 128, 'dense_units2': 128, 'dropout_rate': 0.44042893168907216, 'optimizer': 'rmsprop', 'learning_rate': 0.0009152509350074101}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9057\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:27:50,537] Trial 30 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 3, 'num_conv2_filters': 192, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 64, 'dense_units2': 96, 'dropout_rate': 0.4744446575454246, 'optimizer': 'rmsprop', 'learning_rate': 0.003852922877804752}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9269\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:28:15,394] Trial 31 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 96, 'dense_units2': 112, 'dropout_rate': 0.25561278181811764, 'optimizer': 'rmsprop', 'learning_rate': 0.00037030995720612305}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:28:35,108] Trial 32 finished with value: 0.7777777777777778 and parameters: {'num_conv1_filters': 224, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 80, 'dense_units1': 64, 'dense_units2': 128, 'dropout_rate': 0.2815028232564717, 'optimizer': 'adam', 'learning_rate': 0.0006876239040888729}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7778, AUC: 0.9195\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:29:10,054] Trial 33 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 96, 'dropout_rate': 0.4787894547144196, 'optimizer': 'rmsprop', 'learning_rate': 0.0009728770913251985}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9240\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:29:32,911] Trial 34 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 5, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 128, 'dense_units1': 160, 'dense_units2': 80, 'dropout_rate': 0.4484777092272851, 'optimizer': 'adam', 'learning_rate': 0.0015760280332571975}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9328\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:29:58,537] Trial 35 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 224, 'kernel_size1': 4, 'num_conv2_filters': 224, 'kernel_size2': 5, 'num_lstm_units': 112, 'dense_units1': 256, 'dense_units2': 112, 'dropout_rate': 0.48530619236816375, 'optimizer': 'rmsprop', 'learning_rate': 0.0006203240652186169}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.8988\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:30:18,478] Trial 36 finished with value: 0.7777777777777778 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 64, 'dense_units1': 128, 'dense_units2': 128, 'dropout_rate': 0.4150087402943754, 'optimizer': 'adam', 'learning_rate': 0.0064869359206560905}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7778, AUC: 0.9077\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:30:38,753] Trial 37 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 4, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 80, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.3669643382945723, 'optimizer': 'adam', 'learning_rate': 0.002108949107422473}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9200\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:31:11,909] Trial 38 finished with value: 0.8 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 4, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 96, 'dense_units1': 96, 'dense_units2': 80, 'dropout_rate': 0.325441859238898, 'optimizer': 'rmsprop', 'learning_rate': 0.001124373856941203}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8000, AUC: 0.8948\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:31:47,376] Trial 39 finished with value: 0.9111111111111111 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 256, 'kernel_size2': 4, 'num_lstm_units': 64, 'dense_units1': 192, 'dense_units2': 64, 'dropout_rate': 0.4991207826449434, 'optimizer': 'adam', 'learning_rate': 0.0003394783599300136}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9111, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:32:23,729] Trial 40 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 2, 'num_conv2_filters': 256, 'kernel_size2': 4, 'num_lstm_units': 64, 'dense_units1': 192, 'dense_units2': 48, 'dropout_rate': 0.49824109794194615, 'optimizer': 'adam', 'learning_rate': 0.00020972578575635046}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9274\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:32:48,355] Trial 41 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 224, 'kernel_size2': 4, 'num_lstm_units': 80, 'dense_units1': 224, 'dense_units2': 64, 'dropout_rate': 0.46667457210615954, 'optimizer': 'adam', 'learning_rate': 0.0003390636066781761}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:33:25,255] Trial 42 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 256, 'kernel_size2': 4, 'num_lstm_units': 64, 'dense_units1': 160, 'dense_units2': 64, 'dropout_rate': 0.4839736448207552, 'optimizer': 'adam', 'learning_rate': 0.0002439166006244325}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9215\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:34:01,319] Trial 43 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 224, 'kernel_size2': 4, 'num_lstm_units': 80, 'dense_units1': 192, 'dense_units2': 64, 'dropout_rate': 0.2834240627096231, 'optimizer': 'adam', 'learning_rate': 0.00014594538894512697}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9215\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:34:30,491] Trial 44 finished with value: 0.8333333333333334 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 2, 'num_lstm_units': 128, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.24982309105122147, 'optimizer': 'adam', 'learning_rate': 0.00038735591459082666}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8333, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:34:48,058] Trial 45 finished with value: 0.7888888888888889 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 5, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 64, 'dense_units1': 192, 'dense_units2': 80, 'dropout_rate': 0.4288470270819292, 'optimizer': 'adam', 'learning_rate': 0.0005677066809739889}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7889, AUC: 0.9195\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 464ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:35:11,798] Trial 46 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 192, 'kernel_size2': 3, 'num_lstm_units': 48, 'dense_units1': 128, 'dense_units2': 96, 'dropout_rate': 0.4490559631625852, 'optimizer': 'rmsprop', 'learning_rate': 0.0007824693720927362}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:35:45,008] Trial 47 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 4, 'num_conv2_filters': 128, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 160, 'dense_units2': 112, 'dropout_rate': 0.4987786591176432, 'optimizer': 'adam', 'learning_rate': 0.0008148861553032437}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9249\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:36:10,369] Trial 48 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 224, 'dense_units2': 48, 'dropout_rate': 0.404472161214409, 'optimizer': 'rmsprop', 'learning_rate': 0.0004488131770144706}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9299\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:36:27,873] Trial 49 finished with value: 0.8222222222222222 and parameters: {'num_conv1_filters': 192, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 64, 'dropout_rate': 0.29266012998697044, 'optimizer': 'adam', 'learning_rate': 0.0027784656928479057}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8222, AUC: 0.9200\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:36:54,484] Trial 50 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 128, 'kernel_size1': 3, 'num_conv2_filters': 128, 'kernel_size2': 5, 'num_lstm_units': 80, 'dense_units1': 192, 'dense_units2': 80, 'dropout_rate': 0.4651024083405445, 'optimizer': 'rmsprop', 'learning_rate': 0.0002649028812196163}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9249\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:37:16,833] Trial 51 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 32, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.48107988621256026, 'optimizer': 'rmsprop', 'learning_rate': 0.0018295033635580284}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9269\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:37:32,856] Trial 52 finished with value: 0.7222222222222222 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 32, 'dense_units1': 192, 'dense_units2': 96, 'dropout_rate': 0.4420510566381721, 'optimizer': 'rmsprop', 'learning_rate': 0.002488511367442217}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.7222, AUC: 0.9220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:37:51,503] Trial 53 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 48, 'dense_units1': 160, 'dense_units2': 112, 'dropout_rate': 0.41445551176483375, 'optimizer': 'rmsprop', 'learning_rate': 0.0029981721592808952}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9200\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:38:13,315] Trial 54 finished with value: 0.9 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.37856734784545365, 'optimizer': 'rmsprop', 'learning_rate': 0.0013663088363370757}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9279\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:38:34,423] Trial 55 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 2, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.23847311527129977, 'optimizer': 'rmsprop', 'learning_rate': 0.0010421851950394275}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:38:57,230] Trial 56 finished with value: 0.8555555555555555 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.36465464754741805, 'optimizer': 'rmsprop', 'learning_rate': 0.0012979717717398252}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8556, AUC: 0.9205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:39:19,442] Trial 57 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 160, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 2, 'num_lstm_units': 128, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.3351521977725253, 'optimizer': 'rmsprop', 'learning_rate': 0.0016748375027141151}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9170\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:39:41,841] Trial 58 finished with value: 0.8777777777777778 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 2, 'num_conv2_filters': 160, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 48, 'dropout_rate': 0.3962431527019364, 'optimizer': 'adam', 'learning_rate': 0.0013994257689124115}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8778, AUC: 0.9225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:40:04,543] Trial 59 finished with value: 0.9111111111111111 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.45773325639056367, 'optimizer': 'rmsprop', 'learning_rate': 0.002025057377990718}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9111, AUC: 0.9205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:40:36,857] Trial 60 finished with value: 0.9 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.4242733915510756, 'optimizer': 'rmsprop', 'learning_rate': 0.0020795616532204336}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.9000, AUC: 0.9244\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:40:57,842] Trial 61 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.45561768911810746, 'optimizer': 'rmsprop', 'learning_rate': 0.0020289580210517237}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9299\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:41:18,538] Trial 62 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.4260524312884954, 'optimizer': 'rmsprop', 'learning_rate': 0.00230794647646852}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9235\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:41:39,897] Trial 63 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 80, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.46034301426501095, 'optimizer': 'rmsprop', 'learning_rate': 0.003641345605668129}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9175\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:41:55,836] Trial 64 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 128, 'dropout_rate': 0.4883942316805539, 'optimizer': 'rmsprop', 'learning_rate': 0.0011255215161211473}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9151\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:42:25,631] Trial 65 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 3, 'num_lstm_units': 112, 'dense_units1': 224, 'dense_units2': 112, 'dropout_rate': 0.4711093624665582, 'optimizer': 'rmsprop', 'learning_rate': 0.0018549914528310258}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9323\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:42:48,551] Trial 66 finished with value: 0.8666666666666667 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 2, 'num_conv2_filters': 96, 'kernel_size2': 3, 'num_lstm_units': 64, 'dense_units1': 224, 'dense_units2': 128, 'dropout_rate': 0.4381939851570643, 'optimizer': 'rmsprop', 'learning_rate': 0.0014079129653573495}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8667, AUC: 0.9269\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:43:04,766] Trial 67 finished with value: 0.8333333333333334 and parameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 96, 'dense_units1': 256, 'dense_units2': 32, 'dropout_rate': 0.3869852555793159, 'optimizer': 'rmsprop', 'learning_rate': 0.0009341637877405674}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8333, AUC: 0.9190\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:43:25,472] Trial 68 finished with value: 0.8888888888888888 and parameters: {'num_conv1_filters': 32, 'kernel_size1': 4, 'num_conv2_filters': 96, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 192, 'dense_units2': 112, 'dropout_rate': 0.42526275553507953, 'optimizer': 'rmsprop', 'learning_rate': 0.0015514584260716536}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8889, AUC: 0.9230\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 459ms/step\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-02-08 17:45:07,568] Trial 69 finished with value: 0.8444444444444444 and parameters: {'num_conv1_filters': 96, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 112, 'dense_units1': 128, 'dense_units2': 128, 'dropout_rate': 0.44690090962670637, 'optimizer': 'rmsprop', 'learning_rate': 0.00119045351608449}. Best is trial 23 with value: 0.9111111111111111.\n"]},{"output_type":"stream","name":"stdout","text":["Trial Accuracy: 0.8444, AUC: 0.9269\n","\n","Best Hyperparameters: {'num_conv1_filters': 64, 'kernel_size1': 3, 'num_conv2_filters': 64, 'kernel_size2': 4, 'num_lstm_units': 128, 'dense_units1': 160, 'dense_units2': 112, 'dropout_rate': 0.4572886914281392, 'optimizer': 'rmsprop', 'learning_rate': 0.0014230000820774995}\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n","from sklearn.model_selection import train_test_split\n","import optuna\n","\n","# Load the dataset\n","dataset_path = \"/content/three_T_Marge.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'Target' column for binary classification\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'Target' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values  # Features\n","y = data['Target'].values                 # Labels\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]\n","\n","def objective(trial):\n","    # Hyperparameter tuning\n","    num_conv1_filters = trial.suggest_int('num_conv1_filters', 32, 256, step=32)\n","    kernel_size1 = trial.suggest_int('kernel_size1', 2, 5)\n","    num_conv2_filters = trial.suggest_int('num_conv2_filters', 64, 256, step=32)\n","    kernel_size2 = trial.suggest_int('kernel_size2', 2, 5)\n","    num_lstm_units = trial.suggest_int('num_lstm_units', 32, 128, step=16)\n","    dense_units1 = trial.suggest_int('dense_units1', 64, 256, step=32)\n","    dense_units2 = trial.suggest_int('dense_units2', 32, 128, step=16)\n","    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n","    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n","    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n","\n","    optimizer = Adam(learning_rate=learning_rate) if optimizer_name == 'adam' else RMSprop(learning_rate=learning_rate)\n","\n","    model = Sequential([\n","        Conv1D(num_conv1_filters, kernel_size1, activation='relu', input_shape=(X_train.shape[1], 1)),\n","        BatchNormalization(),\n","        MaxPooling1D(pool_size=2),\n","        Dropout(dropout_rate),\n","        Conv1D(num_conv2_filters, kernel_size2, activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling1D(pool_size=2),\n","        Dropout(dropout_rate),\n","        LSTM(num_lstm_units, activation='relu'),\n","        Dense(dense_units1, activation='swish'),\n","        Dropout(dropout_rate),\n","        Dense(dense_units2, activation='swish'),\n","        Dropout(dropout_rate),\n","        Dense(1, activation='sigmoid')\n","    ])\n","\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=59, batch_size=32, verbose=0, callbacks=[early_stopping])\n","\n","    val_probs = model.predict(X_val).flatten()\n","    val_predictions = (val_probs > 0.5).astype(int)\n","\n","    accuracy = accuracy_score(y_val, val_predictions)\n","    auc_score = roc_auc_score(y_val, val_probs)\n","\n","    print(f\"Trial Accuracy: {accuracy:.4f}, AUC: {auc_score:.4f}\")\n","    return accuracy  # Return accuracy, or change to auc_score if preferred\n","\n","# Run optimization\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=70)\n","\n","# Display best hyperparameters\n","print(\"\\nBest Hyperparameters:\", study.best_params)\n","\n","# Evaluate with best model\n","best_model = study.best_trial.user_attrs.get(\"model\", None)\n","if best_model:\n","    val_probs = best_model.predict(X_val).flatten()\n","    val_predictions = (val_probs > 0.5).astype(int)\n","\n","    # Compute additional metrics\n","    tn, fp, fn, tp = confusion_matrix(y_val, val_predictions).ravel()\n","\n","    sensitivity = tp / (tp + fn)  # Recall or True Positive Rate\n","    specificity = tn / (tn + fp)  # True Negative Rate\n","    mcc = matthews_corrcoef(y_val, val_predictions)  # Matthews Correlation Coefficient\n","    kappa = cohen_kappa_score(y_val, val_predictions)  # Cohen’s Kappa\n","    auc = roc_auc_score(y_val, val_probs)  # AUC-ROC Score\n","\n","    # Print final evaluation metrics\n","    print(\"\\nFinal Model Accuracy:\", accuracy_score(y_val, val_predictions))\n","    print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n","\n","    # Print additional metrics\n","    print(f\"Accuracy: {accuracy_score(y_val, val_predictions):.4f}\")\n","    print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n","    print(f\"Specificity: {specificity:.4f}\")\n","    print(f\"MCC: {mcc:.4f}\")\n","    print(f\"Kappa: {kappa:.4f}\")\n","    print(f\"AUC: {auc:.4f}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"zkhz0qiorfzl"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}