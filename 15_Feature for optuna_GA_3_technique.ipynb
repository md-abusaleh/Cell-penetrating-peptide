{"cells":[{"cell_type":"markdown","metadata":{"id":"IVmT3Y6P86jr"},"source":["# DPC"]},{"cell_type":"code","source":[],"metadata":{"id":"f2-O73TL2az5","executionInfo":{"status":"ok","timestamp":1737090800402,"user_tz":-360,"elapsed":567,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDD6GKjTrfwb","executionInfo":{"status":"ok","timestamp":1737090907623,"user_tz":-360,"elapsed":94570,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"78d19446-701c-40f1-f77f-8b6dad352ee4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["CPFV (Combined Probability and Class Feature Vector)"],"metadata":{"id":"AqiY0Yz1i7dR"}},{"cell_type":"code","source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"ACC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_AAC.csv\",\n","    \"CTDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTDC.csv\",\n","    \"CTD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTD.csv\",\n","    \"GDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_GDC.csv\",\n","    \"PAAC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_PAAC.csv\",\n","    \"PCP\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_PCP.csv\",\n","    \"TPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_TPC.csv\",\n","    \"CTDT\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTDT.csv\",\n","    \"DPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_DPC.csv\",\n","    \"CTDD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/CPFV_CTDD.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/Dataset Marge CPFV.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"],"metadata":{"id":"SPr2XnlIDzZ_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf7f17de-4883-4747-f8f7-e52f3031036b","executionInfo":{"status":"ok","timestamp":1737090930740,"user_tz":-360,"elapsed":10993,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/Dataset Marge CPFV.csv\n"]}]},{"cell_type":"code","source":["# Check the shape of the merged dataset\n","print(\"Shape of the merged dataset:\", combined_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZTZzk5_i8NL","outputId":"8e1c07fa-7844-4b3e-c56e-49a8fa22f22d","executionInfo":{"status":"ok","timestamp":1737090934741,"user_tz":-360,"elapsed":508,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the merged dataset: (300, 240)\n"]}]},{"cell_type":"code","source":["df=pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/Optuna_Dataset Marge CPFV.csv\")"],"metadata":{"id":"QnGPryNRjjkP","executionInfo":{"status":"ok","timestamp":1737090973135,"user_tz":-360,"elapsed":786,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zz6MlMtIjlUu","outputId":"6f5426ce-75b8-48b2-8869-676901af12ef","executionInfo":{"status":"ok","timestamp":1737090976951,"user_tz":-360,"elapsed":510,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 241)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["!pip install deap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxJlB5rJtC7x","outputId":"bed9ad8d-53af-4f48-d776-0930d5f2615b","executionInfo":{"status":"ok","timestamp":1737090983813,"user_tz":-360,"elapsed":3913,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting deap\n","  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (1.26.4)\n","Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: deap\n","Successfully installed deap-1.4.2\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from deap import base, creator, tools, algorithms\n","import random\n","\n","# Load the dataset\n","data_path = '/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/CPFV (Combined Probability and Class Feature Vector)/Optuna_Dataset Marge CPFV.csv'\n","data = pd.read_csv(data_path)\n","\n","# Assuming the last column is the target, split features and labels\n","X = data.iloc[:, :-1]  # Features\n","y = data.iloc[:, -1]   # Target\n","\n","# Encode target labels if necessary\n","if y.dtype == object or np.issubdtype(y.dtype, np.number):  # Handle both string and numeric labels\n","    le = LabelEncoder()\n","    y = le.fit_transform(y.astype(str))  # Ensure all targets are treated as strings for classification\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create the individual and fitness functions\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# Classifier to evaluate fitness\n","def evaluate(individual):\n","    selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n","    if len(selected_features) == 0:  # Prevent division by zero\n","        return 0,\n","\n","    X_train_selected = X_train.iloc[:, selected_features]\n","    X_val_selected = X_val.iloc[:, selected_features]\n","\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_train_selected, y_train)\n","    y_pred = model.predict(X_val_selected)\n","\n","    accuracy = accuracy_score(y_val, y_pred)\n","    return accuracy,\n","\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# Parameters for the Genetic Algorithm\n","population_size = 50\n","generations = 20\n","crossover_probability = 0.8\n","mutation_probability = 0.1\n","\n","# Initialize population\n","population = toolbox.population(n=population_size)\n","\n","# Run the Genetic Algorithm\n","result_population, logbook = algorithms.eaSimple(\n","    population,\n","    toolbox,\n","    cxpb=crossover_probability,\n","    mutpb=mutation_probability,\n","    ngen=generations,\n","    verbose=True\n",")\n","\n","# Find the best individual\n","best_individual = tools.selBest(result_population, k=1)[0]\n","selected_features = [i for i, bit in enumerate(best_individual) if bit == 1 and i < len(X.columns)]  # Bounds check\n","\n","# Select top 20 features based on their importance\n","if len(selected_features) > 15:\n","    feature_importances = pd.Series(best_individual).sort_values(ascending=False)\n","    selected_features = list(feature_importances.head(15).index)\n","\n","# Evaluate performance using the top 15 features\n","X_train_selected = X_train.iloc[:, selected_features]\n","X_val_selected = X_val.iloc[:, selected_features]\n","\n","final_model = RandomForestClassifier(random_state=42)\n","final_model.fit(X_train_selected, y_train)\n","final_predictions = final_model.predict(X_val_selected)\n","final_accuracy = accuracy_score(y_val, final_predictions)\n","\n","print(f\"Top 15 Selected features: {selected_features}\")\n","print(f\"Final Accuracy with top 15 selected features: {final_accuracy}\")\n","\n","# Save the top 15 selected features\n","pd.DataFrame({'Selected Features': selected_features}).to_csv('/content/CPFV_top_15_selected_features.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzUnaXxSyMhe","outputId":"79f4af36-80b0-4e8e-e7db-c4457c6be7c5","executionInfo":{"status":"ok","timestamp":1737092170888,"user_tz":-360,"elapsed":208181,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t50    \n","1  \t45    \n","2  \t45    \n","3  \t42    \n","4  \t44    \n","5  \t40    \n","6  \t37    \n","7  \t38    \n","8  \t38    \n","9  \t44    \n","10 \t37    \n","11 \t42    \n","12 \t41    \n","13 \t30    \n","14 \t41    \n","15 \t43    \n","16 \t44    \n","17 \t48    \n","18 \t41    \n","19 \t40    \n","20 \t40    \n","Top 15 Selected features: [0, 78, 133, 138, 139, 140, 142, 148, 155, 156, 162, 164, 165, 167, 169]\n","Final Accuracy with top 15 selected features: 0.9166666666666666\n"]}]},{"cell_type":"code","source":["selected_feature_columns = data.columns[selected_features]\n","# Create a filtered dataset with only the selected top 15 features\n","filtered_data = data[selected_feature_columns.tolist() + [data.columns[-1]]]\n","filtered_data_path = '/content/CPFV_Top_15_Features.csv'\n","filtered_data.to_csv(filtered_data_path, index=False)\n","\n","print(f\"Filtered dataset with top 15 features saved to: {filtered_data_path}\")"],"metadata":{"id":"birrS7SaWGyk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28b79a9d-260d-45e9-d416-5716defaf37d","executionInfo":{"status":"ok","timestamp":1737092175495,"user_tz":-360,"elapsed":762,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset with top 15 features saved to: /content/CPFV_Top_15_Features.csv\n"]}]},{"cell_type":"code","source":["data=pd.read_csv(\"/content/CPFV_Top_15_Features.csv\")\n"],"metadata":{"id":"dfbu6xYHwXUL","executionInfo":{"status":"ok","timestamp":1737092191035,"user_tz":-360,"elapsed":538,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uADa3ffws27","outputId":"bee5f9ad-1c8a-420f-f581-92f9185eecc4","executionInfo":{"status":"ok","timestamp":1737092195778,"user_tz":-360,"elapsed":808,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 16)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"98sSejDtR5VD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Class Feature Vector (CFV)"],"metadata":{"id":"KykXgdLExeCP"}},{"cell_type":"code","source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"ACC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_AAC.csv\",\n","    \"CTDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTDC (1).csv\",\n","    \"CTD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTD (3).csv\",\n","    \"GDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_GDC.csv\",\n","    \"PAAC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_PAAC.csv\",\n","    \"PCP\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_PCP.csv\",\n","    \"TPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_TPC.csv\",\n","    \"CTDT\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTDT.csv\",\n","    \"DPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_DPC (1).csv\",\n","    \"CTDD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/CFV_CTDD.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/Optuna_Dataset Marge CFV.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"],"metadata":{"id":"-rpIaFvKwxD4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b3f3e57-339a-43bd-9db0-213053890227"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/Optuna_Dataset Marge CFV.csv\n"]}]},{"cell_type":"code","source":["# Check the shape of the merged dataset\n","print(\"Shape of the merged dataset:\", combined_df.shape)"],"metadata":{"id":"hFUb_w-IxtQs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad91ce61-0800-453b-c9b7-e67391c0f0e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the merged dataset: (300, 120)\n"]}]},{"cell_type":"code","source":["df=pd.read_csv(\"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/Optuna_Dataset Marge CFV.csv\")"],"metadata":{"id":"P1N9vmtextUn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"86_AeqSqxtp7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ec41e80-262f-4166-d608-bdd6ed35b456"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 121)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["!pip install deap"],"metadata":{"id":"BYmlV1dUxts9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b64623ba-f27c-4f03-c33e-6167432871d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (1.26.4)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from deap import base, creator, tools, algorithms\n","import random\n","\n","# Load the dataset\n","data_path = '/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Class Feature Vector (CFV)/Optuna_Dataset Marge CFV.csv'\n","data = pd.read_csv(data_path)\n","\n","# Assuming the last column is the target, split features and labels\n","X = data.iloc[:, :-1]  # Features\n","y = data.iloc[:, -1]   # Target\n","\n","# Encode target labels if necessary\n","if y.dtype == object or np.issubdtype(y.dtype, np.number):  # Handle both string and numeric labels\n","    le = LabelEncoder()\n","    y = le.fit_transform(y.astype(str))  # Ensure all targets are treated as strings for classification\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create the individual and fitness functions\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# Classifier to evaluate fitness\n","def evaluate(individual):\n","    selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n","    if len(selected_features) == 0:  # Prevent division by zero\n","        return 0,\n","\n","    X_train_selected = X_train.iloc[:, selected_features]\n","    X_val_selected = X_val.iloc[:, selected_features]\n","\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_train_selected, y_train)\n","    y_pred = model.predict(X_val_selected)\n","\n","    accuracy = accuracy_score(y_val, y_pred)\n","    return accuracy,\n","\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# Parameters for the Genetic Algorithm\n","population_size = 50\n","generations = 20\n","crossover_probability = 0.8\n","mutation_probability = 0.1\n","\n","# Initialize population\n","population = toolbox.population(n=population_size)\n","\n","# Run the Genetic Algorithm\n","result_population, logbook = algorithms.eaSimple(\n","    population,\n","    toolbox,\n","    cxpb=crossover_probability,\n","    mutpb=mutation_probability,\n","    ngen=generations,\n","    verbose=True\n",")\n","\n","# Find the best individual\n","best_individual = tools.selBest(result_population, k=1)[0]\n","selected_features = [i for i, bit in enumerate(best_individual) if bit == 1 and i < len(X.columns)]  # Bounds check\n","\n","# Select top 15 features based on their importance\n","if len(selected_features) > 15:\n","    feature_importances = pd.Series(best_individual).sort_values(ascending=False)\n","    selected_features = list(feature_importances.head(15).index)\n","\n","# Evaluate performance using the top 15 features\n","X_train_selected = X_train.iloc[:, selected_features]\n","X_val_selected = X_val.iloc[:, selected_features]\n","\n","final_model = RandomForestClassifier(random_state=42)\n","final_model.fit(X_train_selected, y_train)\n","final_predictions = final_model.predict(X_val_selected)\n","final_accuracy = accuracy_score(y_val, final_predictions)\n","\n","print(f\"Top 15 Selected features: {selected_features}\")\n","print(f\"Final Accuracy with top 15 selected features: {final_accuracy}\")\n","\n","# Save the top 20 selected features\n","pd.DataFrame({'Selected Features': selected_features}).to_csv('/content/CFV_top_15_selected_features.csv', index=False)\n"],"metadata":{"id":"UJxv5SM8uvbN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21696fcb-f706-43dd-dffd-f617d7aeab72","executionInfo":{"status":"ok","timestamp":1737092469087,"user_tz":-360,"elapsed":206120,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n","/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n"]},{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t50    \n","1  \t40    \n","2  \t38    \n","3  \t36    \n","4  \t35    \n","5  \t46    \n","6  \t42    \n","7  \t46    \n","8  \t47    \n","9  \t37    \n","10 \t36    \n","11 \t37    \n","12 \t48    \n","13 \t48    \n","14 \t43    \n","15 \t43    \n","16 \t41    \n","17 \t39    \n","18 \t42    \n","19 \t34    \n","20 \t41    \n","Top 15 Selected features: [60, 73, 36, 46, 48, 50, 55, 56, 58, 59, 64, 65, 67, 69, 71]\n","Final Accuracy with top 15 selected features: 0.9166666666666666\n"]}]},{"cell_type":"code","source":["selected_feature_columns = data.columns[selected_features]\n","# Create a filtered dataset with only the selected top 15 features\n","filtered_data = data[selected_feature_columns.tolist() + [data.columns[-1]]]\n","filtered_data_path = '/content/CFV_Top_15_Features.csv'\n","filtered_data.to_csv(filtered_data_path, index=False)\n","\n","print(f\"Filtered dataset with top 15 features saved to: {filtered_data_path}\")"],"metadata":{"id":"dSe8hO4Eu0Zp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"92316d7d-ff37-49f2-8906-2965cbe3ec1e","executionInfo":{"status":"ok","timestamp":1737092483300,"user_tz":-360,"elapsed":660,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset with top 15 features saved to: /content/CFV_Top_15_Features.csv\n"]}]},{"cell_type":"markdown","source":["PFV (Probability Feature Vector)"],"metadata":{"id":"qfB6BsmDJkgm"}},{"cell_type":"code","source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"ACC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_AAC_OPTUNA_probability_predictions.csv\",\n","    \"CTDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTDC_OPTUNA_probability_predictions.csv\",\n","    \"CTD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTD_OPTUNA_probability_predictions.csv\",\n","    \"GDC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_GDC_OPTUNA_probability_predictions.csv\",\n","    \"PAAC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_PAAC_OPTUNA_probability_predictions.csv\",\n","    \"PCP\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_PCP_OPTUNA_probability_predictions.csv\",\n","    \"TPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_TPC_OPTUNA_probability_predictions.csv\",\n","    \"CTDT\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTDT_OPTUNA_probability_predictions.csv\",\n","    \"DPC\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_DPC_OPTUNA_probability_predictions.csv\",\n","    \"CTDD\": \"/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/N_CTDD_OPTUNA_probability_predictions.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/Optuna_Dataset Marge PFV.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTbyC6WxKbcN","outputId":"ff662002-020b-4c43-93a6-31da94f72940"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/Optuna_Dataset Marge PFV.csv\n"]}]},{"cell_type":"code","source":["# Check the shape of the merged dataset\n","print(\"Shape of the merged dataset:\", combined_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d5z3mrMKffb","outputId":"3ba41bdc-cc1c-48d4-ba71-c787eb756287"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the merged dataset: (300, 121)\n"]}]},{"cell_type":"code","source":["df=pd.read_csv(\"/content/Optuna_Dataset Marge PFV.csv\")"],"metadata":{"id":"6WZxp0YYKfh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bexOUGn-K2Uj","outputId":"7cfda135-5d20-4712-ab24-4b93d717fdc7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 121)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fjk-izOeliFs","outputId":"73497226-4399-480c-a612-5eac7f960f79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['SVM_ACC', 'Decision Tree_ACC', 'Random Forest_ACC',\n","       'Logistic Regression_ACC', 'k-NN_ACC', 'Naive Bayes_ACC',\n","       'Gradient Boosting_ACC', 'XGBoost_ACC', 'LightGBM_ACC', 'AdaBoost_ACC',\n","       ...\n","       'Logistic Regression_CTDD', 'k-NN_CTDD', 'Naive Bayes_CTDD',\n","       'Gradient Boosting_CTDD', 'XGBoost_CTDD', 'LightGBM_CTDD',\n","       'AdaBoost_CTDD', 'Neural Network_CTDD', 'MLP_CTDD', 'Target'],\n","      dtype='object', length=121)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["!pip install deap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7LIhYQPPK2dy","outputId":"7c84ce5c-a9b5-407b-9cd8-d050604ae4b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (1.26.4)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from deap import base, creator, tools, algorithms\n","import random\n","\n","# Load the dataset\n","data_path = '/content/drive/MyDrive/Cell penetrating peptide/NEW_WORK/Probabilites Dataset Marge/Optuna_Dataset Marge PFV (1).csv'\n","data = pd.read_csv(data_path)\n","\n","# Assuming the last column is the target, split features and labels\n","X = data.iloc[:, :-1]  # Features\n","y = data.iloc[:, -1]   # Target\n","\n","# Encode target labels if necessary\n","if y.dtype == object or np.issubdtype(y.dtype, np.number):  # Handle both string and numeric labels\n","    le = LabelEncoder()\n","    y = le.fit_transform(y.astype(str))  # Ensure all targets are treated as strings for classification\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create the individual and fitness functions\n","creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X.columns))\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# Classifier to evaluate fitness\n","def evaluate(individual):\n","    selected_features = [i for i, bit in enumerate(individual) if bit == 1]\n","    if len(selected_features) == 0:  # Prevent division by zero\n","        return 0,\n","\n","    X_train_selected = X_train.iloc[:, selected_features]\n","    X_val_selected = X_val.iloc[:, selected_features]\n","\n","    model = RandomForestClassifier(random_state=42)\n","    model.fit(X_train_selected, y_train)\n","    y_pred = model.predict(X_val_selected)\n","\n","    accuracy = accuracy_score(y_val, y_pred)\n","    return accuracy,\n","\n","toolbox.register(\"mate\", tools.cxTwoPoint)\n","toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n","toolbox.register(\"select\", tools.selTournament, tournsize=3)\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# Parameters for the Genetic Algorithm\n","population_size = 50\n","generations = 20\n","crossover_probability = 0.8\n","mutation_probability = 0.1\n","\n","# Initialize population\n","population = toolbox.population(n=population_size)\n","\n","# Run the Genetic Algorithm\n","result_population, logbook = algorithms.eaSimple(\n","    population,\n","    toolbox,\n","    cxpb=crossover_probability,\n","    mutpb=mutation_probability,\n","    ngen=generations,\n","    verbose=True\n",")\n","\n","# Find the best individual\n","best_individual = tools.selBest(result_population, k=1)[0]\n","selected_features = [i for i, bit in enumerate(best_individual) if bit == 1 and i < len(X.columns)]  # Bounds check\n","\n","# Select top 15 features based on their importance\n","if len(selected_features) > 15:\n","    feature_importances = pd.Series(best_individual).sort_values(ascending=False)\n","    selected_features = list(feature_importances.head(15).index)\n","\n","# Evaluate performance using the top 15 features\n","X_train_selected = X_train.iloc[:, selected_features]\n","X_val_selected = X_val.iloc[:, selected_features]\n","\n","final_model = RandomForestClassifier(random_state=42)\n","final_model.fit(X_train_selected, y_train)\n","final_predictions = final_model.predict(X_val_selected)\n","final_accuracy = accuracy_score(y_val, final_predictions)\n","\n","print(f\"Top 15 Selected features: {selected_features}\")\n","print(f\"Final Accuracy with top 15 selected features: {final_accuracy}\")\n","\n","# Save the top 20 selected features\n","pd.DataFrame({'Selected Features': selected_features}).to_csv('/content/PFV_top_15_selected_features.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkxGOohWKfk-","outputId":"16743f3e-5c82-4f2f-b71b-7d7c0893d98b","executionInfo":{"status":"ok","timestamp":1737092779881,"user_tz":-360,"elapsed":205131,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n","/usr/local/lib/python3.11/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n","  warnings.warn(\"A class named '{0}' has already been created and it \"\n"]},{"output_type":"stream","name":"stdout","text":["gen\tnevals\n","0  \t50    \n","1  \t36    \n","2  \t41    \n","3  \t43    \n","4  \t42    \n","5  \t36    \n","6  \t38    \n","7  \t35    \n","8  \t40    \n","9  \t46    \n","10 \t41    \n","11 \t38    \n","12 \t45    \n","13 \t45    \n","14 \t43    \n","15 \t34    \n","16 \t41    \n","17 \t39    \n","18 \t44    \n","19 \t40    \n","20 \t39    \n","Top 15 Selected features: [0, 36, 75, 74, 72, 70, 69, 68, 66, 65, 55, 52, 51, 49, 48]\n","Final Accuracy with top 15 selected features: 0.8833333333333333\n"]}]},{"cell_type":"code","source":["selected_feature_columns = data.columns[selected_features]\n","# Create a filtered dataset with only the selected top 15 features\n","filtered_data = data[selected_feature_columns.tolist() + [data.columns[-1]]]\n","filtered_data_path = '/content/PFV_Top_15_Features.csv'\n","filtered_data.to_csv(filtered_data_path, index=False)\n","\n","print(f\"Filtered dataset with top 15 features saved to: {filtered_data_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUPiBwintQEh","outputId":"4cdb57ee-dabb-4b85-8c5c-7b49fe2ec9d4","executionInfo":{"status":"ok","timestamp":1737092807063,"user_tz":-360,"elapsed":490,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset with top 15 features saved to: /content/PFV_Top_15_Features.csv\n"]}]},{"cell_type":"markdown","source":["Three technique dataset are marge"],"metadata":{"id":"ODrnUtK4zpyY"}},{"cell_type":"code","source":["#marge the column\n","import pandas as pd\n","\n","# Define the file paths and prefixes\n","data_paths = {\n","    \"CFV\": \"/content/CFV_Top_15_Features.csv\",\n","    \"CPFV\": \"/content/CPFV_Top_15_Features.csv\",\n","    \"PFV\": \"/content/PFV_Top_15_Features.csv\",\n","}\n","\n","processed_dfs = []\n","final_target_column = None  # To store the unique Target column\n","\n","# Process each file in the dictionary\n","for prefix, path in data_paths.items():\n","    # Load the dataset\n","    df = pd.read_csv(path)\n","\n","    # If a 'Target' column exists, store it and ensure only one is retained\n","    if 'Target' in df.columns:\n","        if final_target_column is None:\n","            final_target_column = df['Target']  # Retain the first Target column\n","        df.drop(columns=['Target'], inplace=True)  # Drop from the current dataset\n","\n","    # Drop the 'True_Label' column if it exists\n","    df.drop(columns=['True_Label'], inplace=True, errors='ignore')\n","\n","    # Rename columns with the prefix\n","    df = df.rename(columns=lambda col: f\"{col}_{prefix}\" if 'probabilities' not in col else col)\n","\n","    # Append the processed DataFrame to the list\n","    processed_dfs.append(df)\n","\n","# Concatenate all DataFrames column-wise\n","combined_df = pd.concat(processed_dfs, axis=1)\n","\n","# Add the retained 'Target' column to the final dataset\n","if final_target_column is not None:\n","    combined_df['Target'] = final_target_column\n","\n","# Save the combined DataFrame\n","output_file = \"/content/three_T_Marge.csv\"\n","combined_df.to_csv(output_file, index=False)\n","\n","print(f\"Processed dataset saved to: {output_file}\")"],"metadata":{"id":"2OD-hWPNzwAJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9edb5ce7-c138-4c12-9465-908a676045de","executionInfo":{"status":"ok","timestamp":1737092823677,"user_tz":-360,"elapsed":621,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed dataset saved to: /content/three_T_Marge.csv\n"]}]},{"cell_type":"code","source":["df=pd.read_csv(\"/content/three_T_Marge.csv\")"],"metadata":{"id":"aLoO-cdN9kzp","executionInfo":{"status":"ok","timestamp":1737092830381,"user_tz":-360,"elapsed":671,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtUnE-v99sz3","outputId":"7486d1fc-5367-437d-e6c5-51f7bd1e4c05","executionInfo":{"status":"ok","timestamp":1737092833586,"user_tz":-360,"elapsed":603,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300, 46)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["Hybrid CNN-LSTM Model for Cell-Penetrating Peptide Classification"],"metadata":{"id":"Y-z2nEIL-9Er"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","dataset_path = \"/content/three_T_Marge.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Inspect the dataset (Optional: Uncomment if needed to verify column names)\n","print(\"Dataset Columns:\", data.columns)\n","print(data.head())\n","\n","# Ensure the dataset contains a 'Target' column for binary classification\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'Target' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values  # Features (all columns except 'Target')\n","y = data['Target'].values                 # Labels (the 'Target' column)\n","\n","# Split data into training and validation sets (80-20 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape data for Conv1D input\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension\n","X_val = X_val[..., np.newaxis]      # Adding channel dimension\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# Stacked Conv1D layers with BatchNormalization and Dropout\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","# LSTM layer for sequential dependencies\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","\n","# Dense Layers for final prediction with Dropout for regularization\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n","\n","# Compile the Model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n","\n","# Evaluate the model on the validation data\n","val_predictions = (model.predict(X_val) > 0.5).astype(int)\n","accuracy = accuracy_score(y_val, val_predictions)\n","\n","print(\"\\nValidation Accuracy:\", accuracy)\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vaN7uof89unN","outputId":"75a65b76-4208-4e70-86d2-0a9c362ed568","executionInfo":{"status":"ok","timestamp":1737092899956,"user_tz":-360,"elapsed":62844,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Columns: Index(['SVM_PCP_CFV', 'Decision Tree_TPC_CFV', 'SVM_GDC_CFV',\n","       'Neural Network_GDC_CFV', 'SVM_PAAC_CFV', 'Random Forest_PAAC_CFV',\n","       'XGBoost_PAAC_CFV', 'LightGBM_PAAC_CFV', 'Neural Network_PAAC_CFV',\n","       'MLP_PAAC_CFV', 'k-NN_PCP_CFV', 'Naive Bayes_PCP_CFV',\n","       'XGBoost_PCP_CFV', 'AdaBoost_PCP_CFV', 'MLP_PCP_CFV',\n","       'SVM_Class_ACC_CPFV', 'Logistic Regression_Class_GDC_CPFV',\n","       'Gradient Boosting_Prob_PCP_CPFV', 'AdaBoost_Class_PCP_CPFV',\n","       'AdaBoost_Prob_PCP_CPFV',\n","       'Neural Network (MLPClassifier)_Class_PCP_CPFV',\n","       'Multilayer Perceptron (Custom MLP)_Class_PCP_CPFV',\n","       'Random Forest_Class_TPC_CPFV', 'Naive Bayes_Prob_TPC_CPFV',\n","       'Gradient Boosting_Class_TPC_CPFV', 'AdaBoost_Class_TPC_CPFV',\n","       'Neural Network (MLPClassifier)_Class_TPC_CPFV',\n","       'Neural Network (MLPClassifier)_Prob_TPC_CPFV',\n","       'Multilayer Perceptron (Custom MLP)_Prob_TPC_CPFV',\n","       'SVM_Prob_CTDT_CPFV', 'SVM_ACC_PFV', 'SVM_GDC_PFV',\n","       'Logistic Regression_TPC_PFV', 'Random Forest_TPC_PFV', 'SVM_TPC_PFV',\n","       'Neural Network_PCP_PFV', 'AdaBoost_PCP_PFV', 'LightGBM_PCP_PFV',\n","       'Gradient Boosting_PCP_PFV', 'Naive Bayes_PCP_PFV', 'XGBoost_PAAC_PFV',\n","       'k-NN_PAAC_PFV', 'Logistic Regression_PAAC_PFV',\n","       'Decision Tree_PAAC_PFV', 'SVM_PAAC_PFV', 'Target'],\n","      dtype='object')\n","   SVM_PCP_CFV  Decision Tree_TPC_CFV  SVM_GDC_CFV  Neural Network_GDC_CFV  \\\n","0     0.995279               1.000000     1.000000                0.998631   \n","1     0.994851               1.000000     1.000000                0.998631   \n","2     0.268433               0.171516     0.252836                0.220107   \n","3     0.743032               1.000000     0.530314                0.986588   \n","4     0.353922               0.171516     0.322715                0.360953   \n","\n","   SVM_PAAC_CFV  Random Forest_PAAC_CFV  XGBoost_PAAC_CFV  LightGBM_PAAC_CFV  \\\n","0      0.909049                0.641420          0.971628           0.927626   \n","1      0.984933                0.902640          0.995887           0.995928   \n","2      0.612209                0.309144          0.066896           0.235922   \n","3      0.568016                0.674516          0.593925           0.694397   \n","4      0.334328                0.340675          0.053428           0.119806   \n","\n","   Neural Network_PAAC_CFV  MLP_PAAC_CFV  ...  AdaBoost_PCP_PFV  \\\n","0                 0.999875      1.000000  ...          0.633444   \n","1                 1.000000      1.000000  ...          0.608171   \n","2                 0.999945      0.117195  ...          0.442570   \n","3                 0.922696      0.505284  ...          0.507928   \n","4                 0.001131      0.984430  ...          0.490675   \n","\n","   LightGBM_PCP_PFV  Gradient Boosting_PCP_PFV  Naive Bayes_PCP_PFV  \\\n","0          0.996590               1.000000e+00             1.000000   \n","1          0.998059               1.000000e+00             1.000000   \n","2          0.010956               2.058050e-10             0.037961   \n","3          0.798022               9.860029e-01             0.247224   \n","4          0.214318               1.049644e-07             0.095711   \n","\n","   XGBoost_PAAC_PFV  k-NN_PAAC_PFV  Logistic Regression_PAAC_PFV  \\\n","0          0.975547       1.000000                      0.797661   \n","1          0.995537       1.000000                      0.996458   \n","2          0.202655       1.000000                      0.333608   \n","3          0.503619       0.333333                      0.564784   \n","4          0.084396       0.333333                      0.385868   \n","\n","   Decision Tree_PAAC_PFV  SVM_PAAC_PFV  Target  \n","0                0.816456      0.995284       1  \n","1                0.983607      1.000000       1  \n","2                0.034483      0.560280       1  \n","3                0.108696      0.582880       1  \n","4                0.034483      0.400538       1  \n","\n","[5 rows x 46 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m98,560\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m82,176\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m224,129\u001b[0m (875.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,129</span> (875.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,233\u001b[0m (872.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,233</span> (872.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 124ms/step - accuracy: 0.7756 - loss: 0.4972 - val_accuracy: 0.8889 - val_loss: 0.6517\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8987 - loss: 0.5374 - val_accuracy: 0.8333 - val_loss: 0.6514\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9011 - loss: 0.2552 - val_accuracy: 0.8111 - val_loss: 0.6474\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9262 - loss: 0.2188 - val_accuracy: 0.7889 - val_loss: 0.6427\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9351 - loss: 0.1633 - val_accuracy: 0.7778 - val_loss: 0.6397\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9323 - loss: 0.2195 - val_accuracy: 0.6556 - val_loss: 0.6464\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9557 - loss: 0.1564 - val_accuracy: 0.6222 - val_loss: 0.6456\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9210 - loss: 0.2475 - val_accuracy: 0.5222 - val_loss: 0.6465\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9464 - loss: 0.1599 - val_accuracy: 0.5222 - val_loss: 0.6349\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9229 - loss: 0.1646 - val_accuracy: 0.5000 - val_loss: 0.6404\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9291 - loss: 0.1720 - val_accuracy: 0.5000 - val_loss: 0.6439\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9352 - loss: 0.1403 - val_accuracy: 0.5000 - val_loss: 0.6320\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9400 - loss: 0.1127 - val_accuracy: 0.5000 - val_loss: 0.6336\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9162 - loss: 0.1525 - val_accuracy: 0.5000 - val_loss: 0.6050\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9232 - loss: 0.1881 - val_accuracy: 0.5000 - val_loss: 0.6111\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9624 - loss: 0.0984 - val_accuracy: 0.5000 - val_loss: 0.6050\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9533 - loss: 0.1121 - val_accuracy: 0.5000 - val_loss: 0.6055\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9496 - loss: 0.1031 - val_accuracy: 0.5000 - val_loss: 0.6096\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9786 - loss: 0.0798 - val_accuracy: 0.5000 - val_loss: 0.5573\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9739 - loss: 0.0751 - val_accuracy: 0.5000 - val_loss: 0.5800\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9441 - loss: 0.1344 - val_accuracy: 0.5000 - val_loss: 0.6810\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9523 - loss: 0.1229 - val_accuracy: 0.5000 - val_loss: 0.6029\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9408 - loss: 0.1174 - val_accuracy: 0.5000 - val_loss: 0.6272\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9537 - loss: 0.1233 - val_accuracy: 0.5000 - val_loss: 0.6883\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9614 - loss: 0.1170 - val_accuracy: 0.5000 - val_loss: 0.6208\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9585 - loss: 0.0774 - val_accuracy: 0.4889 - val_loss: 0.6102\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9546 - loss: 0.0863 - val_accuracy: 0.5000 - val_loss: 0.7505\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9688 - loss: 0.0635 - val_accuracy: 0.5000 - val_loss: 0.8162\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9880 - loss: 0.0422 - val_accuracy: 0.5000 - val_loss: 0.8625\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9554 - loss: 0.1137 - val_accuracy: 0.5000 - val_loss: 0.9875\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9539 - loss: 0.1102 - val_accuracy: 0.5000 - val_loss: 0.9122\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9730 - loss: 0.0693 - val_accuracy: 0.4889 - val_loss: 0.7280\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9787 - loss: 0.0602 - val_accuracy: 0.5444 - val_loss: 0.7484\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9913 - loss: 0.0391 - val_accuracy: 0.5000 - val_loss: 0.9646\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9913 - loss: 0.0313 - val_accuracy: 0.5778 - val_loss: 0.8979\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9970 - loss: 0.0180 - val_accuracy: 0.6111 - val_loss: 0.8591\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9794 - loss: 0.1003 - val_accuracy: 0.5000 - val_loss: 1.2243\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9685 - loss: 0.0808 - val_accuracy: 0.5778 - val_loss: 0.8994\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9840 - loss: 0.0505 - val_accuracy: 0.7000 - val_loss: 0.6771\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9752 - loss: 0.0727 - val_accuracy: 0.6111 - val_loss: 0.8745\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9749 - loss: 0.0614 - val_accuracy: 0.6000 - val_loss: 1.1615\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9887 - loss: 0.0239 - val_accuracy: 0.6000 - val_loss: 1.4207\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9931 - loss: 0.0276 - val_accuracy: 0.5889 - val_loss: 1.5264\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 0.6000 - val_loss: 1.4533\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9880 - loss: 0.0212 - val_accuracy: 0.6000 - val_loss: 1.4907\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9921 - loss: 0.0345 - val_accuracy: 0.5111 - val_loss: 2.1340\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9859 - loss: 0.0245 - val_accuracy: 0.5111 - val_loss: 2.0682\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9963 - loss: 0.0148 - val_accuracy: 0.5778 - val_loss: 1.5605\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9749 - loss: 0.0407 - val_accuracy: 0.6333 - val_loss: 1.5195\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9752 - loss: 0.0469 - val_accuracy: 0.7000 - val_loss: 1.2282\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9931 - loss: 0.0240 - val_accuracy: 0.7889 - val_loss: 1.3031\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9752 - loss: 0.0559 - val_accuracy: 0.8000 - val_loss: 1.0210\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9844 - loss: 0.0425 - val_accuracy: 0.8000 - val_loss: 1.2483\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9746 - loss: 0.0589 - val_accuracy: 0.8000 - val_loss: 1.4300\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8111 - val_loss: 1.1072\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9879 - loss: 0.0446 - val_accuracy: 0.8222 - val_loss: 1.0454\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0205 - val_accuracy: 0.7222 - val_loss: 1.3486\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9925 - loss: 0.0125 - val_accuracy: 0.7556 - val_loss: 1.1918\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9964 - loss: 0.0148 - val_accuracy: 0.8333 - val_loss: 1.0366\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9951 - loss: 0.0160 - val_accuracy: 0.8556 - val_loss: 1.0119\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9857 - loss: 0.0273 - val_accuracy: 0.8556 - val_loss: 1.0292\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9982 - loss: 0.0112 - val_accuracy: 0.8222 - val_loss: 1.0589\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8556 - val_loss: 1.1435\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9964 - loss: 0.0130 - val_accuracy: 0.8444 - val_loss: 1.1885\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9964 - loss: 0.0329 - val_accuracy: 0.8444 - val_loss: 1.2721\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9948 - loss: 0.0388 - val_accuracy: 0.8556 - val_loss: 1.0272\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9955 - loss: 0.0141 - val_accuracy: 0.8667 - val_loss: 0.8338\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9838 - loss: 0.0515 - val_accuracy: 0.8444 - val_loss: 0.9155\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9866 - loss: 0.0277 - val_accuracy: 0.8556 - val_loss: 0.8282\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8778 - val_loss: 0.7706\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9906 - loss: 0.0976 - val_accuracy: 0.8556 - val_loss: 0.7435\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9933 - loss: 0.0295 - val_accuracy: 0.8333 - val_loss: 0.6784\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9837 - loss: 0.0245 - val_accuracy: 0.8556 - val_loss: 0.6902\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9870 - loss: 0.0250 - val_accuracy: 0.8444 - val_loss: 0.7233\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9872 - loss: 0.0271 - val_accuracy: 0.8667 - val_loss: 0.7362\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8778 - val_loss: 0.7769\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0147 - val_accuracy: 0.9000 - val_loss: 0.8164\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9866 - loss: 0.0309 - val_accuracy: 0.8778 - val_loss: 0.8948\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.8667 - val_loss: 1.0050\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8556 - val_loss: 1.0395\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.8556 - val_loss: 1.0231\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9988 - loss: 0.0081 - val_accuracy: 0.8556 - val_loss: 1.0078\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.8667 - val_loss: 1.0312\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8778 - val_loss: 1.0399\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8889 - val_loss: 1.0555\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9895 - loss: 0.0164 - val_accuracy: 0.9000 - val_loss: 1.0046\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.8889 - val_loss: 1.0667\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8556 - val_loss: 1.3286\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8556 - val_loss: 1.4394\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8556 - val_loss: 1.4580\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8444 - val_loss: 1.5219\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8444 - val_loss: 1.5304\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8556 - val_loss: 1.6210\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9866 - loss: 0.0303 - val_accuracy: 0.8778 - val_loss: 1.3730\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9963 - loss: 0.0074 - val_accuracy: 0.8778 - val_loss: 1.2780\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.8778 - val_loss: 1.3678\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9982 - loss: 0.0213 - val_accuracy: 0.8778 - val_loss: 1.3502\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9931 - loss: 0.0539 - val_accuracy: 0.8778 - val_loss: 1.2268\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8889 - val_loss: 1.1652\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9988 - loss: 0.0071 - val_accuracy: 0.8778 - val_loss: 1.1572\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n","\n","Validation Accuracy: 0.8777777777777778\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.89      0.88        45\n","           1       0.89      0.87      0.88        45\n","\n","    accuracy                           0.88        90\n","   macro avg       0.88      0.88      0.88        90\n","weighted avg       0.88      0.88      0.88        90\n","\n"]}]},{"cell_type":"markdown","source":["Deep learning approach combining Conv1D, LSTM, and Dense layers"],"metadata":{"id":"y-u2EAtY_MC0"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load the combined AAC dataset\n","dataset_path = \"/content/three_T_Marge.csv\"\n","data = pd.read_csv(dataset_path)\n","\n","# Ensure the dataset contains the 'Target' column\n","if 'Target' not in data.columns:\n","    raise ValueError(\"The dataset must include a 'Target' column for binary classification.\")\n","\n","# Separate features and labels\n","X = data.drop(columns=['Target']).values  # Features (all columns except 'Target')\n","y = data['Target'].values                 # Labels (the 'Target' column)\n","\n","# Split data into training and validation sets (80-20 split)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Normalize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Reshape input for Conv1D\n","X_train = X_train[..., np.newaxis]  # Adding channel dimension for Conv1D input\n","X_val = X_val[..., np.newaxis]      # Adding channel dimension for Conv1D input\n","\n","# Model Architecture\n","model = Sequential()\n","\n","# Stacked Conv1D layers with BatchNormalization and Dropout\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1), padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","# Removed problematic pooling layer here to avoid negative dimension issue\n","model.add(Dropout(0.3))\n","\n","# LSTM layer for sequential dependencies\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","\n","# Dense Layers for final prediction with Dropout for regularization\n","model.add(Dense(128, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='swish'))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))   # Output layer for binary classification\n","\n","# Compile the Model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Model Summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, verbose=1)\n","\n","# Evaluate the model\n","val_predictions = (model.predict(X_val) > 0.5).astype(int)\n","accuracy = accuracy_score(y_val, val_predictions)\n","\n","print(\"\\nValidation Accuracy:\", accuracy)\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, val_predictions))\n","\n","# Save the trained model\n","model.save(\"mmCombinedDataset_AAC_model.h5\")\n","print(\"Model saved as 'mmCombinedDataset_AAC_model.h5'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-LxirVoj_Mfp","outputId":"f3952bee-0b67-472c-cda6-1b43b628b5cd","executionInfo":{"status":"ok","timestamp":1737093035745,"user_tz":-360,"elapsed":62315,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m41,088\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m98,560\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m82,176\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,513\u001b[0m (939.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,513</span> (939.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m239,617\u001b[0m (936.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239,617</span> (936.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 128ms/step - accuracy: 0.7081 - loss: 0.5305 - val_accuracy: 0.8556 - val_loss: 0.6583\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8933 - loss: 0.3455 - val_accuracy: 0.7778 - val_loss: 0.6563\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9156 - loss: 0.2331 - val_accuracy: 0.7444 - val_loss: 0.6541\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9031 - loss: 0.2202 - val_accuracy: 0.7889 - val_loss: 0.6389\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9051 - loss: 0.2379 - val_accuracy: 0.6111 - val_loss: 0.6227\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9147 - loss: 0.2378 - val_accuracy: 0.6000 - val_loss: 0.6248\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9424 - loss: 0.1676 - val_accuracy: 0.5778 - val_loss: 0.6102\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9356 - loss: 0.1762 - val_accuracy: 0.5000 - val_loss: 0.6236\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9243 - loss: 0.1806 - val_accuracy: 0.5222 - val_loss: 0.5945\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9313 - loss: 0.1562 - val_accuracy: 0.6444 - val_loss: 0.5436\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9363 - loss: 0.1276 - val_accuracy: 0.6667 - val_loss: 0.5238\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9299 - loss: 0.1364 - val_accuracy: 0.5000 - val_loss: 0.6287\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9425 - loss: 0.1436 - val_accuracy: 0.5000 - val_loss: 0.7535\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9549 - loss: 0.1325 - val_accuracy: 0.5000 - val_loss: 0.7674\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9523 - loss: 0.1352 - val_accuracy: 0.5000 - val_loss: 0.7399\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9661 - loss: 0.1167 - val_accuracy: 0.5000 - val_loss: 0.7090\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9586 - loss: 0.1153 - val_accuracy: 0.5000 - val_loss: 0.7733\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9611 - loss: 0.1060 - val_accuracy: 0.5000 - val_loss: 0.9036\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9719 - loss: 0.1352 - val_accuracy: 0.6000 - val_loss: 0.6810\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9648 - loss: 0.1035 - val_accuracy: 0.6222 - val_loss: 0.7201\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9613 - loss: 0.0892 - val_accuracy: 0.6000 - val_loss: 0.9571\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9596 - loss: 0.0802 - val_accuracy: 0.5000 - val_loss: 1.3673\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9822 - loss: 0.0507 - val_accuracy: 0.5000 - val_loss: 1.4774\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9570 - loss: 0.0851 - val_accuracy: 0.5000 - val_loss: 1.6207\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9674 - loss: 0.1378 - val_accuracy: 0.5000 - val_loss: 1.8880\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9725 - loss: 0.0571 - val_accuracy: 0.5000 - val_loss: 2.2305\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9883 - loss: 0.0343 - val_accuracy: 0.5000 - val_loss: 2.5454\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9690 - loss: 0.0765 - val_accuracy: 0.5000 - val_loss: 1.7223\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9894 - loss: 0.0576 - val_accuracy: 0.5000 - val_loss: 2.2147\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9779 - loss: 0.0590 - val_accuracy: 0.5222 - val_loss: 1.2888\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9844 - loss: 0.0440 - val_accuracy: 0.6667 - val_loss: 1.1177\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9618 - loss: 0.1292 - val_accuracy: 0.5222 - val_loss: 1.3709\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9788 - loss: 0.0666 - val_accuracy: 0.8111 - val_loss: 0.6617\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9698 - loss: 0.0848 - val_accuracy: 0.8333 - val_loss: 0.6781\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9780 - loss: 0.0426 - val_accuracy: 0.7889 - val_loss: 0.8475\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9836 - loss: 0.0660 - val_accuracy: 0.8000 - val_loss: 0.6748\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9725 - loss: 0.0704 - val_accuracy: 0.8333 - val_loss: 0.7720\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9667 - loss: 0.0502 - val_accuracy: 0.8222 - val_loss: 0.7263\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9931 - loss: 0.0239 - val_accuracy: 0.7889 - val_loss: 0.9575\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9739 - loss: 0.0626 - val_accuracy: 0.7889 - val_loss: 1.2212\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9824 - loss: 0.0348 - val_accuracy: 0.7889 - val_loss: 1.2981\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.8556 - val_loss: 0.8609\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9913 - loss: 0.0173 - val_accuracy: 0.8556 - val_loss: 0.9236\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0121 - val_accuracy: 0.8667 - val_loss: 1.1183\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9869 - loss: 0.0344 - val_accuracy: 0.8556 - val_loss: 0.9752\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.8556 - val_loss: 0.7835\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9927 - loss: 0.0580 - val_accuracy: 0.8556 - val_loss: 0.9602\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9921 - loss: 0.0376 - val_accuracy: 0.8000 - val_loss: 1.4545\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9818 - loss: 0.0694 - val_accuracy: 0.8667 - val_loss: 1.1260\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9814 - loss: 0.0475 - val_accuracy: 0.8778 - val_loss: 0.7366\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9717 - loss: 0.0477 - val_accuracy: 0.8889 - val_loss: 0.5525\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9892 - loss: 0.0535 - val_accuracy: 0.8556 - val_loss: 0.8644\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9840 - loss: 0.0403 - val_accuracy: 0.9000 - val_loss: 0.8475\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.8598\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9892 - loss: 0.0270 - val_accuracy: 0.8778 - val_loss: 0.9219\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9988 - loss: 0.0141 - val_accuracy: 0.8778 - val_loss: 1.0120\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9921 - loss: 0.0147 - val_accuracy: 0.8889 - val_loss: 0.8096\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9910 - loss: 0.0216 - val_accuracy: 0.8778 - val_loss: 0.8295\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9963 - loss: 0.0216 - val_accuracy: 0.8778 - val_loss: 1.0234\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8667 - val_loss: 1.1007\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8667 - val_loss: 1.1622\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9931 - loss: 0.0106 - val_accuracy: 0.8556 - val_loss: 1.2705\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9964 - loss: 0.0114 - val_accuracy: 0.8778 - val_loss: 1.2812\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9892 - loss: 0.0287 - val_accuracy: 0.8778 - val_loss: 1.2181\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9824 - loss: 0.0343 - val_accuracy: 0.8778 - val_loss: 1.1815\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9893 - loss: 0.0361 - val_accuracy: 0.8556 - val_loss: 1.3042\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9880 - loss: 0.0224 - val_accuracy: 0.7000 - val_loss: 2.0735\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9794 - loss: 0.1000 - val_accuracy: 0.8889 - val_loss: 1.2221\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9776 - loss: 0.0674 - val_accuracy: 0.8667 - val_loss: 0.8940\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9925 - loss: 0.0263 - val_accuracy: 0.8778 - val_loss: 0.7893\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9902 - loss: 0.0251 - val_accuracy: 0.8889 - val_loss: 0.6929\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9828 - loss: 0.0336 - val_accuracy: 0.9000 - val_loss: 0.6546\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9838 - loss: 0.1137 - val_accuracy: 0.8444 - val_loss: 0.7933\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9844 - loss: 0.0874 - val_accuracy: 0.8333 - val_loss: 0.5777\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9866 - loss: 0.0425 - val_accuracy: 0.8667 - val_loss: 0.5347\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9854 - loss: 0.0424 - val_accuracy: 0.8667 - val_loss: 0.5466\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9838 - loss: 0.0559 - val_accuracy: 0.8778 - val_loss: 0.5568\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9895 - loss: 0.0188 - val_accuracy: 0.8889 - val_loss: 0.5706\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8889 - val_loss: 0.5981\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.8889 - val_loss: 0.6379\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9964 - loss: 0.0071 - val_accuracy: 0.8778 - val_loss: 0.7160\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.8778 - val_loss: 0.8100\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9974 - loss: 0.0165 - val_accuracy: 0.8778 - val_loss: 0.8197\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.8778 - val_loss: 0.8027\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8667 - val_loss: 0.8415\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9874 - loss: 0.0218 - val_accuracy: 0.8444 - val_loss: 0.7873\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8778 - val_loss: 0.7794\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8889 - val_loss: 0.7752\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.7760\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9785 - loss: 0.0317 - val_accuracy: 0.9111 - val_loss: 0.7515\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9000 - val_loss: 0.7588\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9892 - loss: 0.0207 - val_accuracy: 0.8667 - val_loss: 0.8465\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9931 - loss: 0.0282 - val_accuracy: 0.8778 - val_loss: 0.8416\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9111 - val_loss: 1.0530\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.9111 - val_loss: 1.0158\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 7.9093e-04 - val_accuracy: 0.9111 - val_loss: 0.8796\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9974 - loss: 0.0118 - val_accuracy: 0.8889 - val_loss: 0.8680\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9931 - loss: 0.0101 - val_accuracy: 0.9111 - val_loss: 0.8912\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 9.1680e-04 - val_accuracy: 0.9111 - val_loss: 0.9188\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9964 - loss: 0.0095 - val_accuracy: 0.9111 - val_loss: 1.0154\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\n","Validation Accuracy: 0.9111111111111111\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.89      0.93      0.91        45\n","           1       0.93      0.89      0.91        45\n","\n","    accuracy                           0.91        90\n","   macro avg       0.91      0.91      0.91        90\n","weighted avg       0.91      0.91      0.91        90\n","\n","Model saved as 'mmCombinedDataset_AAC_model.h5'.\n"]}]},{"cell_type":"markdown","source":["PeptidePredictor_CNN"],"metadata":{"id":"ZKBkZT5M_OyI"}},{"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, Conv1D, BatchNormalization, Dropout, GlobalMaxPooling1D, Dense\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from sklearn.impute import SimpleImputer\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","from sklearn.metrics import classification_report\n","from keras import regularizers\n","\n","# Load Dataset\n","file_path = '/content/three_T_Marge.csv'\n","data = pd.read_csv(file_path)\n","\n","# Separate Features and Labels\n","X = data.iloc[:, :-1].values  # Features\n","y = data.iloc[:, -1].values   # Labels\n","\n","# Handle missing values (imputation)\n","imputer = SimpleImputer(strategy='mean')  # You can also use median or most_frequent\n","X = imputer.fit_transform(X)\n","\n","# Normalize Features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# SMOTE for oversampling the minority class\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X, y = smote.fit_resample(X, y)\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Build Model (same as the one discussed previously)\n","def build_model(input_dim):\n","    inputs = Input(shape=(input_dim, 1))  # 1D CNN expects a 3D input shape (samples, features, 1)\n","\n","    # Conv1D Layer\n","    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(inputs)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","\n","    # Another Conv1D Layer\n","    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","\n","    # Max Pooling\n","    x = GlobalMaxPooling1D()(x)\n","\n","    # Dense Layer\n","    x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n","    x = Dropout(0.4)(x)\n","\n","    # Output Layer\n","    outputs = Dense(1, activation='sigmoid')(x)  # For binary classification\n","\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Reshaping input for Conv1D (samples, features, 1)\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","\n","# Get Input Dimension\n","input_dim = X_train.shape[1]\n","\n","# Initialize Model\n","model = build_model(input_dim)\n","\n","# Early Stopping (optional, but can be added for faster convergence)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Train the Model\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stopping],\n","    verbose=1\n",")\n","\n","# Evaluate the Model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","# Evaluate the Model using Classification Report\n","y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n","print(classification_report(y_test, y_pred))\n","\n","# Save the Model\n","model.save('/content/improved_probability_based_model.h5')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7IWtF6Z_SDv","outputId":"93b4caf0-4ec6-46a7-f112-00b42b1e1292","executionInfo":{"status":"ok","timestamp":1737093082587,"user_tz":-360,"elapsed":34092,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.5467 - loss: 2.9845 - val_accuracy: 0.8778 - val_loss: 1.8366\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8758 - loss: 1.8068 - val_accuracy: 0.9000 - val_loss: 1.7769\n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9245 - loss: 1.6025 - val_accuracy: 0.9000 - val_loss: 1.7315\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9028 - loss: 1.5903 - val_accuracy: 0.9000 - val_loss: 1.6963\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8548 - loss: 1.5002 - val_accuracy: 0.9000 - val_loss: 1.6675\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8876 - loss: 1.4302 - val_accuracy: 0.9000 - val_loss: 1.6358\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8977 - loss: 1.4255 - val_accuracy: 0.9000 - val_loss: 1.6060\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8691 - loss: 1.3304 - val_accuracy: 0.9000 - val_loss: 1.5739\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8939 - loss: 1.2710 - val_accuracy: 0.9000 - val_loss: 1.5420\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8968 - loss: 1.2787 - val_accuracy: 0.9000 - val_loss: 1.5114\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8977 - loss: 1.1846 - val_accuracy: 0.9000 - val_loss: 1.4837\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9221 - loss: 1.1543 - val_accuracy: 0.8889 - val_loss: 1.4556\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9029 - loss: 1.1763 - val_accuracy: 0.8889 - val_loss: 1.4269\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8600 - loss: 1.2770 - val_accuracy: 0.8889 - val_loss: 1.4006\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8858 - loss: 1.1256 - val_accuracy: 0.8889 - val_loss: 1.3743\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8976 - loss: 1.0855 - val_accuracy: 0.9000 - val_loss: 1.3544\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9015 - loss: 1.0303 - val_accuracy: 0.9000 - val_loss: 1.3341\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8887 - loss: 1.0681 - val_accuracy: 0.9000 - val_loss: 1.3118\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9176 - loss: 1.0088 - val_accuracy: 0.9000 - val_loss: 1.2892\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9145 - loss: 1.0194 - val_accuracy: 0.8889 - val_loss: 1.2677\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9221 - loss: 0.9993 - val_accuracy: 0.9000 - val_loss: 1.2470\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9135 - loss: 0.9502 - val_accuracy: 0.9000 - val_loss: 1.2288\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9333 - loss: 0.9505 - val_accuracy: 0.9000 - val_loss: 1.2071\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9052 - loss: 0.9440 - val_accuracy: 0.9000 - val_loss: 1.1875\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9035 - loss: 0.9304 - val_accuracy: 0.9111 - val_loss: 1.1690\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9193 - loss: 0.9147 - val_accuracy: 0.9111 - val_loss: 1.1522\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9202 - loss: 0.8737 - val_accuracy: 0.9111 - val_loss: 1.1302\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9198 - loss: 0.8846 - val_accuracy: 0.9000 - val_loss: 1.1069\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8696 - loss: 0.9109 - val_accuracy: 0.9111 - val_loss: 1.0868\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9307 - loss: 0.8127 - val_accuracy: 0.9111 - val_loss: 1.0650\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9110 - loss: 0.8595 - val_accuracy: 0.9111 - val_loss: 1.0438\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9674 - loss: 0.7526 - val_accuracy: 0.9111 - val_loss: 1.0240\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9221 - loss: 0.8030 - val_accuracy: 0.9111 - val_loss: 1.0077\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9155 - loss: 0.7906 - val_accuracy: 0.9000 - val_loss: 0.9954\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9502 - loss: 0.7665 - val_accuracy: 0.9000 - val_loss: 0.9772\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9536 - loss: 0.7320 - val_accuracy: 0.9000 - val_loss: 0.9624\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9178 - loss: 0.7627 - val_accuracy: 0.9111 - val_loss: 0.9470\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9539 - loss: 0.7135 - val_accuracy: 0.9000 - val_loss: 0.9261\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9073 - loss: 0.8081 - val_accuracy: 0.9000 - val_loss: 0.9217\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9247 - loss: 0.7374 - val_accuracy: 0.9000 - val_loss: 0.9067\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9298 - loss: 0.7156 - val_accuracy: 0.9000 - val_loss: 0.8957\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9181 - loss: 0.6957 - val_accuracy: 0.9000 - val_loss: 0.8853\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9465 - loss: 0.6704 - val_accuracy: 0.9000 - val_loss: 0.8693\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9503 - loss: 0.6642 - val_accuracy: 0.8889 - val_loss: 0.8548\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9398 - loss: 0.6252 - val_accuracy: 0.9000 - val_loss: 0.8398\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9125 - loss: 0.6861 - val_accuracy: 0.9000 - val_loss: 0.8338\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9435 - loss: 0.6471 - val_accuracy: 0.8778 - val_loss: 0.8227\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9300 - loss: 0.6420 - val_accuracy: 0.9000 - val_loss: 0.8143\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9476 - loss: 0.6477 - val_accuracy: 0.9000 - val_loss: 0.7957\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9237 - loss: 0.6235 - val_accuracy: 0.9000 - val_loss: 0.7833\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9117 - loss: 0.6420 - val_accuracy: 0.9000 - val_loss: 0.7720\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9304 - loss: 0.6198 - val_accuracy: 0.9000 - val_loss: 0.7613\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9425 - loss: 0.5660 - val_accuracy: 0.9000 - val_loss: 0.7470\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9271 - loss: 0.5722 - val_accuracy: 0.9000 - val_loss: 0.7339\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9143 - loss: 0.5832 - val_accuracy: 0.8889 - val_loss: 0.7317\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9260 - loss: 0.5948 - val_accuracy: 0.9000 - val_loss: 0.7195\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9296 - loss: 0.5842 - val_accuracy: 0.9000 - val_loss: 0.7032\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9444 - loss: 0.5762 - val_accuracy: 0.9000 - val_loss: 0.6970\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9358 - loss: 0.5294 - val_accuracy: 0.8778 - val_loss: 0.6850\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9195 - loss: 0.5570 - val_accuracy: 0.8889 - val_loss: 0.6762\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9393 - loss: 0.5425 - val_accuracy: 0.8889 - val_loss: 0.6634\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9622 - loss: 0.4905 - val_accuracy: 0.8889 - val_loss: 0.6498\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9707 - loss: 0.4471 - val_accuracy: 0.9000 - val_loss: 0.6434\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9396 - loss: 0.5219 - val_accuracy: 0.8889 - val_loss: 0.6471\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9411 - loss: 0.5336 - val_accuracy: 0.8889 - val_loss: 0.6363\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9378 - loss: 0.5198 - val_accuracy: 0.9000 - val_loss: 0.6242\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9636 - loss: 0.4477 - val_accuracy: 0.9000 - val_loss: 0.6052\n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9415 - loss: 0.4607 - val_accuracy: 0.8889 - val_loss: 0.5992\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9178 - loss: 0.5079 - val_accuracy: 0.8889 - val_loss: 0.6015\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9011 - loss: 0.5313 - val_accuracy: 0.9000 - val_loss: 0.5942\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9448 - loss: 0.4740 - val_accuracy: 0.9000 - val_loss: 0.5888\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9481 - loss: 0.4735 - val_accuracy: 0.8889 - val_loss: 0.5848\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9411 - loss: 0.4352 - val_accuracy: 0.8889 - val_loss: 0.5703\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9577 - loss: 0.4221 - val_accuracy: 0.8889 - val_loss: 0.5610\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9278 - loss: 0.4508 - val_accuracy: 0.8889 - val_loss: 0.5618\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9310 - loss: 0.4301 - val_accuracy: 0.8889 - val_loss: 0.5543\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9224 - loss: 0.4322 - val_accuracy: 0.8889 - val_loss: 0.5509\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9599 - loss: 0.3909 - val_accuracy: 0.8889 - val_loss: 0.5414\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9534 - loss: 0.3969 - val_accuracy: 0.8889 - val_loss: 0.5348\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9355 - loss: 0.4244 - val_accuracy: 0.8889 - val_loss: 0.5388\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9656 - loss: 0.3621 - val_accuracy: 0.8889 - val_loss: 0.5259\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9585 - loss: 0.4080 - val_accuracy: 0.8889 - val_loss: 0.5208\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9381 - loss: 0.4540 - val_accuracy: 0.8889 - val_loss: 0.5158\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9560 - loss: 0.3681 - val_accuracy: 0.8889 - val_loss: 0.5123\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9398 - loss: 0.4189 - val_accuracy: 0.8889 - val_loss: 0.5088\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9311 - loss: 0.4176 - val_accuracy: 0.8889 - val_loss: 0.5013\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9373 - loss: 0.3938 - val_accuracy: 0.8889 - val_loss: 0.4983\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9664 - loss: 0.3667 - val_accuracy: 0.8889 - val_loss: 0.4922\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9376 - loss: 0.3781 - val_accuracy: 0.8889 - val_loss: 0.4928\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9293 - loss: 0.4567 - val_accuracy: 0.8889 - val_loss: 0.4894\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9728 - loss: 0.3478 - val_accuracy: 0.8889 - val_loss: 0.4844\n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9521 - loss: 0.4059 - val_accuracy: 0.8889 - val_loss: 0.4808\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9445 - loss: 0.3647 - val_accuracy: 0.8889 - val_loss: 0.4745\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9390 - loss: 0.3913 - val_accuracy: 0.8889 - val_loss: 0.4753\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9344 - loss: 0.4148 - val_accuracy: 0.8889 - val_loss: 0.4699\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9499 - loss: 0.3472 - val_accuracy: 0.8778 - val_loss: 0.4713\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9734 - loss: 0.2863 - val_accuracy: 0.8889 - val_loss: 0.4686\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9648 - loss: 0.3239 - val_accuracy: 0.8778 - val_loss: 0.4677\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9366 - loss: 0.3378 - val_accuracy: 0.8889 - val_loss: 0.4607\n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9573 - loss: 0.3416 - val_accuracy: 0.8778 - val_loss: 0.4620\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f26dd8e0c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.8889\n","\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f26dd8e0c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.88      0.88        42\n","           1       0.90      0.90      0.90        48\n","\n","    accuracy                           0.89        90\n","   macro avg       0.89      0.89      0.89        90\n","weighted avg       0.89      0.89      0.89        90\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CKF-poK509jU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, Conv1D, BatchNormalization, Dropout, GlobalMaxPooling1D, Dense, LeakyReLU\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.impute import SimpleImputer\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","from keras import regularizers\n","import pandas as pd\n","\n","# Load Dataset\n","file_path = '/content/three_T_Marge.csv'\n","data = pd.read_csv(file_path)\n","\n","# Separate Features and Labels\n","X = data.iloc[:, :-1].values  # Features\n","y = data.iloc[:, -1].values   # Labels\n","\n","# Handle missing values (imputation)\n","imputer = SimpleImputer(strategy='mean')\n","X = imputer.fit_transform(X)\n","\n","# Normalize Features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# SMOTE for oversampling the minority class\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X, y = smote.fit_resample(X, y)\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Build Model\n","def build_model(input_dim):\n","    inputs = Input(shape=(input_dim, 1))\n","\n","    # First Conv1D Layer\n","    x = Conv1D(128, kernel_size=3, padding='same')(inputs)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","\n","    # Second Conv1D Layer\n","    x = Conv1D(256, kernel_size=5, padding='same')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","\n","    # Third Conv1D Layer\n","    x = Conv1D(512, kernel_size=3, padding='same')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","\n","    # Global Max Pooling\n","    x = GlobalMaxPooling1D()(x)\n","\n","    # Fully Connected Layers\n","    x = Dense(256, kernel_regularizer=regularizers.l2(0.01))(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = Dropout(0.5)(x)\n","\n","    x = Dense(128, kernel_regularizer=regularizers.l2(0.01))(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = Dropout(0.5)(x)\n","\n","    x = Dense(64, kernel_regularizer=regularizers.l2(0.01))(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = Dropout(0.5)(x)\n","\n","    # Output Layer\n","    outputs = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Reshaping input for Conv1D\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","\n","# Initialize Model\n","input_dim = X_train.shape[1]\n","model = build_model(input_dim)\n","\n","# Early Stopping and Learning Rate Scheduler\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","\n","# Train the Model\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=150,\n","    batch_size=32,\n","    callbacks=[early_stopping, reduce_lr],\n","    verbose=1\n",")\n","\n","# Evaluate the Model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","# Classification Report\n","y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n","print(classification_report(y_test, y_pred))\n","\n","# Save the Model\n","model.save('/content/high_accuracy_model.h5')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOE6JDmQ092j","executionInfo":{"status":"ok","timestamp":1737094532264,"user_tz":-360,"elapsed":325805,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"011d47ef-a237-4ab0-824e-027211315262"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - accuracy: 0.5848 - loss: 8.2814 - val_accuracy: 0.8667 - val_loss: 6.5102 - learning_rate: 0.0010\n","Epoch 2/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.7976 - loss: 6.8492 - val_accuracy: 0.8667 - val_loss: 6.3487 - learning_rate: 0.0010\n","Epoch 3/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.8091 - loss: 6.8224 - val_accuracy: 0.8667 - val_loss: 6.2096 - learning_rate: 0.0010\n","Epoch 4/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 320ms/step - accuracy: 0.8555 - loss: 6.4537 - val_accuracy: 0.8889 - val_loss: 6.0873 - learning_rate: 0.0010\n","Epoch 5/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - accuracy: 0.8454 - loss: 6.1727 - val_accuracy: 0.8889 - val_loss: 5.9675 - learning_rate: 0.0010\n","Epoch 6/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.8603 - loss: 6.0011 - val_accuracy: 0.8889 - val_loss: 5.8428 - learning_rate: 0.0010\n","Epoch 7/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.8470 - loss: 6.1163 - val_accuracy: 0.8889 - val_loss: 5.7240 - learning_rate: 0.0010\n","Epoch 8/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - accuracy: 0.8715 - loss: 5.8198 - val_accuracy: 0.9000 - val_loss: 5.5967 - learning_rate: 0.0010\n","Epoch 9/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - accuracy: 0.8678 - loss: 5.6045 - val_accuracy: 0.9000 - val_loss: 5.4776 - learning_rate: 0.0010\n","Epoch 10/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 311ms/step - accuracy: 0.8842 - loss: 5.4389 - val_accuracy: 0.8889 - val_loss: 5.3587 - learning_rate: 0.0010\n","Epoch 11/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 317ms/step - accuracy: 0.8927 - loss: 5.2700 - val_accuracy: 0.8889 - val_loss: 5.2416 - learning_rate: 0.0010\n","Epoch 12/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.8553 - loss: 5.3497 - val_accuracy: 0.8889 - val_loss: 5.1319 - learning_rate: 0.0010\n","Epoch 13/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - accuracy: 0.8849 - loss: 4.9890 - val_accuracy: 0.8889 - val_loss: 5.0177 - learning_rate: 0.0010\n","Epoch 14/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.8784 - loss: 4.9974 - val_accuracy: 0.8889 - val_loss: 4.9045 - learning_rate: 0.0010\n","Epoch 15/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 0.8977 - loss: 4.8857 - val_accuracy: 0.8889 - val_loss: 4.7978 - learning_rate: 0.0010\n","Epoch 16/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 288ms/step - accuracy: 0.8932 - loss: 4.6453 - val_accuracy: 0.8889 - val_loss: 4.6926 - learning_rate: 0.0010\n","Epoch 17/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 327ms/step - accuracy: 0.8814 - loss: 4.6158 - val_accuracy: 0.8889 - val_loss: 4.5887 - learning_rate: 0.0010\n","Epoch 18/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 284ms/step - accuracy: 0.9174 - loss: 4.5069 - val_accuracy: 0.8889 - val_loss: 4.4859 - learning_rate: 0.0010\n","Epoch 19/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.8878 - loss: 4.3980 - val_accuracy: 0.8889 - val_loss: 4.3877 - learning_rate: 0.0010\n","Epoch 20/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 0.8329 - loss: 4.3612 - val_accuracy: 0.8889 - val_loss: 4.2964 - learning_rate: 0.0010\n","Epoch 21/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.9126 - loss: 4.2271 - val_accuracy: 0.8889 - val_loss: 4.2064 - learning_rate: 0.0010\n","Epoch 22/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 191ms/step - accuracy: 0.9032 - loss: 4.0858 - val_accuracy: 0.8889 - val_loss: 4.1202 - learning_rate: 0.0010\n","Epoch 23/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - accuracy: 0.8986 - loss: 3.9658 - val_accuracy: 0.8889 - val_loss: 4.0314 - learning_rate: 0.0010\n","Epoch 24/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step - accuracy: 0.8950 - loss: 3.8680 - val_accuracy: 0.8889 - val_loss: 3.9353 - learning_rate: 0.0010\n","Epoch 25/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.8706 - loss: 3.8752 - val_accuracy: 0.8889 - val_loss: 3.8497 - learning_rate: 0.0010\n","Epoch 26/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.9065 - loss: 3.7139 - val_accuracy: 0.8889 - val_loss: 3.7666 - learning_rate: 0.0010\n","Epoch 27/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 191ms/step - accuracy: 0.9015 - loss: 3.6190 - val_accuracy: 0.8889 - val_loss: 3.6871 - learning_rate: 0.0010\n","Epoch 28/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 188ms/step - accuracy: 0.8799 - loss: 3.5837 - val_accuracy: 0.8889 - val_loss: 3.6031 - learning_rate: 0.0010\n","Epoch 29/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.8896 - loss: 3.5234 - val_accuracy: 0.8889 - val_loss: 3.5239 - learning_rate: 0.0010\n","Epoch 30/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 318ms/step - accuracy: 0.8962 - loss: 3.4780 - val_accuracy: 0.8889 - val_loss: 3.4464 - learning_rate: 0.0010\n","Epoch 31/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.9306 - loss: 3.2603 - val_accuracy: 0.9000 - val_loss: 3.3738 - learning_rate: 0.0010\n","Epoch 32/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - accuracy: 0.9249 - loss: 3.1523 - val_accuracy: 0.9000 - val_loss: 3.3006 - learning_rate: 0.0010\n","Epoch 33/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 195ms/step - accuracy: 0.9219 - loss: 3.1017 - val_accuracy: 0.9111 - val_loss: 3.2282 - learning_rate: 0.0010\n","Epoch 34/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8825 - loss: 3.1540 - val_accuracy: 0.9111 - val_loss: 3.1676 - learning_rate: 0.0010\n","Epoch 35/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 183ms/step - accuracy: 0.9030 - loss: 2.9947 - val_accuracy: 0.8889 - val_loss: 3.1073 - learning_rate: 0.0010\n","Epoch 36/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 267ms/step - accuracy: 0.8992 - loss: 2.9803 - val_accuracy: 0.8889 - val_loss: 3.0405 - learning_rate: 0.0010\n","Epoch 37/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.9220 - loss: 2.8320 - val_accuracy: 0.9000 - val_loss: 2.9721 - learning_rate: 0.0010\n","Epoch 38/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - accuracy: 0.8849 - loss: 2.8052 - val_accuracy: 0.9000 - val_loss: 2.9053 - learning_rate: 0.0010\n","Epoch 39/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9034 - loss: 2.7404 - val_accuracy: 0.9000 - val_loss: 2.8447 - learning_rate: 0.0010\n","Epoch 40/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - accuracy: 0.9092 - loss: 2.7223 - val_accuracy: 0.9000 - val_loss: 2.7875 - learning_rate: 0.0010\n","Epoch 41/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.8977 - loss: 2.7055 - val_accuracy: 0.9000 - val_loss: 2.7327 - learning_rate: 0.0010\n","Epoch 42/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.9066 - loss: 2.5531 - val_accuracy: 0.9111 - val_loss: 2.6802 - learning_rate: 0.0010\n","Epoch 43/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 324ms/step - accuracy: 0.8819 - loss: 2.4820 - val_accuracy: 0.9000 - val_loss: 2.6228 - learning_rate: 0.0010\n","Epoch 44/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 320ms/step - accuracy: 0.9448 - loss: 2.3886 - val_accuracy: 0.8889 - val_loss: 2.5647 - learning_rate: 0.0010\n","Epoch 45/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.9120 - loss: 2.4076 - val_accuracy: 0.9000 - val_loss: 2.5127 - learning_rate: 0.0010\n","Epoch 46/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.8676 - loss: 2.3842 - val_accuracy: 0.8889 - val_loss: 2.4607 - learning_rate: 0.0010\n","Epoch 47/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 0.9226 - loss: 2.3017 - val_accuracy: 0.9000 - val_loss: 2.4008 - learning_rate: 0.0010\n","Epoch 48/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - accuracy: 0.9054 - loss: 2.2181 - val_accuracy: 0.9000 - val_loss: 2.3524 - learning_rate: 0.0010\n","Epoch 49/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.9063 - loss: 2.1578 - val_accuracy: 0.9000 - val_loss: 2.2891 - learning_rate: 0.0010\n","Epoch 50/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - accuracy: 0.9240 - loss: 2.0940 - val_accuracy: 0.9000 - val_loss: 2.2409 - learning_rate: 0.0010\n","Epoch 51/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338ms/step - accuracy: 0.9049 - loss: 2.0929 - val_accuracy: 0.9000 - val_loss: 2.2009 - learning_rate: 0.0010\n","Epoch 52/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - accuracy: 0.9026 - loss: 2.0396 - val_accuracy: 0.9000 - val_loss: 2.1567 - learning_rate: 0.0010\n","Epoch 53/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - accuracy: 0.9177 - loss: 1.9941 - val_accuracy: 0.9000 - val_loss: 2.1067 - learning_rate: 0.0010\n","Epoch 54/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8904 - loss: 1.9399 - val_accuracy: 0.9000 - val_loss: 2.0559 - learning_rate: 0.0010\n","Epoch 55/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 187ms/step - accuracy: 0.9044 - loss: 1.9101 - val_accuracy: 0.9000 - val_loss: 2.0198 - learning_rate: 0.0010\n","Epoch 56/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 191ms/step - accuracy: 0.9231 - loss: 1.8622 - val_accuracy: 0.9000 - val_loss: 1.9683 - learning_rate: 0.0010\n","Epoch 57/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.9134 - loss: 1.8647 - val_accuracy: 0.9000 - val_loss: 1.9275 - learning_rate: 0.0010\n","Epoch 58/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 323ms/step - accuracy: 0.9170 - loss: 1.7883 - val_accuracy: 0.9000 - val_loss: 1.8881 - learning_rate: 0.0010\n","Epoch 59/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.9255 - loss: 1.7526 - val_accuracy: 0.9000 - val_loss: 1.8569 - learning_rate: 0.0010\n","Epoch 60/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.8952 - loss: 1.7714 - val_accuracy: 0.9000 - val_loss: 1.8382 - learning_rate: 0.0010\n","Epoch 61/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9183 - loss: 1.6699 - val_accuracy: 0.9000 - val_loss: 1.7836 - learning_rate: 0.0010\n","Epoch 62/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - accuracy: 0.9181 - loss: 1.6869 - val_accuracy: 0.8889 - val_loss: 1.7447 - learning_rate: 0.0010\n","Epoch 63/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 0.8948 - loss: 1.6416 - val_accuracy: 0.8889 - val_loss: 1.7210 - learning_rate: 0.0010\n","Epoch 64/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.8950 - loss: 1.6365 - val_accuracy: 0.8889 - val_loss: 1.6972 - learning_rate: 0.0010\n","Epoch 65/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 297ms/step - accuracy: 0.9126 - loss: 1.5457 - val_accuracy: 0.8889 - val_loss: 1.6577 - learning_rate: 0.0010\n","Epoch 66/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 335ms/step - accuracy: 0.9039 - loss: 1.5524 - val_accuracy: 0.9000 - val_loss: 1.6394 - learning_rate: 0.0010\n","Epoch 67/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.9270 - loss: 1.4798 - val_accuracy: 0.8889 - val_loss: 1.6008 - learning_rate: 0.0010\n","Epoch 68/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9114 - loss: 1.4757 - val_accuracy: 0.8889 - val_loss: 1.5688 - learning_rate: 0.0010\n","Epoch 69/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9193 - loss: 1.4163 - val_accuracy: 0.8889 - val_loss: 1.5398 - learning_rate: 0.0010\n","Epoch 70/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - accuracy: 0.8995 - loss: 1.4412 - val_accuracy: 0.8889 - val_loss: 1.5245 - learning_rate: 0.0010\n","Epoch 71/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.8854 - loss: 1.4122 - val_accuracy: 0.8778 - val_loss: 1.4846 - learning_rate: 0.0010\n","Epoch 72/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.9159 - loss: 1.3384 - val_accuracy: 0.8889 - val_loss: 1.4323 - learning_rate: 0.0010\n","Epoch 73/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 323ms/step - accuracy: 0.9188 - loss: 1.3366 - val_accuracy: 0.8889 - val_loss: 1.4112 - learning_rate: 0.0010\n","Epoch 74/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 299ms/step - accuracy: 0.9292 - loss: 1.2654 - val_accuracy: 0.9000 - val_loss: 1.3848 - learning_rate: 0.0010\n","Epoch 75/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - accuracy: 0.9264 - loss: 1.2457 - val_accuracy: 0.9000 - val_loss: 1.3648 - learning_rate: 0.0010\n","Epoch 76/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.9315 - loss: 1.1926 - val_accuracy: 0.8889 - val_loss: 1.3352 - learning_rate: 0.0010\n","Epoch 77/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9088 - loss: 1.2273 - val_accuracy: 0.8778 - val_loss: 1.3173 - learning_rate: 0.0010\n","Epoch 78/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - accuracy: 0.9059 - loss: 1.2473 - val_accuracy: 0.8889 - val_loss: 1.3104 - learning_rate: 0.0010\n","Epoch 79/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 0.9542 - loss: 1.1129 - val_accuracy: 0.8778 - val_loss: 1.2796 - learning_rate: 0.0010\n","Epoch 80/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.9446 - loss: 1.1076 - val_accuracy: 0.8778 - val_loss: 1.2759 - learning_rate: 0.0010\n","Epoch 81/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260ms/step - accuracy: 0.9312 - loss: 1.1222 - val_accuracy: 0.8778 - val_loss: 1.2730 - learning_rate: 0.0010\n","Epoch 82/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 287ms/step - accuracy: 0.9203 - loss: 1.1139 - val_accuracy: 0.8889 - val_loss: 1.2240 - learning_rate: 0.0010\n","Epoch 83/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.8985 - loss: 1.1573 - val_accuracy: 0.8778 - val_loss: 1.2203 - learning_rate: 0.0010\n","Epoch 84/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.9217 - loss: 1.0925 - val_accuracy: 0.8889 - val_loss: 1.1511 - learning_rate: 0.0010\n","Epoch 85/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.9210 - loss: 1.0826 - val_accuracy: 0.9000 - val_loss: 1.1345 - learning_rate: 0.0010\n","Epoch 86/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 0.9221 - loss: 1.0399 - val_accuracy: 0.9000 - val_loss: 1.1080 - learning_rate: 0.0010\n","Epoch 87/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - accuracy: 0.9123 - loss: 1.1612 - val_accuracy: 0.9000 - val_loss: 1.0927 - learning_rate: 0.0010\n","Epoch 88/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - accuracy: 0.9119 - loss: 1.0295 - val_accuracy: 0.9000 - val_loss: 1.0803 - learning_rate: 0.0010\n","Epoch 89/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.9379 - loss: 0.9376 - val_accuracy: 0.9000 - val_loss: 1.0729 - learning_rate: 0.0010\n","Epoch 90/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 303ms/step - accuracy: 0.9319 - loss: 0.9682 - val_accuracy: 0.8889 - val_loss: 1.0538 - learning_rate: 0.0010\n","Epoch 91/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - accuracy: 0.8915 - loss: 0.9404 - val_accuracy: 0.8889 - val_loss: 1.0327 - learning_rate: 0.0010\n","Epoch 92/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.9278 - loss: 0.9252 - val_accuracy: 0.8778 - val_loss: 1.0423 - learning_rate: 0.0010\n","Epoch 93/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9136 - loss: 0.8913 - val_accuracy: 0.8889 - val_loss: 1.0145 - learning_rate: 0.0010\n","Epoch 94/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 193ms/step - accuracy: 0.9316 - loss: 0.8786 - val_accuracy: 0.8889 - val_loss: 1.0101 - learning_rate: 0.0010\n","Epoch 95/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 228ms/step - accuracy: 0.9310 - loss: 0.8830 - val_accuracy: 0.8778 - val_loss: 0.9911 - learning_rate: 0.0010\n","Epoch 96/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - accuracy: 0.9203 - loss: 0.8415 - val_accuracy: 0.9000 - val_loss: 0.9559 - learning_rate: 0.0010\n","Epoch 97/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step - accuracy: 0.9488 - loss: 0.8037 - val_accuracy: 0.8889 - val_loss: 0.9512 - learning_rate: 0.0010\n","Epoch 98/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.9173 - loss: 0.8042 - val_accuracy: 0.8889 - val_loss: 0.9466 - learning_rate: 0.0010\n","Epoch 99/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 0.9370 - loss: 0.8178 - val_accuracy: 0.8889 - val_loss: 0.9435 - learning_rate: 0.0010\n","Epoch 100/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.9361 - loss: 0.8329 - val_accuracy: 0.8889 - val_loss: 0.9135 - learning_rate: 0.0010\n","Epoch 101/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 184ms/step - accuracy: 0.9311 - loss: 0.7885 - val_accuracy: 0.8889 - val_loss: 0.9043 - learning_rate: 0.0010\n","Epoch 102/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9532 - loss: 0.6975 - val_accuracy: 0.8889 - val_loss: 0.8839 - learning_rate: 0.0010\n","Epoch 103/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 290ms/step - accuracy: 0.9395 - loss: 0.8193 - val_accuracy: 0.8889 - val_loss: 0.9072 - learning_rate: 0.0010\n","Epoch 104/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step - accuracy: 0.9470 - loss: 0.7239 - val_accuracy: 0.8778 - val_loss: 0.8910 - learning_rate: 0.0010\n","Epoch 105/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.9453 - loss: 0.7490 - val_accuracy: 0.8889 - val_loss: 0.8643 - learning_rate: 0.0010\n","Epoch 106/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - accuracy: 0.9336 - loss: 0.7567 - val_accuracy: 0.9000 - val_loss: 0.8456 - learning_rate: 0.0010\n","Epoch 107/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 184ms/step - accuracy: 0.9481 - loss: 0.6887 - val_accuracy: 0.9000 - val_loss: 0.8242 - learning_rate: 0.0010\n","Epoch 108/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9388 - loss: 0.6952 - val_accuracy: 0.9000 - val_loss: 0.8252 - learning_rate: 0.0010\n","Epoch 109/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9461 - loss: 0.6817 - val_accuracy: 0.8889 - val_loss: 0.8039 - learning_rate: 0.0010\n","Epoch 110/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9448 - loss: 0.7158 - val_accuracy: 0.9000 - val_loss: 0.8134 - learning_rate: 0.0010\n","Epoch 111/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 288ms/step - accuracy: 0.9249 - loss: 0.6921 - val_accuracy: 0.8889 - val_loss: 0.8093 - learning_rate: 0.0010\n","Epoch 112/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step - accuracy: 0.9349 - loss: 0.7102 - val_accuracy: 0.9000 - val_loss: 0.7997 - learning_rate: 0.0010\n","Epoch 113/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 295ms/step - accuracy: 0.9573 - loss: 0.6104 - val_accuracy: 0.9000 - val_loss: 0.7824 - learning_rate: 0.0010\n","Epoch 114/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9247 - loss: 0.6657 - val_accuracy: 0.9000 - val_loss: 0.7842 - learning_rate: 0.0010\n","Epoch 115/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9634 - loss: 0.5937 - val_accuracy: 0.9111 - val_loss: 0.7775 - learning_rate: 0.0010\n","Epoch 116/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - accuracy: 0.9511 - loss: 0.5727 - val_accuracy: 0.8889 - val_loss: 0.7611 - learning_rate: 0.0010\n","Epoch 117/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9536 - loss: 0.5812 - val_accuracy: 0.8556 - val_loss: 0.7787 - learning_rate: 0.0010\n","Epoch 118/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9192 - loss: 0.6191 - val_accuracy: 0.8667 - val_loss: 0.7718 - learning_rate: 0.0010\n","Epoch 119/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9479 - loss: 0.5487 - val_accuracy: 0.8556 - val_loss: 0.7890 - learning_rate: 0.0010\n","Epoch 120/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step - accuracy: 0.9527 - loss: 0.5669 - val_accuracy: 0.8889 - val_loss: 0.7340 - learning_rate: 0.0010\n","Epoch 121/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 345ms/step - accuracy: 0.9061 - loss: 0.6693 - val_accuracy: 0.8778 - val_loss: 0.7340 - learning_rate: 0.0010\n","Epoch 122/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.9666 - loss: 0.5179 - val_accuracy: 0.9000 - val_loss: 0.7101 - learning_rate: 0.0010\n","Epoch 123/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 185ms/step - accuracy: 0.9313 - loss: 0.5562 - val_accuracy: 0.8667 - val_loss: 0.7188 - learning_rate: 0.0010\n","Epoch 124/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9628 - loss: 0.5273 - val_accuracy: 0.8667 - val_loss: 0.7142 - learning_rate: 0.0010\n","Epoch 125/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.9202 - loss: 0.5608 - val_accuracy: 0.8667 - val_loss: 0.7119 - learning_rate: 0.0010\n","Epoch 126/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - accuracy: 0.9339 - loss: 0.5563 - val_accuracy: 0.8889 - val_loss: 0.6808 - learning_rate: 0.0010\n","Epoch 127/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - accuracy: 0.9254 - loss: 0.5127 - val_accuracy: 0.9000 - val_loss: 0.6809 - learning_rate: 0.0010\n","Epoch 128/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 296ms/step - accuracy: 0.9590 - loss: 0.5540 - val_accuracy: 0.8889 - val_loss: 0.6745 - learning_rate: 0.0010\n","Epoch 129/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - accuracy: 0.9409 - loss: 0.5158 - val_accuracy: 0.9000 - val_loss: 0.6659 - learning_rate: 0.0010\n","Epoch 130/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - accuracy: 0.9496 - loss: 0.5132 - val_accuracy: 0.8778 - val_loss: 0.6779 - learning_rate: 0.0010\n","Epoch 131/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - accuracy: 0.9494 - loss: 0.4710 - val_accuracy: 0.8889 - val_loss: 0.6746 - learning_rate: 0.0010\n","Epoch 132/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.9672 - loss: 0.4450 - val_accuracy: 0.8444 - val_loss: 0.6996 - learning_rate: 0.0010\n","Epoch 133/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - accuracy: 0.9602 - loss: 0.4339 - val_accuracy: 0.8556 - val_loss: 0.7038 - learning_rate: 0.0010\n","Epoch 134/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 0.9394 - loss: 0.4846 - val_accuracy: 0.8889 - val_loss: 0.6590 - learning_rate: 0.0010\n","Epoch 135/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.9635 - loss: 0.4213 - val_accuracy: 0.8889 - val_loss: 0.6594 - learning_rate: 0.0010\n","Epoch 136/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - accuracy: 0.9728 - loss: 0.4422 - val_accuracy: 0.8667 - val_loss: 0.6437 - learning_rate: 0.0010\n","Epoch 137/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 283ms/step - accuracy: 0.9475 - loss: 0.4508 - val_accuracy: 0.9000 - val_loss: 0.6316 - learning_rate: 0.0010\n","Epoch 138/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - accuracy: 0.9332 - loss: 0.4315 - val_accuracy: 0.8667 - val_loss: 0.6438 - learning_rate: 0.0010\n","Epoch 139/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - accuracy: 0.9391 - loss: 0.4449 - val_accuracy: 0.8778 - val_loss: 0.6362 - learning_rate: 0.0010\n","Epoch 140/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.9149 - loss: 0.4851 - val_accuracy: 0.8889 - val_loss: 0.6242 - learning_rate: 0.0010\n","Epoch 141/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 0.9617 - loss: 0.4604 - val_accuracy: 0.8778 - val_loss: 0.6214 - learning_rate: 0.0010\n","Epoch 142/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 0.9222 - loss: 0.4742 - val_accuracy: 0.8778 - val_loss: 0.6321 - learning_rate: 0.0010\n","Epoch 143/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 0.9476 - loss: 0.4455 - val_accuracy: 0.9000 - val_loss: 0.6073 - learning_rate: 0.0010\n","Epoch 144/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 317ms/step - accuracy: 0.9369 - loss: 0.4291 - val_accuracy: 0.8778 - val_loss: 0.6150 - learning_rate: 0.0010\n","Epoch 145/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 0.9564 - loss: 0.4160 - val_accuracy: 0.9111 - val_loss: 0.5895 - learning_rate: 0.0010\n","Epoch 146/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 0.9697 - loss: 0.3827 - val_accuracy: 0.8889 - val_loss: 0.5915 - learning_rate: 0.0010\n","Epoch 147/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.9771 - loss: 0.3299 - val_accuracy: 0.8444 - val_loss: 0.6414 - learning_rate: 0.0010\n","Epoch 148/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step - accuracy: 0.9549 - loss: 0.3613 - val_accuracy: 0.9000 - val_loss: 0.6034 - learning_rate: 0.0010\n","Epoch 149/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - accuracy: 0.9617 - loss: 0.3533 - val_accuracy: 0.8778 - val_loss: 0.5901 - learning_rate: 0.0010\n","Epoch 150/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9488 - loss: 0.3861 - val_accuracy: 0.8778 - val_loss: 0.5829 - learning_rate: 0.0010\n","Test Accuracy: 0.8778\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.86      0.87        42\n","           1       0.88      0.90      0.89        48\n","\n","    accuracy                           0.88        90\n","   macro avg       0.88      0.88      0.88        90\n","weighted avg       0.88      0.88      0.88        90\n","\n"]}]},{"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, Conv1D, BatchNormalization, Dropout, GlobalMaxPooling1D, Dense\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from sklearn.impute import SimpleImputer\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import pandas as pd\n","from keras import regularizers\n","\n","# Load Dataset\n","file_path = '/content/three_T_Marge.csv'\n","data = pd.read_csv(file_path)\n","\n","# Separate Features and Labels\n","X = data.iloc[:, :-1].values\n","y = data.iloc[:, -1].values\n","\n","# Handle missing values\n","imputer = SimpleImputer(strategy='mean')\n","X = imputer.fit_transform(X)\n","\n","# Normalize Features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# SMOTE for oversampling\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X, y = smote.fit_resample(X, y)\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Reshaping input for Conv1D\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","\n","# Build Model\n","def build_model(input_dim):\n","    inputs = Input(shape=(input_dim, 1))\n","    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(inputs)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","\n","    x = Conv1D(256, kernel_size=5, activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","\n","    x = Conv1D(512, kernel_size=7, activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","\n","    x = GlobalMaxPooling1D()(x)\n","\n","    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n","    x = Dropout(0.5)(x)\n","\n","    outputs = Dense(1, activation='sigmoid')(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","input_dim = X_train.shape[1]\n","model = build_model(input_dim)\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n","\n","# Train Model\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=150,\n","    batch_size=32,\n","    class_weight={0: 1, 1: 1},\n","    callbacks=[early_stopping],\n","    verbose=1\n",")\n","\n","# Evaluate Model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","# Classification Report\n","y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n","print(classification_report(y_test, y_pred))\n","\n","# Save Model\n","model.save('/content/high_accuracy_model.keras')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay6JzqPt095V","executionInfo":{"status":"ok","timestamp":1737093905656,"user_tz":-360,"elapsed":432356,"user":{"displayName":"saleh 3993","userId":"07275202465005334012"}},"outputId":"3893bc3c-65ae-4960-eb48-b5d4abc795e3"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 327ms/step - accuracy: 0.7240 - loss: 5.5424 - val_accuracy: 0.8778 - val_loss: 3.8520\n","Epoch 2/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - accuracy: 0.8760 - loss: 4.9690 - val_accuracy: 0.8889 - val_loss: 3.7310\n","Epoch 3/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 461ms/step - accuracy: 0.8989 - loss: 3.7968 - val_accuracy: 0.8778 - val_loss: 3.6459\n","Epoch 4/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401ms/step - accuracy: 0.8942 - loss: 3.6658 - val_accuracy: 0.8556 - val_loss: 3.5547\n","Epoch 5/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.8770 - loss: 3.3767 - val_accuracy: 0.8222 - val_loss: 3.4699\n","Epoch 6/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.9053 - loss: 3.3158 - val_accuracy: 0.8000 - val_loss: 3.4017\n","Epoch 7/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - accuracy: 0.8787 - loss: 3.3548 - val_accuracy: 0.7556 - val_loss: 3.3300\n","Epoch 8/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 446ms/step - accuracy: 0.8786 - loss: 3.0378 - val_accuracy: 0.7333 - val_loss: 3.2532\n","Epoch 9/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.8998 - loss: 2.9922 - val_accuracy: 0.7111 - val_loss: 3.1903\n","Epoch 10/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 295ms/step - accuracy: 0.8933 - loss: 2.9689 - val_accuracy: 0.7111 - val_loss: 3.1242\n","Epoch 11/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.9084 - loss: 2.8004 - val_accuracy: 0.7000 - val_loss: 3.0726\n","Epoch 12/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 289ms/step - accuracy: 0.9260 - loss: 2.7471 - val_accuracy: 0.6667 - val_loss: 3.0163\n","Epoch 13/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 326ms/step - accuracy: 0.8957 - loss: 2.7171 - val_accuracy: 0.6556 - val_loss: 2.9555\n","Epoch 14/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 0.8665 - loss: 2.6424 - val_accuracy: 0.6556 - val_loss: 2.8987\n","Epoch 15/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 442ms/step - accuracy: 0.9141 - loss: 2.5631 - val_accuracy: 0.6222 - val_loss: 2.8539\n","Epoch 16/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.9256 - loss: 2.4575 - val_accuracy: 0.6000 - val_loss: 2.8192\n","Epoch 17/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step - accuracy: 0.9006 - loss: 2.4451 - val_accuracy: 0.6222 - val_loss: 2.7664\n","Epoch 18/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - accuracy: 0.9010 - loss: 2.3881 - val_accuracy: 0.6333 - val_loss: 2.7146\n","Epoch 19/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 286ms/step - accuracy: 0.9007 - loss: 2.4207 - val_accuracy: 0.6333 - val_loss: 2.6778\n","Epoch 20/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 522ms/step - accuracy: 0.9038 - loss: 2.3022 - val_accuracy: 0.6222 - val_loss: 2.6400\n","Epoch 21/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 0.9583 - loss: 2.2249 - val_accuracy: 0.6222 - val_loss: 2.6048\n","Epoch 22/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 277ms/step - accuracy: 0.8864 - loss: 2.2471 - val_accuracy: 0.6556 - val_loss: 2.5556\n","Epoch 23/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 283ms/step - accuracy: 0.9061 - loss: 2.1851 - val_accuracy: 0.7111 - val_loss: 2.5002\n","Epoch 24/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 0.9273 - loss: 2.1381 - val_accuracy: 0.7111 - val_loss: 2.4608\n","Epoch 25/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 355ms/step - accuracy: 0.9067 - loss: 2.1297 - val_accuracy: 0.7222 - val_loss: 2.4162\n","Epoch 26/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 0.9311 - loss: 2.0686 - val_accuracy: 0.7556 - val_loss: 2.3645\n","Epoch 27/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.8953 - loss: 2.1366 - val_accuracy: 0.7556 - val_loss: 2.3261\n","Epoch 28/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - accuracy: 0.9049 - loss: 2.0577 - val_accuracy: 0.7889 - val_loss: 2.2859\n","Epoch 29/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 272ms/step - accuracy: 0.9152 - loss: 2.0470 - val_accuracy: 0.8111 - val_loss: 2.2502\n","Epoch 30/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 317ms/step - accuracy: 0.9162 - loss: 1.9463 - val_accuracy: 0.8222 - val_loss: 2.2144\n","Epoch 31/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 477ms/step - accuracy: 0.9078 - loss: 1.9881 - val_accuracy: 0.8556 - val_loss: 2.1850\n","Epoch 32/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.8940 - loss: 1.9628 - val_accuracy: 0.8556 - val_loss: 2.1514\n","Epoch 33/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.9214 - loss: 1.8457 - val_accuracy: 0.8333 - val_loss: 2.1112\n","Epoch 34/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 281ms/step - accuracy: 0.9043 - loss: 1.8807 - val_accuracy: 0.8111 - val_loss: 2.0842\n","Epoch 35/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 286ms/step - accuracy: 0.9249 - loss: 1.8930 - val_accuracy: 0.8111 - val_loss: 2.0548\n","Epoch 36/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.9323 - loss: 1.8099 - val_accuracy: 0.8111 - val_loss: 2.0170\n","Epoch 37/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 450ms/step - accuracy: 0.9298 - loss: 1.7747 - val_accuracy: 0.8444 - val_loss: 1.9852\n","Epoch 38/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 290ms/step - accuracy: 0.8972 - loss: 1.9310 - val_accuracy: 0.8556 - val_loss: 1.9536\n","Epoch 39/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.9231 - loss: 1.7225 - val_accuracy: 0.8444 - val_loss: 1.9213\n","Epoch 40/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - accuracy: 0.9116 - loss: 1.7269 - val_accuracy: 0.8556 - val_loss: 1.8905\n","Epoch 41/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - accuracy: 0.8987 - loss: 1.7778 - val_accuracy: 0.8556 - val_loss: 1.8659\n","Epoch 42/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 420ms/step - accuracy: 0.9227 - loss: 1.6973 - val_accuracy: 0.8556 - val_loss: 1.8368\n","Epoch 43/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.9208 - loss: 1.6380 - val_accuracy: 0.8778 - val_loss: 1.8049\n","Epoch 44/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 276ms/step - accuracy: 0.9519 - loss: 1.5657 - val_accuracy: 0.9111 - val_loss: 1.7776\n","Epoch 45/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 273ms/step - accuracy: 0.9310 - loss: 1.5661 - val_accuracy: 0.9222 - val_loss: 1.7477\n","Epoch 46/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 281ms/step - accuracy: 0.9543 - loss: 1.5262 - val_accuracy: 0.9222 - val_loss: 1.7210\n","Epoch 47/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 422ms/step - accuracy: 0.9166 - loss: 1.5938 - val_accuracy: 0.9222 - val_loss: 1.7007\n","Epoch 48/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9330 - loss: 1.4983 - val_accuracy: 0.9222 - val_loss: 1.6719\n","Epoch 49/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 277ms/step - accuracy: 0.9507 - loss: 1.5162 - val_accuracy: 0.9222 - val_loss: 1.6473\n","Epoch 50/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 282ms/step - accuracy: 0.9272 - loss: 1.4824 - val_accuracy: 0.9111 - val_loss: 1.6208\n","Epoch 51/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 276ms/step - accuracy: 0.9276 - loss: 1.5462 - val_accuracy: 0.9222 - val_loss: 1.6070\n","Epoch 52/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 411ms/step - accuracy: 0.9244 - loss: 1.4817 - val_accuracy: 0.9111 - val_loss: 1.5773\n","Epoch 53/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 516ms/step - accuracy: 0.9363 - loss: 1.4368 - val_accuracy: 0.9222 - val_loss: 1.5556\n","Epoch 54/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.9242 - loss: 1.4557 - val_accuracy: 0.9000 - val_loss: 1.5273\n","Epoch 55/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.9408 - loss: 1.4065 - val_accuracy: 0.9000 - val_loss: 1.5131\n","Epoch 56/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 276ms/step - accuracy: 0.9283 - loss: 1.4195 - val_accuracy: 0.9000 - val_loss: 1.4942\n","Epoch 57/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 279ms/step - accuracy: 0.9673 - loss: 1.3339 - val_accuracy: 0.9000 - val_loss: 1.4694\n","Epoch 58/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 462ms/step - accuracy: 0.9560 - loss: 1.2956 - val_accuracy: 0.9000 - val_loss: 1.4554\n","Epoch 59/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9513 - loss: 1.3139 - val_accuracy: 0.9000 - val_loss: 1.4402\n","Epoch 60/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step - accuracy: 0.9389 - loss: 1.3016 - val_accuracy: 0.9000 - val_loss: 1.4145\n","Epoch 61/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 287ms/step - accuracy: 0.9276 - loss: 1.3640 - val_accuracy: 0.8889 - val_loss: 1.4004\n","Epoch 62/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 272ms/step - accuracy: 0.9690 - loss: 1.2314 - val_accuracy: 0.9000 - val_loss: 1.3794\n","Epoch 63/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 338ms/step - accuracy: 0.9410 - loss: 1.2532 - val_accuracy: 0.8889 - val_loss: 1.3629\n","Epoch 64/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 457ms/step - accuracy: 0.9436 - loss: 1.2308 - val_accuracy: 0.9000 - val_loss: 1.3515\n","Epoch 65/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.9643 - loss: 1.1696 - val_accuracy: 0.8889 - val_loss: 1.3364\n","Epoch 66/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 276ms/step - accuracy: 0.9461 - loss: 1.1831 - val_accuracy: 0.9111 - val_loss: 1.3171\n","Epoch 67/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 280ms/step - accuracy: 0.9752 - loss: 1.1367 - val_accuracy: 0.8889 - val_loss: 1.3029\n","Epoch 68/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 274ms/step - accuracy: 0.9397 - loss: 1.2232 - val_accuracy: 0.8889 - val_loss: 1.3153\n","Epoch 69/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - accuracy: 0.9520 - loss: 1.1489 - val_accuracy: 0.8889 - val_loss: 1.2744\n","Epoch 70/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 343ms/step - accuracy: 0.9539 - loss: 1.1469 - val_accuracy: 0.9000 - val_loss: 1.2560\n","Epoch 71/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 440ms/step - accuracy: 0.9429 - loss: 1.1819 - val_accuracy: 0.8889 - val_loss: 1.2513\n","Epoch 72/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.9340 - loss: 1.1374 - val_accuracy: 0.8889 - val_loss: 1.2261\n","Epoch 73/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 283ms/step - accuracy: 0.9430 - loss: 1.1541 - val_accuracy: 0.8889 - val_loss: 1.2132\n","Epoch 74/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 285ms/step - accuracy: 0.9612 - loss: 1.0417 - val_accuracy: 0.8889 - val_loss: 1.2017\n","Epoch 75/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 279ms/step - accuracy: 0.9650 - loss: 1.0129 - val_accuracy: 0.8889 - val_loss: 1.1926\n","Epoch 76/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 459ms/step - accuracy: 0.9662 - loss: 1.0324 - val_accuracy: 0.8889 - val_loss: 1.1820\n","Epoch 77/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.9741 - loss: 1.0000 - val_accuracy: 0.8889 - val_loss: 1.1691\n","Epoch 78/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 283ms/step - accuracy: 0.9546 - loss: 1.0331 - val_accuracy: 0.8889 - val_loss: 1.1574\n","Epoch 79/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - accuracy: 0.9530 - loss: 1.0080 - val_accuracy: 0.8889 - val_loss: 1.1482\n","Epoch 80/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - accuracy: 0.9505 - loss: 1.0301 - val_accuracy: 0.8889 - val_loss: 1.1401\n","Epoch 81/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 458ms/step - accuracy: 0.9697 - loss: 0.9855 - val_accuracy: 0.8889 - val_loss: 1.1289\n","Epoch 82/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 295ms/step - accuracy: 0.9528 - loss: 0.9652 - val_accuracy: 0.8889 - val_loss: 1.1272\n","Epoch 83/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 277ms/step - accuracy: 0.9648 - loss: 0.9116 - val_accuracy: 0.8778 - val_loss: 1.1177\n","Epoch 84/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 289ms/step - accuracy: 0.9422 - loss: 0.9590 - val_accuracy: 0.8889 - val_loss: 1.1026\n","Epoch 85/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 285ms/step - accuracy: 0.9816 - loss: 0.8750 - val_accuracy: 0.9000 - val_loss: 1.0921\n","Epoch 86/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 448ms/step - accuracy: 0.9696 - loss: 0.8664 - val_accuracy: 0.8889 - val_loss: 1.0847\n","Epoch 87/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.9729 - loss: 0.8597 - val_accuracy: 0.8889 - val_loss: 1.0758\n","Epoch 88/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 293ms/step - accuracy: 0.9731 - loss: 0.8709 - val_accuracy: 0.8889 - val_loss: 1.0672\n","Epoch 89/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step - accuracy: 0.9863 - loss: 0.8342 - val_accuracy: 0.8778 - val_loss: 1.0675\n","Epoch 90/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 276ms/step - accuracy: 0.9844 - loss: 0.8141 - val_accuracy: 0.8889 - val_loss: 1.0558\n","Epoch 91/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 455ms/step - accuracy: 0.9481 - loss: 0.8498 - val_accuracy: 0.8778 - val_loss: 1.0425\n","Epoch 92/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9784 - loss: 0.7842 - val_accuracy: 0.8667 - val_loss: 1.0385\n","Epoch 93/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - accuracy: 0.9681 - loss: 0.8061 - val_accuracy: 0.8778 - val_loss: 1.0263\n","Epoch 94/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 274ms/step - accuracy: 0.9754 - loss: 0.8192 - val_accuracy: 0.8778 - val_loss: 1.0266\n","Epoch 95/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 279ms/step - accuracy: 0.9715 - loss: 0.8100 - val_accuracy: 0.8778 - val_loss: 1.0165\n","Epoch 96/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377ms/step - accuracy: 0.9539 - loss: 0.8157 - val_accuracy: 0.8778 - val_loss: 1.0014\n","Epoch 97/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9831 - loss: 0.7449 - val_accuracy: 0.8667 - val_loss: 0.9938\n","Epoch 98/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 279ms/step - accuracy: 0.9699 - loss: 0.7587 - val_accuracy: 0.8889 - val_loss: 0.9830\n","Epoch 99/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 284ms/step - accuracy: 0.9871 - loss: 0.7128 - val_accuracy: 0.8778 - val_loss: 0.9705\n","Epoch 100/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 284ms/step - accuracy: 0.9890 - loss: 0.7020 - val_accuracy: 0.8778 - val_loss: 0.9572\n","Epoch 101/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - accuracy: 0.9743 - loss: 0.7007 - val_accuracy: 0.8778 - val_loss: 0.9563\n","Epoch 102/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 444ms/step - accuracy: 0.9854 - loss: 0.7091 - val_accuracy: 0.8889 - val_loss: 0.9394\n","Epoch 103/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.9802 - loss: 0.6651 - val_accuracy: 0.8889 - val_loss: 0.9330\n","Epoch 104/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9762 - loss: 0.7173 - val_accuracy: 0.8889 - val_loss: 0.9247\n","Epoch 105/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 278ms/step - accuracy: 0.9720 - loss: 0.6793 - val_accuracy: 0.8889 - val_loss: 0.9241\n","Epoch 106/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 275ms/step - accuracy: 0.9789 - loss: 0.6664 - val_accuracy: 0.8667 - val_loss: 0.9217\n","Epoch 107/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - accuracy: 0.9628 - loss: 0.6902 - val_accuracy: 0.8667 - val_loss: 0.9140\n","Epoch 108/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 471ms/step - accuracy: 0.9596 - loss: 0.6686 - val_accuracy: 0.8667 - val_loss: 0.9122\n","Epoch 109/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 299ms/step - accuracy: 0.9909 - loss: 0.6203 - val_accuracy: 0.8667 - val_loss: 0.9106\n","Epoch 110/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - accuracy: 0.9872 - loss: 0.6039 - val_accuracy: 0.8778 - val_loss: 0.9047\n","Epoch 111/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 276ms/step - accuracy: 0.9771 - loss: 0.6109 - val_accuracy: 0.8667 - val_loss: 0.9037\n","Epoch 112/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 324ms/step - accuracy: 0.9746 - loss: 0.6203 - val_accuracy: 0.8667 - val_loss: 0.9003\n","Epoch 113/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 461ms/step - accuracy: 0.9880 - loss: 0.5866 - val_accuracy: 0.9000 - val_loss: 0.9069\n","Epoch 114/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.9690 - loss: 0.6646 - val_accuracy: 0.8778 - val_loss: 0.8872\n","Epoch 115/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.9709 - loss: 0.5749 - val_accuracy: 0.8667 - val_loss: 0.8847\n","Epoch 116/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.9645 - loss: 0.6257 - val_accuracy: 0.8667 - val_loss: 0.8824\n","Epoch 117/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - accuracy: 0.9982 - loss: 0.5649 - val_accuracy: 0.8556 - val_loss: 0.8844\n","Epoch 118/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 439ms/step - accuracy: 0.9901 - loss: 0.5553 - val_accuracy: 0.8667 - val_loss: 0.8945\n","Epoch 119/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - accuracy: 0.9887 - loss: 0.5299 - val_accuracy: 0.8556 - val_loss: 0.8908\n","Epoch 120/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 281ms/step - accuracy: 0.9964 - loss: 0.5201 - val_accuracy: 0.8556 - val_loss: 0.8885\n","Epoch 121/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step - accuracy: 0.9914 - loss: 0.5154 - val_accuracy: 0.8667 - val_loss: 0.8917\n","Epoch 122/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - accuracy: 0.9899 - loss: 0.5075 - val_accuracy: 0.8778 - val_loss: 0.8764\n","Epoch 123/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 435ms/step - accuracy: 0.9964 - loss: 0.4965 - val_accuracy: 0.8778 - val_loss: 0.8748\n","Epoch 124/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.9788 - loss: 0.5215 - val_accuracy: 0.8556 - val_loss: 0.8615\n","Epoch 125/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 277ms/step - accuracy: 0.9859 - loss: 0.4915 - val_accuracy: 0.8778 - val_loss: 0.8574\n","Epoch 126/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 275ms/step - accuracy: 0.9701 - loss: 0.4909 - val_accuracy: 0.8889 - val_loss: 0.8471\n","Epoch 127/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 296ms/step - accuracy: 0.9735 - loss: 0.5029 - val_accuracy: 0.9000 - val_loss: 0.8359\n","Epoch 128/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 345ms/step - accuracy: 0.9759 - loss: 0.4914 - val_accuracy: 0.8889 - val_loss: 0.8290\n","Epoch 129/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 455ms/step - accuracy: 0.9920 - loss: 0.4710 - val_accuracy: 0.8889 - val_loss: 0.8227\n","Epoch 130/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.9870 - loss: 0.4581 - val_accuracy: 0.8889 - val_loss: 0.8386\n","Epoch 131/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 274ms/step - accuracy: 0.9951 - loss: 0.4509 - val_accuracy: 0.8778 - val_loss: 0.8289\n","Epoch 132/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - accuracy: 0.9820 - loss: 0.4981 - val_accuracy: 0.8778 - val_loss: 0.8402\n","Epoch 133/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step - accuracy: 0.9946 - loss: 0.4467 - val_accuracy: 0.8667 - val_loss: 0.8339\n","Epoch 134/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 454ms/step - accuracy: 0.9831 - loss: 0.4362 - val_accuracy: 0.8778 - val_loss: 0.8225\n","Epoch 135/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.9933 - loss: 0.4265 - val_accuracy: 0.8889 - val_loss: 0.8084\n","Epoch 136/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 272ms/step - accuracy: 0.9828 - loss: 0.4278 - val_accuracy: 0.8889 - val_loss: 0.7905\n","Epoch 137/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 268ms/step - accuracy: 0.9892 - loss: 0.4378 - val_accuracy: 0.8889 - val_loss: 0.7947\n","Epoch 138/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.9901 - loss: 0.4316 - val_accuracy: 0.8889 - val_loss: 0.7908\n","Epoch 139/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 438ms/step - accuracy: 0.9825 - loss: 0.4390 - val_accuracy: 0.8889 - val_loss: 0.7481\n","Epoch 140/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.9974 - loss: 0.3905 - val_accuracy: 0.9000 - val_loss: 0.7597\n","Epoch 141/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 273ms/step - accuracy: 0.9913 - loss: 0.4090 - val_accuracy: 0.8778 - val_loss: 0.7464\n","Epoch 142/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 269ms/step - accuracy: 0.9877 - loss: 0.3900 - val_accuracy: 0.9000 - val_loss: 0.7700\n","Epoch 143/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 0.9982 - loss: 0.3687 - val_accuracy: 0.8667 - val_loss: 0.7722\n","Epoch 144/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 445ms/step - accuracy: 0.9742 - loss: 0.4318 - val_accuracy: 0.8889 - val_loss: 0.7503\n","Epoch 145/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372ms/step - accuracy: 0.9805 - loss: 0.3958 - val_accuracy: 0.8444 - val_loss: 0.7415\n","Epoch 146/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 290ms/step - accuracy: 0.9910 - loss: 0.3666 - val_accuracy: 0.8667 - val_loss: 0.7423\n","Epoch 147/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 268ms/step - accuracy: 0.9933 - loss: 0.3623 - val_accuracy: 0.8667 - val_loss: 0.7378\n","Epoch 148/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 272ms/step - accuracy: 0.9939 - loss: 0.3513 - val_accuracy: 0.8667 - val_loss: 0.7269\n","Epoch 149/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 270ms/step - accuracy: 0.9882 - loss: 0.3714 - val_accuracy: 0.8889 - val_loss: 0.7257\n","Epoch 150/150\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 453ms/step - accuracy: 0.9880 - loss: 0.3422 - val_accuracy: 0.8667 - val_loss: 0.7334\n","Test Accuracy: 0.8889\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.90      0.88        42\n","           1       0.91      0.88      0.89        48\n","\n","    accuracy                           0.89        90\n","   macro avg       0.89      0.89      0.89        90\n","weighted avg       0.89      0.89      0.89        90\n","\n"]}]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Soq3v3WT_9st","outputId":"7a9400ee-f642-422e-fdf1-04b1b62a7e01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"]}]},{"cell_type":"code","source":["import optuna\n","from keras.models import Model\n","from keras.layers import Input, Conv1D, BatchNormalization, Dropout, GlobalMaxPooling1D, Dense\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from keras import regularizers\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from imblearn.over_sampling import SMOTE\n","import pandas as pd\n","from sklearn.metrics import classification_report\n","\n","# Load the dataset\n","file_path = '/content/three_T_Marge.csv'\n","data = pd.read_csv(file_path)\n","\n","# Separate features and labels\n","X = data.iloc[:, :-1].values  # Features\n","y = data.iloc[:, -1].values   # Labels\n","\n","# Handle missing values (imputation)\n","imputer = SimpleImputer(strategy='mean')\n","X = imputer.fit_transform(X)\n","\n","# Normalize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# SMOTE for oversampling the minority class\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X, y = smote.fit_resample(X, y)\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Reshaping the input for Conv1D (samples, features, 1)\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","\n","# Objective function for Optuna\n","def objective(trial):\n","    # Hyperparameters to tune\n","    filters_1 = trial.suggest_int('filters_1', 32, 128)\n","    filters_2 = trial.suggest_int('filters_2', 64, 256)\n","    kernel_size_1 = trial.suggest_int('kernel_size_1', 3, 5)\n","    kernel_size_2 = trial.suggest_int('kernel_size_2', 3, 5)\n","    dropout_1 = trial.suggest_float('dropout_1', 0.2, 0.5)\n","    dropout_2 = trial.suggest_float('dropout_2', 0.2, 0.5)\n","    dense_units = trial.suggest_int('dense_units', 64, 256)\n","    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n","\n","    # Build model\n","    inputs = Input(shape=(X_train.shape[1], 1))  # 1D CNN expects a 3D input shape (samples, features, 1)\n","\n","    # First Conv1D Layer\n","    x = Conv1D(filters_1, kernel_size=kernel_size_1, activation='relu', padding='same')(inputs)\n","    x = BatchNormalization()(x)\n","    x = Dropout(dropout_1)(x)\n","\n","    # Second Conv1D Layer\n","    x = Conv1D(filters_2, kernel_size=kernel_size_2, activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(dropout_2)(x)\n","\n","    # Max Pooling\n","    x = GlobalMaxPooling1D()(x)\n","\n","    # Dense Layer\n","    x = Dense(dense_units, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n","    x = Dropout(0.4)(x)\n","\n","    # Output Layer\n","    outputs = Dense(1, activation='sigmoid')(x)  # For binary classification\n","\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    # Early stopping\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","    # Train the model\n","    history = model.fit(\n","        X_train, y_train,\n","        validation_data=(X_test, y_test),\n","        epochs=50,\n","        batch_size=32,\n","        callbacks=[early_stopping],\n","        verbose=0\n","    )\n","\n","    # Evaluate the model\n","    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","    return accuracy  # We want to maximize accuracy\n","\n","# Create an Optuna study and start optimizing\n","study = optuna.create_study(direction='maximize')  # We want to maximize the accuracy\n","\n","# Optimize the hyperparameters\n","study.optimize(objective, n_trials=50)  # n_trials is the number of different hyperparameter sets to try\n","\n","# Print the best hyperparameters and accuracy\n","print(f\"Best Hyperparameters: {study.best_params}\")\n","print(f\"Best Accuracy: {study.best_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_eNI4Ct_0Zj","outputId":"a0e80518-3c37-49ae-a898-f5a5db5f1591"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-01-16 16:44:19,237] A new study created in memory with name: no-name-9ce818a1-8954-409b-ae3c-0d3c3465e7d1\n","<ipython-input-55-c5e6fc210871>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n","[I 2025-01-16 16:44:49,664] Trial 0 finished with value: 0.8999999761581421 and parameters: {'filters_1': 127, 'filters_2': 99, 'kernel_size_1': 3, 'kernel_size_2': 5, 'dropout_1': 0.3846746952997323, 'dropout_2': 0.23942198137150264, 'dense_units': 198, 'learning_rate': 1.8600464785366256e-05}. Best is trial 0 with value: 0.8999999761581421.\n","[I 2025-01-16 16:45:08,252] Trial 1 finished with value: 0.9111111164093018 and parameters: {'filters_1': 125, 'filters_2': 251, 'kernel_size_1': 5, 'kernel_size_2': 4, 'dropout_1': 0.3130175125421953, 'dropout_2': 0.3254846559253608, 'dense_units': 90, 'learning_rate': 6.0115629311913246e-05}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:45:27,511] Trial 2 finished with value: 0.8777777552604675 and parameters: {'filters_1': 39, 'filters_2': 173, 'kernel_size_1': 5, 'kernel_size_2': 3, 'dropout_1': 0.3799748841573184, 'dropout_2': 0.21137831313015337, 'dense_units': 185, 'learning_rate': 6.893167236040197e-05}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:45:46,337] Trial 3 finished with value: 0.8999999761581421 and parameters: {'filters_1': 34, 'filters_2': 121, 'kernel_size_1': 5, 'kernel_size_2': 4, 'dropout_1': 0.20863516134035473, 'dropout_2': 0.46685560274591736, 'dense_units': 152, 'learning_rate': 6.422412055131429e-05}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:46:13,754] Trial 4 finished with value: 0.8999999761581421 and parameters: {'filters_1': 124, 'filters_2': 245, 'kernel_size_1': 4, 'kernel_size_2': 3, 'dropout_1': 0.31157096142848756, 'dropout_2': 0.46589905422873645, 'dense_units': 226, 'learning_rate': 0.0014676410377365413}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:46:40,093] Trial 5 finished with value: 0.9111111164093018 and parameters: {'filters_1': 46, 'filters_2': 115, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.2867071463049373, 'dropout_2': 0.4141642554259044, 'dense_units': 144, 'learning_rate': 0.0003558521134098415}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:46:57,693] Trial 6 finished with value: 0.8888888955116272 and parameters: {'filters_1': 97, 'filters_2': 81, 'kernel_size_1': 3, 'kernel_size_2': 5, 'dropout_1': 0.2337432715863932, 'dropout_2': 0.22065429273421128, 'dense_units': 204, 'learning_rate': 0.0013529168706831439}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:47:25,839] Trial 7 finished with value: 0.8888888955116272 and parameters: {'filters_1': 101, 'filters_2': 157, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.3114764745301792, 'dropout_2': 0.24628010827366417, 'dense_units': 244, 'learning_rate': 0.0003061593405279982}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:47:55,588] Trial 8 finished with value: 0.8999999761581421 and parameters: {'filters_1': 100, 'filters_2': 144, 'kernel_size_1': 3, 'kernel_size_2': 4, 'dropout_1': 0.3269411355547992, 'dropout_2': 0.26603610540081996, 'dense_units': 113, 'learning_rate': 0.0010284732137685}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:48:23,609] Trial 9 finished with value: 0.8999999761581421 and parameters: {'filters_1': 90, 'filters_2': 252, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.2876498176182226, 'dropout_2': 0.4783574717587224, 'dense_units': 164, 'learning_rate': 0.007954314179150363}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:48:51,687] Trial 10 finished with value: 0.8999999761581421 and parameters: {'filters_1': 68, 'filters_2': 220, 'kernel_size_1': 5, 'kernel_size_2': 3, 'dropout_1': 0.48435172807654137, 'dropout_2': 0.32934514841714346, 'dense_units': 67, 'learning_rate': 1.2501514837870126e-05}. Best is trial 1 with value: 0.9111111164093018.\n","[I 2025-01-16 16:49:19,680] Trial 11 finished with value: 0.9222221970558167 and parameters: {'filters_1': 60, 'filters_2': 197, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.2598558372020141, 'dropout_2': 0.3931967458563041, 'dense_units': 104, 'learning_rate': 0.00018393736277396444}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:49:37,674] Trial 12 finished with value: 0.8999999761581421 and parameters: {'filters_1': 62, 'filters_2': 199, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.25075171442795424, 'dropout_2': 0.35943234042238825, 'dense_units': 82, 'learning_rate': 9.871197702350997e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:49:55,604] Trial 13 finished with value: 0.8999999761581421 and parameters: {'filters_1': 70, 'filters_2': 205, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.4030849762952675, 'dropout_2': 0.3248454944970825, 'dense_units': 106, 'learning_rate': 0.00020328824238406102}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:50:14,353] Trial 14 finished with value: 0.9111111164093018 and parameters: {'filters_1': 55, 'filters_2': 229, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.2533158430223779, 'dropout_2': 0.3901053352497688, 'dense_units': 116, 'learning_rate': 3.4079346487803737e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:50:31,864] Trial 15 finished with value: 0.8888888955116272 and parameters: {'filters_1': 113, 'filters_2': 184, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.43958640493276707, 'dropout_2': 0.2870112257268839, 'dense_units': 93, 'learning_rate': 0.00014521003878171574}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:51:00,436] Trial 16 finished with value: 0.8888888955116272 and parameters: {'filters_1': 78, 'filters_2': 224, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.36275152681420775, 'dropout_2': 0.4221404160727509, 'dense_units': 138, 'learning_rate': 0.0006465408704309003}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:51:29,140] Trial 17 finished with value: 0.9111111164093018 and parameters: {'filters_1': 81, 'filters_2': 196, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.20420789267690057, 'dropout_2': 0.30501540133420063, 'dense_units': 67, 'learning_rate': 3.0221114952665883e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:51:56,994] Trial 18 finished with value: 0.8999999761581421 and parameters: {'filters_1': 52, 'filters_2': 251, 'kernel_size_1': 3, 'kernel_size_2': 3, 'dropout_1': 0.27965946066483227, 'dropout_2': 0.37334570624161056, 'dense_units': 129, 'learning_rate': 0.007331991740357606}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:52:15,747] Trial 19 finished with value: 0.8999999761581421 and parameters: {'filters_1': 115, 'filters_2': 147, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.34257669259974743, 'dropout_2': 0.43014532363055435, 'dense_units': 89, 'learning_rate': 0.002817452946260116}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:52:43,162] Trial 20 finished with value: 0.8888888955116272 and parameters: {'filters_1': 87, 'filters_2': 174, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.4161475705549803, 'dropout_2': 0.3440095271977459, 'dense_units': 170, 'learning_rate': 3.970145796725065e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:53:00,311] Trial 21 finished with value: 0.9222221970558167 and parameters: {'filters_1': 47, 'filters_2': 123, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.27298676341108064, 'dropout_2': 0.4055493046768332, 'dense_units': 129, 'learning_rate': 0.0004859136594503574}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:53:27,606] Trial 22 finished with value: 0.9111111164093018 and parameters: {'filters_1': 44, 'filters_2': 122, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.2696559969172424, 'dropout_2': 0.3884028299270095, 'dense_units': 124, 'learning_rate': 0.0004876468579827277}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:53:45,554] Trial 23 finished with value: 0.8888888955116272 and parameters: {'filters_1': 61, 'filters_2': 73, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.23128240095655628, 'dropout_2': 0.43366992735632287, 'dense_units': 99, 'learning_rate': 0.00019117653361831762}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:54:02,237] Trial 24 finished with value: 0.8999999761581421 and parameters: {'filters_1': 52, 'filters_2': 141, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.3041587153401159, 'dropout_2': 0.398204445170376, 'dense_units': 79, 'learning_rate': 0.00011422703428140538}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:54:30,200] Trial 25 finished with value: 0.9111111164093018 and parameters: {'filters_1': 72, 'filters_2': 236, 'kernel_size_1': 3, 'kernel_size_2': 4, 'dropout_1': 0.3386117151007234, 'dropout_2': 0.44337115184567205, 'dense_units': 129, 'learning_rate': 0.0007349031739775794}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:54:48,616] Trial 26 finished with value: 0.9111111164093018 and parameters: {'filters_1': 60, 'filters_2': 211, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.25956808532822284, 'dropout_2': 0.36017096855986536, 'dense_units': 112, 'learning_rate': 0.00030219345307849586}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:55:15,435] Trial 27 finished with value: 0.8888888955116272 and parameters: {'filters_1': 33, 'filters_2': 95, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.23188004549058258, 'dropout_2': 0.3071933598844476, 'dense_units': 100, 'learning_rate': 0.0029242032382932157}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:55:32,950] Trial 28 finished with value: 0.8888888955116272 and parameters: {'filters_1': 45, 'filters_2': 133, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.305195050330465, 'dropout_2': 0.40276042494146136, 'dense_units': 146, 'learning_rate': 5.458310655591577e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:55:47,470] Trial 29 finished with value: 0.5444444417953491 and parameters: {'filters_1': 128, 'filters_2': 165, 'kernel_size_1': 3, 'kernel_size_2': 4, 'dropout_1': 0.3569603085723054, 'dropout_2': 0.4922060491740591, 'dense_units': 181, 'learning_rate': 1.584487106533323e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:56:05,975] Trial 30 finished with value: 0.8888888955116272 and parameters: {'filters_1': 115, 'filters_2': 106, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.3281750660013824, 'dropout_2': 0.3737840848248487, 'dense_units': 78, 'learning_rate': 2.5736945729666565e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:56:33,688] Trial 31 finished with value: 0.8999999761581421 and parameters: {'filters_1': 45, 'filters_2': 101, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.29143444516575334, 'dropout_2': 0.4057613802524141, 'dense_units': 137, 'learning_rate': 0.0004774754710171809}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:56:51,911] Trial 32 finished with value: 0.8888888955116272 and parameters: {'filters_1': 41, 'filters_2': 121, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.27426575450994795, 'dropout_2': 0.41217589014978784, 'dense_units': 154, 'learning_rate': 0.00022273061523305897}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:57:18,638] Trial 33 finished with value: 0.8999999761581421 and parameters: {'filters_1': 51, 'filters_2': 88, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.24442851073671049, 'dropout_2': 0.44884212700936366, 'dense_units': 142, 'learning_rate': 0.0004102285189373308}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:57:45,811] Trial 34 finished with value: 0.8999999761581421 and parameters: {'filters_1': 36, 'filters_2': 108, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.2937225362538803, 'dropout_2': 0.3760813117888636, 'dense_units': 121, 'learning_rate': 7.753314420187831e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:58:12,637] Trial 35 finished with value: 0.8999999761581421 and parameters: {'filters_1': 58, 'filters_2': 189, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.22314115861471664, 'dropout_2': 0.34543987636213835, 'dense_units': 204, 'learning_rate': 0.00014392269878643572}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:58:40,277] Trial 36 finished with value: 0.8999999761581421 and parameters: {'filters_1': 66, 'filters_2': 65, 'kernel_size_1': 3, 'kernel_size_2': 3, 'dropout_1': 0.37500507182713977, 'dropout_2': 0.4530204586979437, 'dense_units': 104, 'learning_rate': 5.230163712615732e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:59:07,524] Trial 37 finished with value: 0.8999999761581421 and parameters: {'filters_1': 48, 'filters_2': 131, 'kernel_size_1': 5, 'kernel_size_2': 4, 'dropout_1': 0.3244686643192047, 'dropout_2': 0.4223849267388872, 'dense_units': 177, 'learning_rate': 0.0003008501706796602}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:59:25,800] Trial 38 finished with value: 0.9111111164093018 and parameters: {'filters_1': 107, 'filters_2': 156, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.26278399363130556, 'dropout_2': 0.4688861040709221, 'dense_units': 158, 'learning_rate': 0.0009497026154151705}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 16:59:53,528] Trial 39 finished with value: 0.8999999761581421 and parameters: {'filters_1': 38, 'filters_2': 241, 'kernel_size_1': 3, 'kernel_size_2': 4, 'dropout_1': 0.3172587971963795, 'dropout_2': 0.3309693897761231, 'dense_units': 191, 'learning_rate': 7.600777931510383e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:00:13,425] Trial 40 finished with value: 0.8999999761581421 and parameters: {'filters_1': 122, 'filters_2': 173, 'kernel_size_1': 4, 'kernel_size_2': 4, 'dropout_1': 0.2161237007670856, 'dropout_2': 0.2606885023598794, 'dense_units': 88, 'learning_rate': 0.001526852663945485}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:00:31,437] Trial 41 finished with value: 0.9111111164093018 and parameters: {'filters_1': 56, 'filters_2': 228, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.25199357926484095, 'dropout_2': 0.3924542920033023, 'dense_units': 114, 'learning_rate': 2.3995470139337766e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:00:58,471] Trial 42 finished with value: 0.9111111164093018 and parameters: {'filters_1': 55, 'filters_2': 255, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.2839846024167107, 'dropout_2': 0.3861031008100392, 'dense_units': 112, 'learning_rate': 0.00011389898325199926}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:01:25,823] Trial 43 finished with value: 0.9111111164093018 and parameters: {'filters_1': 75, 'filters_2': 216, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.2421955044105012, 'dropout_2': 0.35604987293460577, 'dense_units': 253, 'learning_rate': 4.297532384865094e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:01:44,186] Trial 44 finished with value: 0.9111111164093018 and parameters: {'filters_1': 66, 'filters_2': 237, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.2975451255749283, 'dropout_2': 0.4088721379990002, 'dense_units': 122, 'learning_rate': 0.00023848016466991332}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:02:02,891] Trial 45 finished with value: 0.8999999761581421 and parameters: {'filters_1': 49, 'filters_2': 229, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.2705527615965292, 'dropout_2': 0.310121492565804, 'dense_units': 225, 'learning_rate': 1.0921774883326119e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:02:20,456] Trial 46 finished with value: 0.8888888955116272 and parameters: {'filters_1': 94, 'filters_2': 117, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.25696615157751124, 'dropout_2': 0.2887800671007851, 'dense_units': 133, 'learning_rate': 1.8824006589206118e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:02:47,817] Trial 47 finished with value: 0.9111111164093018 and parameters: {'filters_1': 83, 'filters_2': 207, 'kernel_size_1': 5, 'kernel_size_2': 4, 'dropout_1': 0.28141098579266005, 'dropout_2': 0.3685774134152419, 'dense_units': 147, 'learning_rate': 0.00015298813837852734}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:03:06,289] Trial 48 finished with value: 0.8777777552604675 and parameters: {'filters_1': 32, 'filters_2': 249, 'kernel_size_1': 4, 'kernel_size_2': 3, 'dropout_1': 0.2000502952159187, 'dropout_2': 0.22503314437080058, 'dense_units': 93, 'learning_rate': 3.561729952346203e-05}. Best is trial 11 with value: 0.9222221970558167.\n","[I 2025-01-16 17:03:34,070] Trial 49 finished with value: 0.8999999761581421 and parameters: {'filters_1': 41, 'filters_2': 192, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_1': 0.49720540497182825, 'dropout_2': 0.4184238637597771, 'dense_units': 163, 'learning_rate': 0.0006508085242434319}. Best is trial 11 with value: 0.9222221970558167.\n"]},{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'filters_1': 60, 'filters_2': 197, 'kernel_size_1': 4, 'kernel_size_2': 5, 'dropout_1': 0.2598558372020141, 'dropout_2': 0.3931967458563041, 'dense_units': 104, 'learning_rate': 0.00018393736277396444}\n","Best Accuracy: 0.9222\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fGKE62nI5_-q"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}